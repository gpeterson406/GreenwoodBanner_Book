<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>A Second Semester Statistics Course with R</title>
  <meta name="description" content="A Second Semester Statistics Course with R">
  <meta name="generator" content="bookdown 0.4 and GitBook 2.6.7">

  <meta property="og:title" content="A Second Semester Statistics Course with R" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="gpeterson406/GreenwoodBanner_Book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="A Second Semester Statistics Course with R" />
  
  
  

<meta name="author" content="Mark Greenwood and Katherine Banner">


<meta name="date" content="2017-07-09">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="chapter7.html">
<link rel="next" href="chapter9.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Acknowledgments</a></li>
<li class="chapter" data-level="1" data-path="chapter1.html"><a href="chapter1.html"><i class="fa fa-check"></i><b>1</b> Preface</a><ul>
<li class="chapter" data-level="1.1" data-path="chapter1.html"><a href="chapter1.html#overview-of-methods"><i class="fa fa-check"></i><b>1.1</b> Overview of methods</a></a></li>
<li class="chapter" data-level="1.2" data-path="chapter1.html"><a href="chapter1.html#getting-started-in-r"><i class="fa fa-check"></i><b>1.2</b> Getting started in R</a></li>
<li class="chapter" data-level="1.3" data-path="chapter1.html"><a href="chapter1.html#basic-summary-statistics-histograms-and-boxplots-using-r"><i class="fa fa-check"></i><b>1.3</b> Basic summary statistics, histograms, and boxplots using R</a></li>
<li class="chapter" data-level="1.4" data-path="chapter1.html"><a href="chapter1.html#chapter-summary"><i class="fa fa-check"></i><b>1.4</b> Chapter summary</a></li>
<li class="chapter" data-level="1.5" data-path="chapter1.html"><a href="chapter1.html#important-r-code"><i class="fa fa-check"></i><b>1.5</b> Important R Code</a></li>
<li class="chapter" data-level="1.6" data-path="chapter1.html"><a href="chapter1.html#practice-problems"><i class="fa fa-check"></i><b>1.6</b> Practice problems</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="chapter2.html"><a href="chapter2.html"><i class="fa fa-check"></i><b>2</b> (R)e-Introduction to statistics</a><ul>
<li class="chapter" data-level="2.1" data-path="chapter2.html"><a href="chapter2.html#section2-1"><i class="fa fa-check"></i><b>2.1</b> Histograms, boxplots, and density curves</a></li>
<li class="chapter" data-level="2.2" data-path="chapter2.html"><a href="chapter2.html#section2-2"><i class="fa fa-check"></i><b>2.2</b> Beanplots</a></li>
<li class="chapter" data-level="2.3" data-path="chapter2.html"><a href="chapter2.html#section2-3"><i class="fa fa-check"></i><b>2.3</b> Models, hypotheses, and permutations for the 2 sample mean situation</a></li>
<li class="chapter" data-level="2.4" data-path="chapter2.html"><a href="chapter2.html#section2-4"><i class="fa fa-check"></i><b>2.4</b> Permutation testing for the 2 sample mean situation</a></li>
<li class="chapter" data-level="2.5" data-path="chapter2.html"><a href="chapter2.html#section2-5"><i class="fa fa-check"></i><b>2.5</b> Hypothesis testing (general)</a></li>
<li class="chapter" data-level="2.6" data-path="chapter2.html"><a href="chapter2.html#section2-6"><i class="fa fa-check"></i><b>2.6</b> Connecting randomization (nonparametric) and parametric tests</a></li>
<li class="chapter" data-level="2.7" data-path="chapter2.html"><a href="chapter2.html#section2-7"><i class="fa fa-check"></i><b>2.7</b> Second example of permutation tests</a></li>
<li class="chapter" data-level="2.8" data-path="chapter2.html"><a href="chapter2.html#section2-8"><i class="fa fa-check"></i><b>2.8</b> Confidence intervals and bootstrapping</a></li>
<li class="chapter" data-level="2.9" data-path="chapter2.html"><a href="chapter2.html#section2-9"><i class="fa fa-check"></i><b>2.9</b> Bootstrap confidence intervals for difference in GPAs</a></li>
<li class="chapter" data-level="2.10" data-path="chapter2.html"><a href="chapter2.html#section2-10"><i class="fa fa-check"></i><b>2.10</b> Chapter summary</a></li>
<li class="chapter" data-level="2.11" data-path="chapter2.html"><a href="chapter2.html#section2-11"><i class="fa fa-check"></i><b>2.11</b> Summary of important R code</a></li>
<li class="chapter" data-level="2.12" data-path="chapter2.html"><a href="chapter2.html#section2-12"><i class="fa fa-check"></i><b>2.12</b> Practice problems</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="chapter3.html"><a href="chapter3.html"><i class="fa fa-check"></i><b>3</b> One-Way ANOVA</a><ul>
<li class="chapter" data-level="3.1" data-path="chapter3.html"><a href="chapter3.html#section3-1"><i class="fa fa-check"></i><b>3.1</b> Situation</a></li>
<li class="chapter" data-level="3.2" data-path="chapter3.html"><a href="chapter3.html#section3-2"><i class="fa fa-check"></i><b>3.2</b> Linear model for One-Way ANOVA (cell-means and reference-coding)</a></li>
<li class="chapter" data-level="3.3" data-path="chapter3.html"><a href="chapter3.html#section3-3"><i class="fa fa-check"></i><b>3.3</b> One-Way ANOVA Sums of Squares, Mean Squares, and F-test</a></li>
<li class="chapter" data-level="3.4" data-path="chapter3.html"><a href="chapter3.html#section3-4"><i class="fa fa-check"></i><b>3.4</b> ANOVA model diagnostics including QQ-plots</a></li>
<li class="chapter" data-level="3.5" data-path="chapter3.html"><a href="chapter3.html#section3-5"><i class="fa fa-check"></i><b>3.5</b> Guinea pig tooth growth One-Way ANOVA example</a></li>
<li class="chapter" data-level="3.6" data-path="chapter3.html"><a href="chapter3.html#section3-6"><i class="fa fa-check"></i><b>3.6</b> Multiple (pair-wise) comparisons using Tukey’s HSD and the compact letter display</a></li>
<li class="chapter" data-level="3.7" data-path="chapter3.html"><a href="chapter3.html#section3-7"><i class="fa fa-check"></i><b>3.7</b> Pair-wise comparisons for Prisoner Rating data</a></li>
<li class="chapter" data-level="3.8" data-path="chapter3.html"><a href="chapter3.html#section3-8"><i class="fa fa-check"></i><b>3.8</b> Chapter Summary</a></li>
<li class="chapter" data-level="3.9" data-path="chapter3.html"><a href="chapter3.html#section3-9"><i class="fa fa-check"></i><b>3.9</b> Summary of important R code</a></li>
<li class="chapter" data-level="3.10" data-path="chapter3.html"><a href="chapter3.html#section3-10"><i class="fa fa-check"></i><b>3.10</b> Practice problems</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="chapter4.html"><a href="chapter4.html"><i class="fa fa-check"></i><b>4</b> Two-Way ANOVA</a><ul>
<li class="chapter" data-level="4.1" data-path="chapter4.html"><a href="chapter4.html#section4-1"><i class="fa fa-check"></i><b>4.1</b> Situation</a></li>
<li class="chapter" data-level="4.2" data-path="chapter4.html"><a href="chapter4.html#section4-2"><i class="fa fa-check"></i><b>4.2</b> Designing a two-way experiment and visualizing results</a></li>
<li class="chapter" data-level="4.3" data-path="chapter4.html"><a href="chapter4.html#section4-3"><i class="fa fa-check"></i><b>4.3</b> Two-Way ANOVA models and hypothesis tests</a></li>
<li class="chapter" data-level="4.4" data-path="chapter4.html"><a href="chapter4.html#section4-4"><i class="fa fa-check"></i><b>4.4</b> Guinea pig tooth growth analysis with Two-Way ANOVA</a></li>
<li class="chapter" data-level="4.5" data-path="chapter4.html"><a href="chapter4.html#section4-5"><i class="fa fa-check"></i><b>4.5</b> Observational study example: The Psychology of Debt</a></li>
<li class="chapter" data-level="4.6" data-path="chapter4.html"><a href="chapter4.html#section4-6"><i class="fa fa-check"></i><b>4.6</b> Pushing Two-Way ANOVA to the limit: Un-replicated designs</a></li>
<li class="chapter" data-level="4.7" data-path="chapter4.html"><a href="chapter4.html#section4-7"><i class="fa fa-check"></i><b>4.7</b> Chapter summary</a></li>
<li class="chapter" data-level="4.8" data-path="chapter4.html"><a href="chapter4.html#section4-8"><i class="fa fa-check"></i><b>4.8</b> Important R code</a></li>
<li class="chapter" data-level="4.9" data-path="chapter4.html"><a href="chapter4.html#section4-9"><i class="fa fa-check"></i><b>4.9</b> Practice problems</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="chapter5.html"><a href="chapter5.html"><i class="fa fa-check"></i><b>5</b> Chi-square tests</a><ul>
<li class="chapter" data-level="5.1" data-path="chapter5.html"><a href="chapter5.html#section5-1"><i class="fa fa-check"></i><b>5.1</b> Situation, contingency tables, and plots</a></li>
<li class="chapter" data-level="5.2" data-path="chapter5.html"><a href="chapter5.html#section5-2"><i class="fa fa-check"></i><b>5.2</b> Homogeneity Test Hypotheses</a></li>
<li class="chapter" data-level="5.3" data-path="chapter5.html"><a href="chapter5.html#section5-3"><i class="fa fa-check"></i><b>5.3</b> Independence Test Hypotheses</a></li>
<li class="chapter" data-level="5.4" data-path="chapter5.html"><a href="chapter5.html#section5-4"><i class="fa fa-check"></i><b>5.4</b> Models for R by C tables</a></li>
<li class="chapter" data-level="5.5" data-path="chapter5.html"><a href="chapter5.html#section5-5"><i class="fa fa-check"></i><b>5.5</b> Permutation tests for the <span class="math inline">\(X^2\)</span> statistic</a></li>
<li class="chapter" data-level="5.6" data-path="chapter5.html"><a href="chapter5.html#section5-6"><i class="fa fa-check"></i><b>5.6</b> Chi-square distribution for the <span class="math inline">\(X^2\)</span> statistic</a></li>
<li class="chapter" data-level="5.7" data-path="chapter5.html"><a href="chapter5.html#section5-7"><i class="fa fa-check"></i><b>5.7</b> Examining residuals for the source of differences</a></li>
<li class="chapter" data-level="5.8" data-path="chapter5.html"><a href="chapter5.html#section5-8"><i class="fa fa-check"></i><b>5.8</b> General Protocol for <span class="math inline">\(X^2\)</span> tests</a></li>
<li class="chapter" data-level="5.9" data-path="chapter5.html"><a href="chapter5.html#section5-9"><i class="fa fa-check"></i><b>5.9</b> Political Party and Voting results: Complete Analysis</a></li>
<li class="chapter" data-level="5.10" data-path="chapter5.html"><a href="chapter5.html#section5-10"><i class="fa fa-check"></i><b>5.10</b> Is cheating and lying related in students?</a></li>
<li class="chapter" data-level="5.11" data-path="chapter5.html"><a href="chapter5.html#section5-11"><i class="fa fa-check"></i><b>5.11</b> Analyzing a stratified random sample of California schools</a></li>
<li class="chapter" data-level="5.12" data-path="chapter5.html"><a href="chapter5.html#section5-12"><i class="fa fa-check"></i><b>5.12</b> Chapter summary</a></li>
<li class="chapter" data-level="5.13" data-path="chapter5.html"><a href="chapter5.html#section5-13"><i class="fa fa-check"></i><b>5.13</b> Review of Important R commands</a></li>
<li class="chapter" data-level="5.14" data-path="chapter5.html"><a href="chapter5.html#section5-14"><i class="fa fa-check"></i><b>5.14</b> Practice problems</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="chapter6.html"><a href="chapter6.html"><i class="fa fa-check"></i><b>6</b> Correlation and Simple Linear Regression</a><ul>
<li class="chapter" data-level="6.1" data-path="chapter6.html"><a href="chapter6.html#section6-1"><i class="fa fa-check"></i><b>6.1</b> Relationships between two quantitative variables</a></li>
<li class="chapter" data-level="6.2" data-path="chapter6.html"><a href="chapter6.html#section6-2"><i class="fa fa-check"></i><b>6.2</b> Estimating the correlation coefficient</a></li>
<li class="chapter" data-level="6.3" data-path="chapter6.html"><a href="chapter6.html#section6-3"><i class="fa fa-check"></i><b>6.3</b> Relationships between variables by groups</a></li>
<li class="chapter" data-level="6.4" data-path="chapter6.html"><a href="chapter6.html#section6-4"><i class="fa fa-check"></i><b>6.4</b> Inference for the correlation coefficient (Optional Section)</a></li>
<li class="chapter" data-level="6.5" data-path="chapter6.html"><a href="chapter6.html#section6-5"><i class="fa fa-check"></i><b>6.5</b> Are tree diameters related to tree heights?</a></li>
<li class="chapter" data-level="6.6" data-path="chapter6.html"><a href="chapter6.html#section6-6"><i class="fa fa-check"></i><b>6.6</b> Describing relationships with a regression model</a></li>
<li class="chapter" data-level="6.7" data-path="chapter6.html"><a href="chapter6.html#section6-7"><i class="fa fa-check"></i><b>6.7</b> Least Squares Estimation</a></li>
<li class="chapter" data-level="6.8" data-path="chapter6.html"><a href="chapter6.html#section6-8"><i class="fa fa-check"></i><b>6.8</b> Measuring the strength of regressions: R2</a></li>
<li class="chapter" data-level="6.9" data-path="chapter6.html"><a href="chapter6.html#section6-9"><i class="fa fa-check"></i><b>6.9</b> Outliers: leverage and influence</a></li>
<li class="chapter" data-level="6.10" data-path="chapter6.html"><a href="chapter6.html#section6-10"><i class="fa fa-check"></i><b>6.10</b> Residual diagnostics – setting the stage for inference</a></li>
<li class="chapter" data-level="6.11" data-path="chapter6.html"><a href="chapter6.html#section6-11"><i class="fa fa-check"></i><b>6.11</b> Old Faithful discharge and waiting times</a></li>
<li class="chapter" data-level="6.12" data-path="chapter6.html"><a href="chapter6.html#section6-12"><i class="fa fa-check"></i><b>6.12</b> Chapter summary</a></li>
<li class="chapter" data-level="6.13" data-path="chapter6.html"><a href="chapter6.html#section6-13"><i class="fa fa-check"></i><b>6.13</b> Important R code</a></li>
<li class="chapter" data-level="6.14" data-path="chapter6.html"><a href="chapter6.html#section6-14"><i class="fa fa-check"></i><b>6.14</b> Practice problems</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="chapter7.html"><a href="chapter7.html"><i class="fa fa-check"></i><b>7</b> Simple linear regression inference</a><ul>
<li class="chapter" data-level="7.1" data-path="chapter7.html"><a href="chapter7.html#section7-1"><i class="fa fa-check"></i><b>7.1</b> Model</a></li>
<li class="chapter" data-level="7.2" data-path="chapter7.html"><a href="chapter7.html#section7-2"><i class="fa fa-check"></i><b>7.2</b> Confidence Interval and Hypothesis tests for the slope and intercept</a></li>
<li class="chapter" data-level="7.3" data-path="chapter7.html"><a href="chapter7.html#section7-3"><i class="fa fa-check"></i><b>7.3</b> Bozeman temperature trend</a></li>
<li class="chapter" data-level="7.4" data-path="chapter7.html"><a href="chapter7.html#section7-4"><i class="fa fa-check"></i><b>7.4</b> Randomizing inferences for the slope coefficient</a></li>
<li class="chapter" data-level="7.5" data-path="chapter7.html"><a href="chapter7.html#section7-5"><i class="fa fa-check"></i><b>7.5</b> Transformations part I: Linearizing relationships</a></li>
<li class="chapter" data-level="7.6" data-path="chapter7.html"><a href="chapter7.html#section7-6"><i class="fa fa-check"></i><b>7.6</b> Transformations part II: Impacts on SLR interpretations: log(y), log(x), &amp; both log(y) &amp; log(x)</a></li>
<li class="chapter" data-level="7.7" data-path="chapter7.html"><a href="chapter7.html#section7-7"><i class="fa fa-check"></i><b>7.7</b> Confidence Interval for the mean and prediction Intervals for a new observation</a></li>
<li class="chapter" data-level="7.8" data-path="chapter7.html"><a href="chapter7.html#section7-8"><i class="fa fa-check"></i><b>7.8</b> Chapter summary</a></li>
<li class="chapter" data-level="7.9" data-path="chapter7.html"><a href="chapter7.html#section7-9"><i class="fa fa-check"></i><b>7.9</b> Important R code</a></li>
<li class="chapter" data-level="7.10" data-path="chapter7.html"><a href="chapter7.html#section7-10"><i class="fa fa-check"></i><b>7.10</b> Practice problems</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="chapter8.html"><a href="chapter8.html"><i class="fa fa-check"></i><b>8</b> Multiple linear regression</a><ul>
<li class="chapter" data-level="8.1" data-path="chapter8.html"><a href="chapter8.html#section8-1"><i class="fa fa-check"></i><b>8.1</b> Going from SLR to MLR</a></li>
<li class="chapter" data-level="8.2" data-path="chapter8.html"><a href="chapter8.html#section8-2"><i class="fa fa-check"></i><b>8.2</b> Validity conditions in MLR</a></li>
<li class="chapter" data-level="8.3" data-path="chapter8.html"><a href="chapter8.html#section8-3"><i class="fa fa-check"></i><b>8.3</b> Interpretation of MLR terms</a></li>
<li class="chapter" data-level="8.4" data-path="chapter8.html"><a href="chapter8.html#section8-4"><i class="fa fa-check"></i><b>8.4</b> Comparing multiple regression models</a></li>
<li class="chapter" data-level="8.5" data-path="chapter8.html"><a href="chapter8.html#section8-5"><i class="fa fa-check"></i><b>8.5</b> General recommendations for MLR interpretations and VIFs</a></li>
<li class="chapter" data-level="8.6" data-path="chapter8.html"><a href="chapter8.html#section8-6"><i class="fa fa-check"></i><b>8.6</b> MLR Inference: Parameter inferences using the t-distribution</a></li>
<li class="chapter" data-level="8.7" data-path="chapter8.html"><a href="chapter8.html#section8-7"><i class="fa fa-check"></i><b>8.7</b> Overall F-test in Multiple Linear Regression</a></li>
<li class="chapter" data-level="8.8" data-path="chapter8.html"><a href="chapter8.html#section8-8"><i class="fa fa-check"></i><b>8.8</b> Case Study: First year college GPA and SATs</a></li>
<li class="chapter" data-level="8.9" data-path="chapter8.html"><a href="chapter8.html#section8-9"><i class="fa fa-check"></i><b>8.9</b> Different intercepts for different groups: MLR with Indicator variables</a></li>
<li class="chapter" data-level="8.10" data-path="chapter8.html"><a href="chapter8.html#section8-10"><i class="fa fa-check"></i><b>8.10</b> Additive MLR with more than two groups: Headache example</a></li>
<li class="chapter" data-level="8.11" data-path="chapter8.html"><a href="chapter8.html#section8-11"><i class="fa fa-check"></i><b>8.11</b> Different slopes and different intercepts</a></li>
<li class="chapter" data-level="8.12" data-path="chapter8.html"><a href="chapter8.html#section8-12"><i class="fa fa-check"></i><b>8.12</b> F-tests for MLR models with quantitative and categorical variables and interactions</a></li>
<li class="chapter" data-level="8.13" data-path="chapter8.html"><a href="chapter8.html#section8-13"><i class="fa fa-check"></i><b>8.13</b> AICs for model selection</a></li>
<li class="chapter" data-level="8.14" data-path="chapter8.html"><a href="chapter8.html#section8-14"><i class="fa fa-check"></i><b>8.14</b> Forced Expiratory Volume model selection using AICs</a></li>
<li class="chapter" data-level="8.15" data-path="chapter8.html"><a href="chapter8.html#section8-15"><i class="fa fa-check"></i><b>8.15</b> Chapter summary</a></li>
<li class="chapter" data-level="8.16" data-path="chapter8.html"><a href="chapter8.html#section8-16"><i class="fa fa-check"></i><b>8.16</b> Important R code</a></li>
<li class="chapter" data-level="8.17" data-path="chapter8.html"><a href="chapter8.html#section8-17"><i class="fa fa-check"></i><b>8.17</b> Practice problems</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="chapter9.html"><a href="chapter9.html"><i class="fa fa-check"></i><b>9</b> Case studies</a><ul>
<li class="chapter" data-level="9.1" data-path="chapter9.html"><a href="chapter9.html#section9-1"><i class="fa fa-check"></i><b>9.1</b> Overview of material covered</a></li>
<li class="chapter" data-level="9.2" data-path="chapter9.html"><a href="chapter9.html#section9-2"><i class="fa fa-check"></i><b>9.2</b> The impact of simulated chronic nitrogen deposition on the biomass and N2-fixation activity of two boreal feather moss–cyanobacteria associations</a></li>
<li class="chapter" data-level="9.3" data-path="chapter9.html"><a href="chapter9.html#section9-3"><i class="fa fa-check"></i><b>9.3</b> Ants learn to rely on more informative attributes during decision-making</a></li>
<li class="chapter" data-level="9.4" data-path="chapter9.html"><a href="chapter9.html#section9-4"><i class="fa fa-check"></i><b>9.4</b> Multi-variate models are essential for understanding vertebrate diversification in deep time</a></li>
<li class="chapter" data-level="9.5" data-path="chapter9.html"><a href="chapter9.html#section9-5"><i class="fa fa-check"></i><b>9.5</b> General summary</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">A Second Semester Statistics Course with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="chapter8" class="section level1">
<h1><span class="header-section-number">Chapter 8</span> Multiple linear regression</h1>
<div id="section8-1" class="section level2">
<h2><span class="header-section-number">8.1</span> Going from SLR to MLR</h2>
<p>In many situations, especially in observational studies, it is unlikely that the system is simple enough to be characterized by a single predictor variable. In experiments, if we randomly assign levels of a predictor variable we can assume that the impacts of other variables cancel out as a direct result of the random assignment. But it is possible even in these experimental situations that we can “improve” our model for the response variable by adding additional predictor variables that explain additional variation in the responses, reducing the amount of unexplained variation. This can allow more precise inferences to be generated from the model. As mentioned previously, it might be useful to know the sex or weight of the subjects in the Beers vs BAC study to account for more of the variation in the responses – this idea motivates our final topic: <strong><em>multiple linear regression</em></strong> (<strong>MLR</strong>) models. In observational studies, we can think of a suite of characteristics of observations that might be related to a response variable. For example, consider a study of yearly salaries and variables that might explain the amount people get paid. We might be most interested in seeing how incomes change based on age, but it would be hard to ignore potential differences based on sex and education level. Trying to explain incomes would likely require more than one predictor variable and we wouldn’t be able to explain all the variability in the responses just based on gender and education level, but a model using those variables might still provide some useful information about each component and about age impacts on income after we adjust (control for) sex and education. The extension to MLR allows us to incorporate multiple predictors into a regression model. Geometrically, this is a way of relating many different dimensions (number of <span class="math inline">\(x\text{&#39;s}\)</span>) to what happened in a single response variable (one dimension).</p>
<p>We start with the same model as in SLR except now we allow <span class="math inline">\(K\)</span> different <span class="math inline">\(x\text{&#39;s}\)</span>:</p>
<p><span class="math display">\[y_i = \beta_0 + \beta_1x_{1i} + \beta_2x_{2i}+ \ldots + \beta_Kx_{Ki}
+ \varepsilon_i\]</span></p>
<p>Note that if <span class="math inline">\(K=1\)</span>, we are back to SLR. In the MLR model, there are <span class="math inline">\(K\)</span> predictors and we still have a y-intercept. The MLR model carries the same assumptions as an SLR model with a couple of slight tweaks specific to MLR (see Section <a href="chapter8.html#section8-2">8.2</a> for the details on the changes to the validity conditions).</p>
<p>We are able to use the least squares criterion for estimating the regression coefficients in MLR, but the mathematics are beyond the scope of this course. The <code>lm</code> function takes care of finding the least squares coefficients using a very sophisticated algorithm<a href="#fn69" class="footnoteRef" id="fnref69"><sup>69</sup></a>. The estimated regression equation it returns is:</p>
<p><span class="math display">\[\hat{y}_i = b_0 + b_1x_{1i} +b_2x_{2i}+\ldots+b_Kx_{Ki}\]</span></p>
<p>where each <span class="math inline">\(b_k\)</span> estimates its corresponding parameter <span class="math inline">\(\beta_k\)</span>.</p>
<p>An example of snow depths at some high elevation locations on a day in April provides a nice motivation for these methods. A random sample of <span class="math inline">\(n=25\)</span> MT locations (from the population of <span class="math inline">\(N=85\)</span> at the time) were obtained from the Natural Resources Conversation Service’s website (<a href="http://www.wcc.nrcs.usda.gov/snotel/Montana/montana.html" class="uri">http://www.wcc.nrcs.usda.gov/snotel/Montana/montana.html</a>) a few years ago. Information on the snow depth (<code>Snow.Depth</code>) in inches, daily Minimum and Maximum Temperatures (<code>Min.Temp</code> and <code>Max.Temp</code>) in <span class="math inline">\(^\circ F\)</span> and elevation of the site (<code>Elevation</code>) in feet. A snow science researcher (or spring back-country skier) might be interested in understanding <em>Snow depth</em> as a function of <em>Minimum Temperature</em>, <em>Maximum Temperature</em>, and <em>Elevation</em>. One might assume that colder and higher places will have more snow, but using just one of the predictor variables might leave out some important predictive information. The following code loads the data set and makes the scatterplot matrix (Figure <a href="chapter8.html#fig:Figure8-1">8.1</a>) to allow some preliminary assessment of the pairwise relationships.</p>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">snotel_s &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;http://www.math.montana.edu/courses/s217/documents/snotel_s.csv&quot;</span>)
snotel2 &lt;-<span class="st"> </span>snotel_s[,<span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>,<span class="dv">4</span><span class="op">:</span><span class="dv">6</span>,<span class="dv">3</span>)] <span class="co">#Reorders columns for nicer pairs.panel display</span>
<span class="kw">require</span>(psych)
<span class="kw">pairs.panels</span>(snotel2[,<span class="op">-</span><span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>)], <span class="dt">ellipse=</span>F,
             <span class="dt">main=</span><span class="st">&quot;Scatterplot matrix of SNOTEL Data&quot;</span>)</code></pre></div>
<div class="figure"><span id="fig:Figure8-1"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-1-1.png" alt="Scatterplot matrix of the SNOTEL data." width="672" />
<p class="caption">
Figure 8.1: Scatterplot matrix of the SNOTEL data.
</p>
</div>
<p>It appears that there are many strong linear relationships between the variables, with <em>Elevation</em> and <em>Snow Depth</em> having the largest magnitude, <strong><em>r</em></strong> = 0.80. Higher temperatures seem to be associated with less snow - not a big surprise so far! There might be an outlier at an elevation of 7400 feet and a snow depth below 10 inches that we should explore further.</p>
<p>A new issue arises in attempting to build MLR models called <strong><em>multicollinearity</em></strong>. Again, it is a not surprise that temperature and elevation are correlated but that creates a problem if we try to put them both into a model to explain snow depth. Is it the elevation, temperature, or the combination of both that matters for getting and retaining more snow? <strong>Correlation between predictor variables</strong> is called multicollinearity and <strong>makes estimation and interpretation of MLR models more complicated than in SLR</strong>. Section <a href="chapter8.html#section8-5">8.5</a> deals with this issue directly and discusses methods for detecting its presence. For now, remember that in MLR this issue sometimes makes it difficult to disentangle the impacts of different predictor variables on the response when the predictors share information – when they are correlated.</p>
<p>To get familiar with this example, we can start with fitting some potential SLR models and plotting the estimated models. Figure <a href="chapter8.html#fig:Figure8-2">8.2</a> contains the result for the SLR using <em>Elevation</em> and results for two temperature based models are in Figure <a href="chapter8.html#fig:Figure8-3">8.3</a>. <em>Snow Depth</em> is selected as the obvious response variable both due to skier interest and potential scientific causation (snow can’t change elevation but elevation could be the driver of snow deposition and retention).</p>

<div class="figure"><span id="fig:Figure8-2"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-2-1.png" alt="Plot of estimated SLR model for Snow Depth with Elevation as the predictor." width="672" />
<p class="caption">
Figure 8.2: Plot of estimated SLR model for Snow Depth with Elevation as the predictor.
</p>
</div>
<p>Based on the model summaries provided below, the three estimated SLR models are:</p>
<p><span class="math display">\[\begin{array}{rl}
\widehat{\text{SnowDepth}}_i &amp;= -72.006 + 0.0163\text{ Elevation}_i, \\
\widehat{\text{SnowDepth}}_i &amp;= 174.096 - 4.884\text{ MinTemp}_i,\text{ and} \\
\widehat{\text{SnowDepth}}_i &amp;= 122.672 - 2.284\text{ MaxTemp}_i.
\end{array}\]</span></p>
<p>The plots of the estimated models reinforce our expected results, showing a positive change in <em>Snow Depth</em> for higher <em>Elevations</em> and negative impacts for increasing temperatures on <em>Snow Depth</em>. These plots are made across the observed range<a href="#fn70" class="footnoteRef" id="fnref70"><sup>70</sup></a> of the predictor variable and help us to get a sense of the total impacts of predictors. For example, for elevation in Figure <a href="chapter8.html#fig:Figure8-2">8.2</a>, the smallest observed value was 4925 feet and the largest was 8300 feet. The regression line goes from estimating a mean snow depth of 8 inches to 63 inches. That gives you some practical idea of the size of the estimated <em>Snow Depth</em> change for the changes in <em>Elevation</em> observed in the data. Putting this together, we can say that there was around a 55 inch change in predicted snow depths for a close to 3400 foot increase in elevation. This helps make the slope coefficient of 0.0163 in the model more easily understood. Remember that in SLR, the range of <span class="math inline">\(x\)</span> matters just as much as the units of <span class="math inline">\(x\)</span> in determining the practical importance and size of the slope coefficient. A value of 0.0163 looks small but is actually at the heart of a pretty good model for predicting snow depth. A one foot change of elevation is “tiny” here relative to changes in the response so the slope coefficient can be small and still amount to big changes in the predicted response across the range of values of <span class="math inline">\(x\)</span>. If the <em>Elevation</em> had been recorded in thousands of feet, then the slope would have been <span class="math inline">\(0.0163*1000=16.3\)</span> inches in change in mean <em>Snow Depth</em> for a 1000 foot increase in elevation.</p>
<p>The plots of the two estimated temperature models in Figure <a href="chapter8.html#fig:Figure8-3">8.3</a> suggest a similar change in the responses over the range of observed temperatures. Those predictors range from 22<span class="math inline">\(^\circ F\)</span> to 34<span class="math inline">\(^\circ F\)</span> (minimum temperature) and from 26<span class="math inline">\(^\circ F\)</span> to 50<span class="math inline">\(^\circ F\)</span> (maximum temperature). This tells us a 1<span class="math inline">\(^\circ F\)</span> increase in either temperature is a greater proportion of the observed range of each predictor than a 1 unit (foot) increase in elevation, so these two variables will generate larger apparent magnitudes of slope coefficients. But having large slope coefficients is no guarantee of a good model – in fact, the elevation model has the highest <span class="math inline">\(R^2\)</span> value of these three models even though its slope coefficient looks tiny compared to the other models.</p>

<div class="figure"><span id="fig:Figure8-3"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-3-1.png" alt="Plots of two estimated SLR models using Min Temp (top panel) and Max Temp (bottom panel) as predictors. Note that each of these results are from models with a single predictor variable." width="672" /><img src="08-multipleLinearRegression_files/figure-html/Figure8-3-2.png" alt="Plots of two estimated SLR models using Min Temp (top panel) and Max Temp (bottom panel) as predictors. Note that each of these results are from models with a single predictor variable." width="672" />
<p class="caption">
Figure 8.3: Plots of two estimated SLR models using Min Temp (top panel) and Max Temp (bottom panel) as predictors. Note that each of these results are from models with a single predictor variable.
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m1 &lt;-<span class="st"> </span><span class="kw">lm</span>(Snow.Depth<span class="op">~</span>Elevation, <span class="dt">data=</span>snotel2)
m2 &lt;-<span class="st"> </span><span class="kw">lm</span>(Snow.Depth<span class="op">~</span>Min.Temp, <span class="dt">data=</span>snotel2)
m3 &lt;-<span class="st"> </span><span class="kw">lm</span>(Snow.Depth<span class="op">~</span>Max.Temp, <span class="dt">data=</span>snotel2)
<span class="kw">require</span>(effects)
<span class="kw">plot</span>(<span class="kw">allEffects</span>(m1, <span class="dt">xlevels=</span><span class="kw">list</span>(<span class="dt">Elevation=</span>snotel2<span class="op">$</span>Elevation)),
     <span class="dt">main=</span><span class="st">&quot;SLR: Effect of Elevation&quot;</span>)
<span class="kw">plot</span>(<span class="kw">allEffects</span>(m2, <span class="dt">xlevels=</span><span class="kw">list</span>(<span class="dt">Min.temp=</span>snotel2<span class="op">$</span>Min.Temp)),
     <span class="dt">main=</span><span class="st">&quot;SLR: Effect of Min Temp&quot;</span>)
<span class="kw">plot</span>(<span class="kw">allEffects</span>(m3, <span class="dt">xlevels=</span><span class="kw">list</span>(<span class="dt">Max.Temp=</span>snotel2<span class="op">$</span>Max.Temp)),
     <span class="dt">main=</span><span class="st">&quot;SLR: Effect of Max Temp&quot;</span>)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(m1)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Snow.Depth ~ Elevation, data = snotel2)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -36.416  -5.135  -1.767   7.645  23.508 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) -72.005873  17.712927  -4.065 0.000478
## Elevation     0.016275   0.002579   6.311 1.93e-06
## 
## Residual standard error: 13.27 on 23 degrees of freedom
## Multiple R-squared:  0.634,  Adjusted R-squared:  0.618 
## F-statistic: 39.83 on 1 and 23 DF,  p-value: 1.933e-06</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(m2)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Snow.Depth ~ Min.Temp, data = snotel2)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -26.156 -11.238   2.810   9.846  26.444 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) 174.0963    25.5628   6.811 6.04e-07
## Min.Temp     -4.8836     0.9148  -5.339 2.02e-05
## 
## Residual standard error: 14.65 on 23 degrees of freedom
## Multiple R-squared:  0.5534, Adjusted R-squared:  0.534 
## F-statistic:  28.5 on 1 and 23 DF,  p-value: 2.022e-05</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(m3)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Snow.Depth ~ Max.Temp, data = snotel2)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -26.447 -10.367  -4.394  10.042  34.774 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) 122.6723    19.6380   6.247 2.25e-06
## Max.Temp     -2.2840     0.5257  -4.345 0.000238
## 
## Residual standard error: 16.25 on 23 degrees of freedom
## Multiple R-squared:  0.4508, Adjusted R-squared:  0.4269 
## F-statistic: 18.88 on 1 and 23 DF,  p-value: 0.0002385</code></pre>
<p>Since all three variables look like they are potentially useful in predicting snow depth, we want to consider if an MLR model might explain more of the variability in <em>Snow Depth</em>. To fit an MLR model, we use the same general format as in other topics but with adding “<code>+</code>” between any additional predictors<a href="#fn71" class="footnoteRef" id="fnref71"><sup>71</sup></a> we want to add to the model, <code>y~x1+x2+...+xk</code>:</p>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m4 &lt;-<span class="st"> </span><span class="kw">lm</span>(Snow.Depth<span class="op">~</span>Elevation<span class="op">+</span>Min.Temp<span class="op">+</span>Max.Temp, <span class="dt">data=</span>snotel2)
<span class="kw">summary</span>(m4)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Snow.Depth ~ Elevation + Min.Temp + Max.Temp, data = snotel2)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -29.508  -7.679  -3.139   9.627  26.394 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) -10.506529  99.616286  -0.105   0.9170
## Elevation     0.012332   0.006536   1.887   0.0731
## Min.Temp     -0.504970   2.042614  -0.247   0.8071
## Max.Temp     -0.561892   0.673219  -0.835   0.4133
## 
## Residual standard error: 13.6 on 21 degrees of freedom
## Multiple R-squared:  0.6485, Adjusted R-squared:  0.5983 
## F-statistic: 12.91 on 3 and 21 DF,  p-value: 5.328e-05</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(<span class="kw">allEffects</span>(m4), <span class="dt">main=</span><span class="st">&quot;MLR model with Elev, Min &amp; Max Temps&quot;</span>)</code></pre></div>
<div class="figure"><span id="fig:Figure8-4"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-4-1.png" alt="Term-plots for the MLR for Snow Depth based on Elevation, Min Temp and Max Temp. Note that the x-axis ranges are different than those used in Figures 8.2 and 8.3 for the comparably SLR models." width="768" />
<p class="caption">
Figure 8.4: Term-plots for the MLR for Snow Depth based on Elevation, Min Temp and Max Temp. Note that the x-axis ranges are different than those used in Figures <a href="chapter8.html#fig:Figure8-2">8.2</a> and <a href="chapter8.html#fig:Figure8-3">8.3</a> for the comparably SLR models.
</p>
</div>
<p>Based on the output, the estimated MLR model is</p>
<p><span class="math display">\[\widehat{\text{SnowDepth}}_i = -10.51 + 0.0123\text{ Elevation}_i
-0.505\text{ MinTemp}_i - 0.562\text{ MaxTemp}_i.\]</span></p>
<p>The direction of the estimated slope coefficients were similar but they all changed in magnitude as compared to the respective SLRs, as seen in the estimated term-plots from the MLR model in Figure <a href="chapter8.html#fig:Figure8-4">8.4</a>.</p>
<p>There are two ways to think about the changes from individual SLR slope coefficients to the similar MLR results.</p>
<ol style="list-style-type: decimal">
<li><p>Each term in the MLR is the result for estimating each slope after controlling for the other two variables (and we will always use this interpretation any time we interpret MLR effects). For example, “corrected for” or “adjusted for” the variability that is explained by the temperature variables.</p></li>
<li><p>Because of multicollinearity in the predictors, the variables might share information that is useful for explaining the variability in the response variable, so the slope coefficients of each predictor get perturbed because the model cannot separate their effects on the response. This issue disappears when the predictors are uncorrelated or even just minimally correlated.</p></li>
</ol>
<p>There are some ramifications of multicollinearity in MLR:</p>
<ol style="list-style-type: decimal">
<li><p>Adding variables to a model might lead to almost no improvement in the overall variability explained by the model.</p></li>
<li><p>Adding variables to a model can cause slope coefficients to change signs as well as magnitudes.</p></li>
<li><p>Adding variables to a model can lead to inflated standard errors for some or all of the coefficients (this is less obvious but is related to the shared information in predictors making it less clear what slope coefficient to use for each variable).</p></li>
<li><p>In extreme cases of multicollinearity, it may even be impossible to obtain any coefficient estimates.</p></li>
</ol>
<p>These seem like pretty serious issues and they are but there are many, many situations where we proceed with MLR even in the presence of potentially correlated predictors. It is likely that you have heard or read about inferences from models that are dealing with this issue – for example, medical studies often report the increased risk of death from some behavior or trait after controlling for sex, age, etc. In many research articles, it is becoming common practice to report the slope for a variable most of interest with it in the model alone (SLR) and in models after adjusting for the other variables that are expected to matter. These types of results are built with MLR or related multiple-predictor models like MLR.</p>
</div>
<div id="section8-2" class="section level2">
<h2><span class="header-section-number">8.2</span> Validity conditions in MLR</h2>
<p>But before we get to oexcited about any results, we should always assess our validity conditions. For MLR, they are similar to those for SLR:</p>
<ul>
<li><p><strong>Quantitative variables condition:</strong></p>
<ul>
<li>The response and all predictors need to be quantitative variables. This condition is relaxed to allow a categorical predictor in two ways in Sections <a href="chapter8.html#section8-9">8.9</a> and <a href="chapter8.html#section8-11">8.11</a>.</li>
</ul></li>
<li><p><strong>Independence of observations:</strong></p>
<ul>
<li><p>This assumption is about the responses – we must assume that they were collected in a fashion so that they can be assumed to be independent. This implies that we also have independent random errors.</p></li>
<li><p>This is not an assumption about the predictor variables!</p></li>
</ul></li>
<li><p><strong>Linearity of relationship (</strong><b><font color='red'>NEW VERSION FOR MLR!</font></b><strong>):</strong></p>
<ul>
<li><p>Linearity is assumed between the response variable and <strong>each</strong> explanatory variable (<span class="math inline">\(y\)</span> and each <span class="math inline">\(x\)</span>).</p></li>
<li><p>We can check this two ways:</p>
<ol style="list-style-type: decimal">
<li><p>Make plots of the response versus each explanatory variable:</p>
<ul>
<li>Only visual evidence of a curving relationship is a problem here. Transformations of individual explanatory variables or the response are possible.</li>
</ul></li>
<li><p>Examine the Residuals vs Fitted plot:</p>
<ul>
<li>When using MLR, curves in the residuals vs. fitted values suggest a missed curving relationship with at least one predictor variable, but it will not be specific as to which one is non-linear. Revisit the scatterplots to identify the source of the issue.</li>
</ul></li>
</ol></li>
</ul></li>
<li><p><strong>Multicollinearity effects checked for:</strong></p>
<ul>
<li><p>Issues here do not mean we cannot proceed with a given model, but it can impact our ability to trust and interpret the estimated terms.</p></li>
<li><p>Check a scatterplot or correlation matrix to assess the potential for shared information in different predictor variables.</p></li>
<li><p>Use the diagnostic measure called a <strong><em>variance inflation factor</em></strong> (<strong><em>VIF</em></strong>) discussed in Section <a href="chapter8.html#section8-5">8.5</a> (we need to develop some ideas first to understand this measure).</p></li>
</ul></li>
<li><p><strong>Equal (constant) variance:</strong></p>
<ul>
<li>Same as before since it pertains to the residuals.</li>
</ul></li>
<li><p><strong>Normality of residuals:</strong></p>
<ul>
<li>Same as before since it pertains to the residuals.</li>
</ul></li>
<li><p><strong>No influential points:</strong></p>
<ul>
<li><p>Leverage is now determined by how unusual a point is for multiple explanatory variables.</p></li>
<li><p>The <strong><em>leverage</em></strong> values in the Residuals vs Leverage plot are scaled to add up to the <em>degrees of freedom (df) used for the model</em> which is the number of explanatory variables (<span class="math inline">\(K\)</span>) plus 1, so <span class="math inline">\(K+1\)</span>.</p></li>
<li><p>The scale of leverages depends on the complexity of the model through the <em>df</em> and the sample size.</p></li>
<li><p>The interpretation is still that the larger the leverage value, the more leverage the point has.</p></li>
<li><p>The mean leverage is always <em>(model used df)/n = (K+1)/n</em> – so focus on the values with above average leverage.</p>
<ul>
<li>For example, with <span class="math inline">\(K=3\)</span> and <span class="math inline">\(n=20\)</span>, the average leverage is <span class="math inline">\(4/20=1/5\)</span>.</li>
</ul></li>
<li><p>High leverage points whose response does not follow the pattern defined by the other observations (now based on patterns for multiple <span class="math inline">\(x\text{&#39;s}\)</span> with the response) will be influential.</p></li>
<li><p>Use the Residual’s vs Leverage plot to identify problematic points. Explore further with Cook’s D continuing to provide a measure of the influence of each observation.</p>
<ul>
<li>The rules and interpretations for Cook’s D are the same as in SLR (over 0.5 is possibly influential and over is definitely influential).</li>
</ul></li>
</ul></li>
</ul>
<p>While not a condition for use of the methods, a note about RA and RS is useful here in considering the scope of inference of any results. To make inferences about a population, we need to have a representative sample. If we have randomly assigned levels of treatment variables(s), then we can make causal inferences to subjects like those that we could have observed. And if we both have a representative sample and randomization, we can make causal inferences for the population. It is possible to randomly assign levels of variable(s) to subjects and still collect additional information from other explanatory (sometimes called <strong><em>control</em></strong>) variables. The causal interpretations would only be associated with the explanatory variables that were randomly assigned even though the model might contain other variables. Their interpretation still involves noting all the variables included in the model, as demonstrated below. It is even possible to include interactions between randomly assigned variables and other variables – like drug dosage and sex of the subjects. In these cases, causal inference could apply to the treatment levels but noting that the impacts differ based on the non-randomly assigned variable.</p>
<p>For the <em>Snow Depth</em> data, the conditions can be assessed as:</p>
<ul>
<li><p><strong>Quantitative variables condition:</strong></p>
<ul>
<li>These are all met.</li>
</ul></li>
<li><p><strong>Independence of observations:</strong></p>
<ul>
<li>The observations are based on a random sample of sites from the population and the sites are spread around the mountains in Montana. Many people would find it to be reasonable to assume that the sites are independent of one another but others would be worried that sites closer together in space might be more similar than they are to far-away observations (this is called <strong><em>spatial correlation</em></strong>). I (Greenwood) have been in a heated discussion with statistics colleagues about whether spatial dependency should be considered or if it is valid to ignore it in this sort of situation. It is certainly possible to be concerned about independence of observations here but it takes more advanced statistical methods to actually assess whether there is spatial dependency in these data and even in those models, the first task would be to fit this sort of model and then explore the results.</li>
</ul></li>
</ul>
<p>We need our diagnostic plots to assess the remaining assumptions. The same code as before will provide diagnostic plots. There is some extra code (<code>par(...)</code>) added to allow us to add labels to the plots to know which model is being displayed since we have so many to discuss here.</p>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>), <span class="dt">oma=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">2</span>,<span class="dv">0</span>))
<span class="kw">plot</span>(m4, <span class="dt">sub.caption=</span><span class="st">&quot;Diagnostics for m4&quot;</span>)</code></pre></div>
<div class="figure"><span id="fig:Figure8-5"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-5-1.png" alt="Diagnostic plots for model m4: \(\text{Snow.Depth}\sim \text{Elevation} + \text{Min.Temp} + \text{Max.Temp}\)" width="672" />
<p class="caption">
Figure 8.5: Diagnostic plots for model m4: <span class="math inline">\(\text{Snow.Depth}\sim \text{Elevation} + \text{Min.Temp} + \text{Max.Temp}\)</span>
</p>
</div>
<ul>
<li><p><strong>Linearity of relationship (</strong><b><font color='red'>NEW VERSION FOR MLR!</font></b><strong>):</strong></p>
<ul>
<li><p>Make plots of the response versus each explanatory variable:</p>
<ul>
<li>In Figure <a href="chapter8.html#fig:Figure8-1">8.1</a>, the plots of each variable versus snow depth do not clearly show any nonlinearity except for a little dip around 7000 feet in the plot vs <em>Elevation</em>.</li>
</ul></li>
<li><p>Examine the Residuals vs Fitted plot in Figure <a href="chapter8.html#fig:Figure8-5">8.5</a>:</p>
<ul>
<li>Generally, there is no clear curvature in the Residuals vs Fitted panel and that would be an acceptable answer. However, there is some pattern in the smoothing line that could suggest a more complicated relationship between at least one predictor and the response. This also resembles the pattern in the <em>Elevation</em> vs. <em>Snow depth</em> panel in Figure <a href="chapter8.html#fig:Figure8-1">8.1</a> so that might be the source of this “problem”. This suggests that there is the potential to do a little bit better but that it is not unreasonable to proceed on with the MLR, ignoring this little wiggle in the diagnostic plot.</li>
</ul></li>
</ul></li>
<li><p><strong>Multicollinearity effects checked for:</strong></p>
<ul>
<li><p>The predictors certainly share information in this application (correlations between -0.67 and -0.91) and multicollinearity looks to be a major concern in being able to understand/separate the impacts of temperatures and elevations on snow depths.</p></li>
<li><p>See Section <a href="chapter8.html#section8-5">8.5</a> for more on this issue in these data.</p></li>
</ul></li>
<li><p><strong>Equal (constant) variance:</strong></p>
<ul>
<li>While there is a little bit more variability in the middle of the fitted values, this is more an artifact of having a smaller data set with a couple of moderate outliers that fell in the same range of fitted values and maybe a little bit of missed curvature. So there is not too much of an issue with this condition.</li>
</ul></li>
<li><p><strong>Normality of residuals:</strong></p>
<ul>
<li>The residuals are quite good in the QQ-plot, showing only a little deviation for observation 9 from a normal distribution and that deviation is extremely minor. Certainly no evidence of a violation of the normality assumption here.</li>
</ul></li>
<li><p><strong>No influential points:</strong></p>
<ul>
<li><p>With <span class="math inline">\(K=3\)</span> predictors and <span class="math inline">\(n=25\)</span> observations, the average leverage is <span class="math inline">\(4/25=0.16\)</span>. This gives us a scale to interpret the leverage values on the x-axis of the lower right panel of our diagnostic plots.</p></li>
<li><p>There are three higher leverage points (leverages over 0.3) with only one being influential (point 9) with Cook’s D close to 1.</p>
<ul>
<li>Note that point 10 had the same leverage but was not influential with Cook’s D less than 0.5.</li>
</ul></li>
<li><p>We can explore both of these points to see how two observations can have the same leverage and different amounts of influence.</p></li>
</ul></li>
</ul>
<p>The two flagged points, observations 9 and 10 in the data set, are for the sites “Northeast Entrance” (to Yellowstone) and “Combination”. We can use the MLR equation to do some prediction for each observation and calculate residuals to see how far the model’s predictions are from the actual observed values for these sites. For the Northeast Entrance, the <em>Max.Temp</em> was 45, the <em>Min.Temp</em> was 28, and the <em>Elevation</em> was 7350 as you can see in this printout of just the two rows of the data set available by referencing rows 9 and 10 in the bracket from <code>snotel2</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">snotel2[<span class="kw">c</span>(<span class="dv">9</span>,<span class="dv">10</span>),]</code></pre></div>
<pre><code>##    ID             Station Max.Temp Min.Temp Elevation Snow.Depth
## 9  18 Northeast Entrance        45       28      7350       11.2
## 10 53        Combination        36       28      5600       14.0</code></pre>
<p>The estimated <em>Snow Depth</em> for the <em>Northeast Entrance</em> site (observation 9) is found using the estimated model with</p>
<p><span class="math display">\[\begin{array}{rl}
\widehat{\text{SnowDepth}}_9 &amp;= -10.51 + 0.0123\text{Elevation}_9 -
0.505\text{MinTemp}_9 - 0.562\text{MaxTemp}_9 \\
&amp; = -10.51 + 0.0123*\boldsymbol{7350} -0.505*\boldsymbol{28} - 
0.562*\boldsymbol{45} \\
&amp; = 40.465 \text{ inches,}
\end{array}\]</span></p>
<p>but the observed snow depth was actually <span class="math inline">\(y_9=11.2\)</span> inches. The observed <strong><em>residual</em></strong> is then</p>
<p><span class="math display">\[e_9=y_9-\hat{y}_9 = 11.2-40.465 = -29.265 \text{ inches.}\]</span></p>
<p>So the model “misses” the snow depth by over 29 inches with the model suggesting over 40 inches of snow but only 11 inches actually being present<a href="#fn72" class="footnoteRef" id="fnref72"><sup>72</sup></a>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="op">-</span><span class="fl">10.51</span> <span class="op">+</span><span class="st"> </span><span class="fl">0.0123</span><span class="op">*</span><span class="dv">7350</span> <span class="op">-</span><span class="st"> </span><span class="fl">0.505</span><span class="op">*</span><span class="dv">28</span> <span class="op">-</span><span class="st"> </span><span class="fl">0.562</span><span class="op">*</span><span class="dv">45</span></code></pre></div>
<pre><code>## [1] 40.465</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="fl">11.2</span> <span class="op">-</span><span class="st"> </span><span class="fl">40.465</span></code></pre></div>
<pre><code>## [1] -29.265</code></pre>
<p>This point is being rated as influential (Cook’s D <span class="math inline">\(\approx\)</span> 1) with a leverage of nearly 0.35 and a standardized residual (y-axis of Residuals vs. Leverage plot) of nearly -3. This suggests that even with this observation impacting/distorting the slope coefficients (that is what <strong><em>influence</em></strong> means), the model is still doing really poorly at fitting this observation. We’ll drop it and re-fit the model in a second to see how the slopes change. First, let’s compare that result to what happened for data point 10 (“Combination”) which was just as high leverage but not identified as influential.</p>
<p>The estimated snow depth for “Combination” is </span></p>
<p><span class="math display">\[\begin{array}{rl}
\widehat{\text{SnowDepth}}_{10} &amp;= -10.51 + 0.0123\text{Elevation}_{10} -
0.505\text{MinTemp}_{10} - 0.562\text{MaxTemp}_{10} \\
&amp; = -10.51 + 0.0123*\boldsymbol{5600} -0.505*\boldsymbol{28} - 
0.562*\boldsymbol{36} \\
&amp; = 23.998 \text{ inches,}
\end{array}\]</span></p>
<p>The observed snow depth here was <span class="math inline">\(y_{10} = 14.0\)</span> inches so the observed residual is then</p>
<p><span class="math display">\[e_{10}=y_{10}-\hat{y}_{10} = 14.0-23.998 = -9.998 \text{ inches.}\]</span></p>
<p>This results in a standardized residual of around -1. This is still a “miss” but not as glaring as the previous result and also is not having a major impact on the model’s estimated slope coefficients based on the small Cook’s D value.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="op">-</span><span class="fl">10.51</span> <span class="op">+</span><span class="st"> </span><span class="fl">0.0123</span><span class="op">*</span><span class="dv">5600</span> <span class="op">-</span><span class="st"> </span><span class="fl">0.505</span><span class="op">*</span><span class="dv">28</span> <span class="op">-</span><span class="st"> </span><span class="fl">0.562</span><span class="op">*</span><span class="dv">36</span></code></pre></div>
<pre><code>## [1] 23.998</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">14</span> <span class="op">-</span><span class="st"> </span><span class="fl">23.998</span></code></pre></div>
<pre><code>## [1] -9.998</code></pre>
<p>Note that any predictions using this model presume that it is trustworthy, but the large Cook’s D on one observation suggests we should consider the model after removing that observation. We can re-run the model without the 9<sup>th</sup> observation using the data set <code>snotel2[-9,]</code>.</p>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m5 &lt;-<span class="st"> </span><span class="kw">lm</span>(Snow.Depth<span class="op">~</span>Elevation<span class="op">+</span>Min.Temp<span class="op">+</span>Max.Temp, <span class="dt">data=</span>snotel2[<span class="op">-</span><span class="dv">9</span>,])
<span class="kw">summary</span>(m5)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Snow.Depth ~ Elevation + Min.Temp + Max.Temp, data = snotel2[-9, 
##     ])
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -29.2918  -4.9757  -0.9146   5.4292  20.4260 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) -1.424e+02  9.210e+01  -1.546  0.13773
## Elevation    2.141e-02  6.101e-03   3.509  0.00221
## Min.Temp     6.722e-01  1.733e+00   0.388  0.70217
## Max.Temp     5.078e-01  6.486e-01   0.783  0.44283
## 
## Residual standard error: 11.29 on 20 degrees of freedom
## Multiple R-squared:  0.7522, Adjusted R-squared:  0.715 
## F-statistic: 20.24 on 3 and 20 DF,  p-value: 2.843e-06</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(<span class="kw">allEffects</span>(m5), <span class="dt">main=</span><span class="st">&quot;MLR model with NE Ent. Removed&quot;</span>)</code></pre></div>
<div class="figure"><span id="fig:Figure8-6"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-6-1.png" alt="Term-plots for the MLR for Snow Depth based on Elevation, Min Temp, and Max Temp with Northeast entrance observation removed from data set (n=24)." width="768" />
<p class="caption">
Figure 8.6: Term-plots for the MLR for Snow Depth based on Elevation, Min Temp, and Max Temp with Northeast entrance observation removed from data set (n=24).
</p>
</div>
<p>The estimated MLR model with <span class="math inline">\(n=24\)</span> after removing the influential “NE Entrance” observation is</p>
<p><span class="math display">\[\widehat{\text{SnowDepth}}_i = -142.4 + 0.0214\text{ Elevation}_i
+0.672\text{ MinTemp}_i +0.508\text{ MaxTemp}_i.\]</span></p>
<p>Something unusual has happened here: there is a positive slope for both temperature terms in Figure <a href="chapter8.html#fig:Figure8-6">8.6</a> that both contradicts reasonable expectations (warmer temperatures are related to higher snow levels?) and our original SLR results. So what happened? First, removing the influential point has drastically changed the slope coefficients (remember that was the definition of an influential point). Second, when there are predictors that share information, the results can be somewhat unexpected for some or all the predictors when they are all in the model together. Note that the <em>Elevation</em> term looks like what we might expect and seems to have a big impact on the predicted <em>Snow Depths</em>. So when the temperature variables are included in the model they might be functioning to explain some differences in sites that the <em>Elevation</em> term could not explain. This is where our “adjusting for” terminology comes into play. The unusual-looking slopes for the temperature effects can be explained by interpreting them as the estimated change in the response for changes in temperature <strong>after we control for the impacts of elevation</strong>. Suppose that <em>Elevation</em> explains most of the variation in <em>Snow Depth</em> except for a few sites where the elevation cannot explain all the variability and the site characteristics happen to show higher temperatures and more snow (or lower temperatures and less snow). This could be because warmer areas might have been hit by a recent snow storm while colder areas might have been missed (this is just one day and subject to spatial and temporal fluctuations in precipitation patterns). Or maybe there is another factor related to having marginally warmer temperatures that are accompanied by more snow (maybe the lower snow sites for each elevation were so steep that they couldn’t hold much snow but were also relatively colder?). Thinking about it this way, the temperature model components could provide useful corrections to what <em>Elevation</em> is providing in an overall model and explain more variability than any of the variables could alone. It is also possible that the temperature variables are not needed in a model with <em>Elevation</em> in it, are just “explaining noise”, and should be removed from the model. Each of the next sections take on various aspects of these issues and eventually lead to a general set of modeling and model selection recommendations to help you work in situations as complicated as this. Exploring the results for this model assumes we trust it and, once again, we need to check diagnostics before getting too focused on any particular results from it.</p>
<p>The Residuals vs. Leverage diagnostic plot in Figure <a href="chapter8.html#fig:Figure8-7">8.7</a> for the model fit to the data set without NE Entrance (now <span class="math inline">\(n=24\)</span>) reveals a new point that is somewhat influential (point 22 in the data set has Cook’s D <span class="math inline">\(\approx\)</span> 0.5). It is for a location called “Bloody <span class="math inline">\(\require{color}\colorbox{black}{Redact.}\)</span>”<a href="#fn73" class="footnoteRef" id="fnref73"><sup>73</sup></a> which has a leverage of nearly 0.2 and a standardized residual of nearly -3. This point did not show up as influential in the original version of the data set with the same model but it is now. It also shows up as a potential outlier. As we did before, we can explore it a bit by comparing the model predicted snow depth to the observed snow depth. The predicted snow depth for this site is</p>
<p><span class="math display">\[\widehat{\text{SnowDepth}}_{22} = -142.4 + 0.0214*\boldsymbol{7550}
+0.672*\boldsymbol{26} +0.508*\boldsymbol{39} = 56.45 \text{ inches.}\]</span></p>
<p>The observed snow depth was 27.2 inches, so the estimated residual is -39.25 inches. Again, this point is potentially influential and an outlier. Additionally, our model contains results that are not what we would have expected <em>a priori</em>, so it is not unreasonable to consider removing this observation to be able to work towards a model that fully trustworthy.</p>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>), <span class="dt">oma=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">2</span>,<span class="dv">0</span>))
<span class="kw">plot</span>(m5, <span class="dt">sub.caption=</span><span class="st">&quot;Diagnostics for m5&quot;</span>)</code></pre></div>
<div class="figure"><span id="fig:Figure8-7"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-7-1.png" alt="Diagnostic plots for MLR for Snow Depth based on Elevation, Min Temp and Max Temp with Northeast entrance observation removed from data set." width="672" />
<p class="caption">
Figure 8.7: Diagnostic plots for MLR for Snow Depth based on Elevation, Min Temp and Max Temp with Northeast entrance observation removed from data set.
</p>
</div>
<p>This worry-some observation is located in the 22<sup>nd</sup> row of the original data set:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">snotel2[<span class="dv">22</span>,]</code></pre></div>
<pre><code>##    ID           Station Max.Temp Min.Temp Elevation Snow.Depth
## 22 36 Bloody [Redact.]        39       26      7550       27.2</code></pre>
<p>With the removal of both the “Northeast Entrance” and “Bloody <span class="math inline">\(\require{color}\colorbox{black}{Redact.}\)</span>” sites, there are <span class="math inline">\(n=23\)</span> observations remaining. This model (<code>m6</code>) seems to contain residual diagnostics (Figure <a href="chapter8.html#fig:Figure8-8">8.8</a>) that are finally generally reasonable.</p>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m6 &lt;-<span class="st"> </span><span class="kw">lm</span>(Snow.Depth<span class="op">~</span>Elevation<span class="op">+</span>Min.Temp<span class="op">+</span>Max.Temp, <span class="dt">data=</span>snotel2[<span class="op">-</span><span class="kw">c</span>(<span class="dv">9</span>,<span class="dv">22</span>),])
<span class="kw">summary</span>(m6)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Snow.Depth ~ Elevation + Min.Temp + Max.Temp, data = snotel2[-c(9, 
##     22), ])
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -14.878  -4.486   0.024   3.996  20.728 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) -2.133e+02  7.458e+01  -2.859   0.0100
## Elevation    2.686e-02  4.997e-03   5.374 3.47e-05
## Min.Temp     9.843e-01  1.359e+00   0.724   0.4776
## Max.Temp     1.243e+00  5.452e-01   2.280   0.0343
## 
## Residual standard error: 8.832 on 19 degrees of freedom
## Multiple R-squared:  0.8535, Adjusted R-squared:  0.8304 
## F-statistic:  36.9 on 3 and 19 DF,  p-value: 4.003e-08</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>), <span class="dt">oma=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">2</span>,<span class="dv">0</span>))
<span class="kw">plot</span>(m6, <span class="dt">sub.caption=</span><span class="st">&quot;Diagnostics for m6&quot;</span>)</code></pre></div>
<div class="figure"><span id="fig:Figure8-8"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-8-1.png" alt="Diagnostic plots for MLR for Snow Depth based on Elevation, Min Temp and Max Temp with two observations removed (\(n=23\))." width="672" />
<p class="caption">
Figure 8.8: Diagnostic plots for MLR for Snow Depth based on Elevation, Min Temp and Max Temp with two observations removed (<span class="math inline">\(n=23\)</span>).
</p>
</div>
<p>It is hard to suggest that there any curvature issues and the slight variation in the Scale-Location plot is mostly due to few observations with fitted values around 30 happening to be well approximated by the model. The normality assumption is generally reasonable and no points seem to be overly influential on this model (finally!).</p>
<p>The term-plots (Figure <a href="chapter8.html#fig:Figure8-9">8.9</a>) show that the temperature slopes are both positive although in this model <em>Max.Temp</em> seems to be more “important” than <em>Min.Temp</em>. We have ruled out individual influential points as the source of un-expected directions in slope coefficients and the more likely issue is multicollinearity – in a model that includes <em>Elevation</em>, the temperature effects may be positive, again acting with the <em>Elevation</em> term to generate the best possible predictions of the observed responses. Throughout this discussion, we have mainly focused on the slope coefficients and diagnostics. We have other tools in MLR to more quantitatively assess and compare different regression models that are considered in the next sections.</p>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(<span class="kw">allEffects</span>(m6), <span class="dt">main=</span><span class="st">&quot;MLR model with n=23&quot;</span>)</code></pre></div>
<div class="figure"><span id="fig:Figure8-9"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-9-1.png" alt="Term-plots for the MLR for Snow Depth based on Elevation, Min Temp and Max Temp with two observations removed." width="672" />
<p class="caption">
Figure 8.9: Term-plots for the MLR for Snow Depth based on Elevation, Min Temp and Max Temp with two observations removed.
</p>
</div>
</div>
<div id="section8-3" class="section level2">
<h2><span class="header-section-number">8.3</span> Interpretation of MLR terms</h2>
<p>Since these results (finally) do not contain any highly influential points, we can formally discuss interpretations of the slope coefficients and how the term-plots (Figure <a href="chapter8.html#fig:Figure8-9">8.9</a>) aid our interpretations. Term-plots in MLR are constructed by holding all the other variables at their mean and generating predictions and 95% CIs for the mean response across the levels of observed values for each predictor variable. This idea also helps us to work towards interpretations of each term in an MLR model. For example, for <em>Elevation</em>, the term-plot starts at an elevation around 5000 feet and ends at an elevation around 8000 feet. To generate that line and CIs for the mean snow depth at different elevations, the MLR model of</p>
<p><span class="math display">\[\widehat{\text{SnowDepth}}_i = -213.3 + 0.0269\text{ Elevation}_i
+0.984\text{ MinTemp}_i +1.243\text{ MaxTemp}_i\]</span></p>
<p>is used, but we need to have “something” to put in for the two temperature variables to predict <em>Snow Depth</em> for different <em>Elevations</em>. The typical convention is to hold the “other” variables at their means to generate these plots. This tactic also provides a way of interpreting each slope coefficient. Specifically, we can interpret the <em>Elevation</em> slope as: For a 1 foot increase in <em>Elevation</em>, we expect the mean <em>Snow Depth</em> to increase by 0.0269 inches, holding the minimum and maximum temperatures constant. More generally, the <strong><em>slope interpretation in an MLR</em></strong> is:</p>
<ul>
<li>For a 1 <strong><em>[units of <span class="math inline">\(\boldsymbol{x_k}\)</span>]</em></strong> increase in <span class="math inline">\(\boldsymbol{x_k}\)</span>, we expect the mean of <span class="math inline">\(\boldsymbol{y}\)</span> to change by <span class="math inline">\(\boldsymbol{b_k}\)</span> <strong><em>[units of y]</em></strong>, after controlling for <strong>[list of other explanatory variables in model]</strong>.</li>
</ul>
<p>To make this more concrete, we can recreate some points in the Elevation term-plot. To do this, we first need the mean of the “other” predictors, <em>Min.Temp</em> and <em>Max.Temp</em>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(snotel2[<span class="op">-</span><span class="kw">c</span>(<span class="dv">9</span>,<span class="dv">22</span>),]<span class="op">$</span>Min.Temp)</code></pre></div>
<pre><code>## [1] 27.82609</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(snotel2[<span class="op">-</span><span class="kw">c</span>(<span class="dv">9</span>,<span class="dv">22</span>),]<span class="op">$</span>Max.Temp)</code></pre></div>
<pre><code>## [1] 36.3913</code></pre>
<p>We can put these values into the MLR equation and simplify the equation, to an equation that is just in terms of just <em>Elevation</em> given that we are holding <em>Min.Temp</em> and <em>Max.Temp</em> at their means:</p>
<p><span class="math display">\[\begin{array}{rl}
\widehat{\text{SnowDepth}}_i &amp;= -213.3 + 0.0269\text{ Elevation}_i
+0.984*\boldsymbol{27.826} +1.243*\boldsymbol{36.391} \\
&amp;= -213.3 + 0.0269\text{ Elevation}_i + 27.38 + 45.23 \\
&amp;= \boldsymbol{-140.69 + 0.0269}\textbf{ Elevation}_\boldsymbol{i}.
\end{array}\]</span></p>
<p>So at the means on the two temperature variables, the model looks like an SLR with an estimated y-intercept of -140.69 (mean <em>Snow Depth</em> for <em>Elevation</em> of 0 if temperatures are at their means) and an estimated slope of 0.0269. Then we can plot the predicted changes in <span class="math inline">\(y\)</span> across all the values of the predictor variable (<em>Elevation</em>) while holding the other variables constant. To generate the needed values to define a line, we can plug various <em>Elevation</em> values into the simplified equation:</p>
<ul>
<li><p>For an elevation of 5000 at the average temperatures, we predict a mean snow depth of <span class="math inline">\(-140.69 + 0.0269*5000 = -6.19\)</span> inches.</p></li>
<li><p>For an elevation of 6000 at the average temperatures, we predict a mean snow depth of <span class="math inline">\(-140.69 + 0.0269*6000 = 20.71\)</span> inches.</p></li>
<li><p>For an elevation of 8000 at the average temperatures, we predict a mean snow depth of <span class="math inline">\(-140.69 + 0.0269*8000 = 74.51\)</span> inches.</p></li>
</ul>
<p>We can plot this information (Figure <a href="chapter8.html#fig:Figure8-10">8.10</a>) using the <code>plot</code> function to show the points we calculated and the <code>lines</code> function to add a line that connects the dots. In the <code>plot</code> function, we used the <code>ylim=...</code> option to make the scaling on the y-axis match the previous term-plot’s scaling.</p>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))
<span class="co">#Making own effect plot:</span>
elevs &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">5000</span>,<span class="dv">6000</span>,<span class="dv">8000</span>)
snowdepths &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="op">-</span><span class="fl">6.19</span>,<span class="fl">20.71</span>,<span class="fl">74.51</span>)
<span class="kw">plot</span>(snowdepths<span class="op">~</span>elevs, <span class="dt">ylim=</span><span class="kw">c</span>(<span class="op">-</span><span class="dv">20</span>,<span class="dv">90</span>), <span class="dt">cex=</span><span class="dv">2</span>, <span class="dt">col=</span><span class="st">&quot;blue&quot;</span>, <span class="dt">pch=</span><span class="dv">16</span>,
     <span class="dt">main=</span><span class="st">&quot;Effect plot of elevation by hand&quot;</span>)
<span class="kw">lines</span>(snowdepths<span class="op">~</span>elevs, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lwd=</span><span class="dv">2</span>)</code></pre></div>
<div class="figure"><span id="fig:Figure8-10"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-10-1.png" alt="Term-plot for Elevation “by-hand”, holding temperature variables constant at their means." width="672" />
<p class="caption">
Figure 8.10: Term-plot for Elevation “by-hand”, holding temperature variables constant at their means.
</p>
</div>
<p>Note that we only needed 2 points to define the line but need a denser grid of elevations if we want to add the 95% CIs for the true mean snow depth across the different elevations since they vary as a function of the distance from the mean of the explanatory variables.</p>
<p>To get the associated 95% CIs, we could return to using the <code>predict</code> function for the MLR, again holding the temperatures at their mean values. The <code>predict</code> function is sensitive and needs the same variable names as used in the original model fitting to work. First we create a “new” data set using the <code>seq</code> function to generate the desired grid of elevations and the <code>rep</code> function<a href="#fn74" class="footnoteRef" id="fnref74"><sup>74</sup></a> to repeat the means of the temperatures for each of elevation values we need to make the plot. The code creates a specific version of the predictor variables to force the <code>predict</code> function to provide fitted values and CIs across different elevations with temperatures held constant that is stored in <code>newdata1</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">elevs &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dt">from=</span><span class="dv">5000</span>, <span class="dt">to=</span><span class="dv">8000</span>, <span class="dt">length.out=</span><span class="dv">30</span>)
newdata1 &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">Elevation=</span>elevs, <span class="dt">Min.Temp=</span><span class="kw">rep</span>(<span class="fl">27.826</span>,<span class="dv">30</span>),
                       <span class="dt">Max.Temp=</span><span class="kw">rep</span>(<span class="fl">36.3913</span>,<span class="dv">30</span>))
newdata1</code></pre></div>
<pre><code>##    Elevation Min.Temp Max.Temp
## 1   5000.000   27.826  36.3913
## 2   5103.448   27.826  36.3913
## 3   5206.897   27.826  36.3913
## 4   5310.345   27.826  36.3913
## 5   5413.793   27.826  36.3913
## 6   5517.241   27.826  36.3913
## 7   5620.690   27.826  36.3913
## 8   5724.138   27.826  36.3913
## 9   5827.586   27.826  36.3913
## 10  5931.034   27.826  36.3913
## 11  6034.483   27.826  36.3913
## 12  6137.931   27.826  36.3913
## 13  6241.379   27.826  36.3913
## 14  6344.828   27.826  36.3913
## 15  6448.276   27.826  36.3913
## 16  6551.724   27.826  36.3913
## 17  6655.172   27.826  36.3913
## 18  6758.621   27.826  36.3913
## 19  6862.069   27.826  36.3913
## 20  6965.517   27.826  36.3913
## 21  7068.966   27.826  36.3913
## 22  7172.414   27.826  36.3913
## 23  7275.862   27.826  36.3913
## 24  7379.310   27.826  36.3913
## 25  7482.759   27.826  36.3913
## 26  7586.207   27.826  36.3913
## 27  7689.655   27.826  36.3913
## 28  7793.103   27.826  36.3913
## 29  7896.552   27.826  36.3913
## 30  8000.000   27.826  36.3913</code></pre>
<p>The predicted snow depths along with 95% confidence intervals for the mean, holding temperatures at their means, are:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">predict</span>(m6, <span class="dt">newdata=</span>newdata1, <span class="dt">interval=</span><span class="st">&quot;confidence&quot;</span>)</code></pre></div>
<pre><code>##           fit        lwr      upr
## 1  -6.3680312 -24.913607 12.17754
## 2  -3.5898846 -21.078518 13.89875
## 3  -0.8117379 -17.246692 15.62322
## 4   1.9664088 -13.418801 17.35162
## 5   4.7445555  -9.595708 19.08482
## 6   7.5227022  -5.778543 20.82395
## 7  10.3008489  -1.968814 22.57051
## 8  13.0789956   1.831433 24.32656
## 9  15.8571423   5.619359 26.09493
## 10 18.6352890   9.390924 27.87965
## 11 21.4134357  13.140233 29.68664
## 12 24.1915824  16.858439 31.52473
## 13 26.9697291  20.531902 33.40756
## 14 29.7478758  24.139153 35.35660
## 15 32.5260225  27.646326 37.40572
## 16 35.3041692  31.002236 39.60610
## 17 38.0823159  34.139812 42.02482
## 18 40.8604626  36.997617 44.72331
## 19 43.6386092  39.559231 47.71799
## 20 46.4167559  41.866745 50.96677
## 21 49.1949026  43.988619 54.40119
## 22 51.9730493  45.985587 57.96051
## 23 54.7511960  47.900244 61.60215
## 24 57.5293427  49.759987 65.29870
## 25 60.3074894  51.582137 69.03284
## 26 63.0856361  53.377796 72.79348
## 27 65.8637828  55.154251 76.57331
## 28 68.6419295  56.916422 80.36744
## 29 71.4200762  58.667725 84.17243
## 30 74.1982229  60.410585 87.98586</code></pre>
<p>So we could do this with any model <strong>for each predictor</strong> variable to create term-plots, or we can just use the <code>allEffects</code> function to do this for us. This exercise is useful to complete once to understand what is being displayed in term-plots but using the <code>allEffects</code> function makes getting these plots much easier.</p>
<p>There are two other model components of possible interest in this model. The slope of 0.984 for <em>Min.Temp</em> suggests that for a 1<span class="math inline">\(^\circ F\)</span> increase in <em>Minimum Temperature</em>, we expect a 0.984 inch change in the mean <em>Snow Depth</em>, after controlling for <em>Elevation</em> and <em>Max.Temp</em> at the sites. Similarly, the slope of 1.243 for the <em>Max.Temp</em> suggests that for a 1<span class="math inline">\(^\circ F\)</span> increase in <em>Maximum Temperature</em>, we expect a 1.243 inch change in the mean <em>Snow Depth</em>, holding <em>Elevation</em> and <em>Min.Temp</em>constant. Note that there are a variety of ways to note that each term in an MLR is only a particular value given the other variables in the model. We can use words such as “holding the other variables constant” or “after adjusting for the other variables” or “controlling for the other variables”. The main point is to find words that reflect that this single slope coefficient might be different if we had a different overall model and the only way to interpret it is conditional on the other model components.</p>
<p>Term-plots have a few general uses to enhance our regular slope interpretations. They can help us the model predicts over the range of each observed <span class="math inline">\(x\)</span>. This can help you to get a sense of the “practical” importance of each term. Additionally, the term-plots show 95% confidence intervals for the mean response across the range of each variable, holding the other variables at their means. These intervals can be useful for assessing the precision in the estimated mean at different values of each predictor. However, note that you should not use these plots for deciding whether the term should be retained in the model – we have other tools for making that assessment. And one last note about term-plots – they do not mean that the relationships are really linear between the predictor and response variable being displayed. The model <strong>forces</strong> the relationship to be linear even if that is not the real functional form. <strong>Term-plots are not diagnostics for the model, they are summaries of the model you assumed was correct!</strong> Any time we do linear regression, all of our inferences are contingent upon the model we chose. We know our model is not perfect, but we hope that it helps us learn something about our research question(s).</p>
</div>
<div id="section8-4" class="section level2">
<h2><span class="header-section-number">8.4</span> Comparing multiple regression models</h2>
<p>With more than one variable, we now have many potential models that we could consider. We could include only one of the predictors, all of them, or combinations of sets of the variables. For example, maybe the model that includes <em>Elevation</em> does not “need” both <em>Min.Temp</em>and <em>Max.Temp</em>? Or maybe the model isn’t improved over an SLR with just <em>Elevation</em> as a predictor. Or maybe none of the predictors are “useful”? In this section, we discuss some general model comparison issues and a metric that can be used to pick among a suite of different models (often called a set of <strong><em>candidate models</em></strong> to reflect that they are all potentially interesting and we need to compare them and possibly pick one).</p>
<p>It is certainly possible the researchers may have an <em>a priori</em> reason to only consider a single model. For example, in a designed experiment where combinations of, say, three different predictors are randomly assigned, the initial model with all three predictors may be sufficient to address all the research questions of interest. One advantage in these situations is that the variable combinations can be created to prevent multicollinearity among the predictors and avoid that complication in interpretations. However, this is more the exception than the rule. Usually, there are competing predictors or questions about whether some predictors matter more than others. This type of research always introduces the potential for multicollinearity to complicate the interpretation of each predictor in the presence of others. Because of this, multiple models are often considered, where “unimportant” variables are dropped from the model. The assessment of “importance” using p-values will be discussed in Section <a href="chapter8.html#section8-6">8.6</a>, but for now we will consider other reasons to pick one model over another.</p>
<p>There are some general reasons to choose a particular model:</p>
<ol style="list-style-type: decimal">
<li><p>Diagnostics are better with one model compared to others.</p></li>
<li><p>One model predicts/explains the responses better than the others (<span class="math inline">\(\boldsymbol{R}^2\)</span>)).</p></li>
<li><p><em>a priori</em> reasons to “use” a particular model, for example in a designed experiment or it includes variable(s) whose slopes need to be estimated to find interesting results (even if the variables are not “important” in the model).</p></li>
<li><p>Model selection “criteria” suggest one model is better than the others<a href="#fn75" class="footnoteRef" id="fnref75"><sup>75</sup></a>.</p></li>
</ol>
<p>It is OK to consider multiple reasons to select a model but it is dangerous to “shop” for a model across many possible models – a practice which is sometimes called <strong><em>data-dredging</em></strong> and leads to a high chance of spurious results from a single model that is usually reported based on this type of exploration. Just like in other discussions of multiple testing issues previously, if you explore many versions of a model, maybe only keeping the best ones, this is very different from picking one model (and tests) <em>a priori</em> and just exploring that result.</p>
<p>As in SLR, we can use the <span class="math inline">\(\boldsymbol{R}^2\)</span> (the <strong><em>coefficient of determination</em></strong>) to measure the percentage of the variation in the response variable that the model explains. In MLR, it is important to remember that <span class="math inline">\(\boldsymbol{R}^2\)</span> is now an overall measure for the model and not specific to a single variable. It is comparable to other models including those fit with only a single predictor (SLR). So to meet criterion (2), we could simply find the model with the largest <span class="math inline">\(\boldsymbol{R}^2\)</span> value, finding the model that explains the most variation in the responses. Unfortunately for this idea, when you add more “stuff” to a regression model (even “unimportant” predictors), the <span class="math inline">\(\boldsymbol{R}^2\)</span> will always go up. This can be seen by considering</p>
<p><span class="math display">\[R^2 = \frac{\text{SS}_{\text{regression}}}{\text{SS}_{\text{total}}}\ 
\text{ where }\  \text{SS}_{\text{regression}} = \text{SS}_{\text{total}}
- \text{SS}_{\text{error}}\ 
\text{ and }\  \text{SS}_{\text{error}} = \Sigma(y-\hat{y})^2.\]</span></p>
<p>Because adding extra variables to a linear model will only make the fitted values better, not worse, the <span class="math inline">\(\text{SS}_{\text{error}}\)</span> will always go down if more predictors are added to the model. If <span class="math inline">\(\text{SS}_{\text{error}}\)</span> goes down and <span class="math inline">\(\text{SS}_{\text{total}}\)</span> is fixed, then adding extra variables will always increase <span class="math inline">\(\text{SS}_{\text{regression}}\)</span> and, thus, increase <span class="math inline">\(\boldsymbol{R}^2\)</span>. This means that <span class="math inline">\(\boldsymbol{R}^2\)</span> is only useful for selecting models when you are picking between two models of the same size (same number of predictors). So we mainly use it as a summary of model quality once we pick a model, not a method of picking among a set of candidate models. Remember that <span class="math inline">\(\boldsymbol{R}^2\)</span> continues to have the property of being between 0 and 1 (or 0% and 100%) and that value refers to the <strong>proportion (percentage) of variation in the response explained by the model</strong>, whether we are using it for SLR or MLR.</p>
<p>However, there is an adjustment to the <span class="math inline">\(\boldsymbol{R}^2\)</span> measure that makes it useful for selecting among models. The measure is called the <strong><em>adjusted</em></strong> <span class="math inline">\(\boldsymbol{R}^2\)</span>. The <span class="math inline">\(\boldsymbol{R}^2_{\text{adjusted}}\)</span> measure adds a penalty for adding more variables to the model, providing the potential for this measure to decrease if the extra variables do not really benefit the model. The measure is calculated as</p>
<p><span class="math display">\[R^2_{\text{adjusted}} = 1 - 
\frac{\text{SS}_{\text{error}}/df_{\text{error}}}{\text{SS}_{\text{total}}/(N-1)}
= 1 - \frac{\text{MS}_{\text{error}}}{\text{MS}_{\text{total}}},\]</span></p>
<p>which incorporates the <em>degrees of freedom</em> for the model via the error <em>degrees of freedom</em> which go down as the model complexity increases. This adjustment means that just adding extra useless variables (variables that do not explain very much extra variation) do not increase this measure. That makes this measure useful for model selection since it can help us to stop adding unimportant variables and find a “good” model among a set of candidates. Like the regular <span class="math inline">\(\boldsymbol{R}^2\)</span>, larger values are better. The downside to <span class="math inline">\(\boldsymbol{R}^2_{\text{adjusted}}\)</span> is that it <strong>is no longer a percentage of variation in the response that is explained by the model</strong>; it can be less than 0 and so has no interpretable scale. It is just “larger is better”. It provides one method for building a model (different from using p-values to drop unimportant variables as discussed below), by fitting a set of candidate models containing different variables and then <strong>picking the model with the largest</strong> <span class="math inline">\(\boldsymbol{R}^2_{\text{adjusted}}\)</span>. You will want to interpret this new measure on a percentage scale, but do not do that. It is a just a measure to help you pick a model and that is all it is!</p>
<p>One other caveat in model comparison is worth mentioning: make sure you are comparing models for the same responses. That may sound trivial and usually it is. But when there are missing values in the data set, especially on some explanatory variables and not others, it is important to be careful that the <span class="math inline">\(y\text{&#39;s}\)</span> do not change between models you are comparing. This relates to our <em>Snow Depth</em> modeling because responses were being removed due to their influential nature. We can’t compare <span class="math inline">\(\boldsymbol{R}^2\)</span> or <span class="math inline">\(\boldsymbol{R}^2_{\text{adjusted}}\)</span> for <span class="math inline">\(n=25\)</span> to a model when <span class="math inline">\(n=23\)</span> – it isn’t a fair comparison on either measure since they based on the total variability which is changing as the responses used change.</p>
<p>In the MLR (or SLR) model summaries, both the <span class="math inline">\(\boldsymbol{R}^2\)</span> and <span class="math inline">\(\boldsymbol{R}^2_{\text{adjusted}}\)</span> are available. Make sure you are able to pick out the correct one. For the reduced data set (<span class="math inline">\(n=23\)</span>) <em>Snow Depth</em> models, the pertinent part of the model summary for the model with all three predictors is:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m6 &lt;-<span class="st"> </span><span class="kw">lm</span>(Snow.Depth<span class="op">~</span>Elevation<span class="op">+</span>Min.Temp<span class="op">+</span>Max.Temp, <span class="dt">data=</span>snotel2[<span class="op">-</span><span class="kw">c</span>(<span class="dv">9</span>,<span class="dv">22</span>),])
<span class="kw">summary</span>(m6)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Snow.Depth ~ Elevation + Min.Temp + Max.Temp, data = snotel2[-c(9, 
##     22), ])
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -14.878  -4.486   0.024   3.996  20.728 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) -2.133e+02  7.458e+01  -2.859   0.0100
## Elevation    2.686e-02  4.997e-03   5.374 3.47e-05
## Min.Temp     9.843e-01  1.359e+00   0.724   0.4776
## Max.Temp     1.243e+00  5.452e-01   2.280   0.0343
## 
## Residual standard error: 8.832 on 19 degrees of freedom
## Multiple R-squared:  0.8535, Adjusted R-squared:  0.8304 
## F-statistic:  36.9 on 3 and 19 DF,  p-value: 4.003e-08</code></pre>
<p>There is a value for <span class="math inline">\(\large{\textbf{Multiple R-Squared}} \text{ of } 0.8535\)</span>, this is the <span class="math inline">\(\boldsymbol{R}^2\)</span> value and suggests that the model with <em>Elevation</em>, <em>Min</em> and <em>Max</em> temperatures explains 85.4% of the variation in <em>Snow Depth</em>. The <span class="math inline">\(\boldsymbol{R}^2_{\text{adjusted}}\)</span> is 0.8304 and is available further to the right labeled as <span class="math inline">\(\color{red}{\large{\textbf{Adjusted R-Squared}}}\)</span>. We repeated this for a suite of different models for this same <span class="math inline">\(n=23\)</span> data set and found the following results in Table <a href="chapter8.html#tab:Table8-1">8.1</a>. The top <span class="math inline">\(\boldsymbol{R}^2_{\text{adjusted}}\)</span> model is the model with <em>Elevation</em> and <em>Max.Temp</em>, which beats out the model with all three variables on <span class="math inline">\(\boldsymbol{R}^2_{\text{adjusted}}\)</span>. Note that the top <span class="math inline">\(R^2\)</span> model is the model with three predictors, but the most complicated model will always have that characteristic.</p>

<table>
<caption><span id="tab:Table8-1">Table 8.1: </span>Model comparisons for Snow Depth data, sorted by model complexity.</caption>
<thead>
<tr class="header">
<th align="left">Model</th>
<th align="center"><span class="math inline">\(\boldsymbol{K}\)</span></th>
<th align="right"><span class="math inline">\(\boldsymbol{R^2}\)</span></th>
<th align="right"><span class="math inline">\(\boldsymbol{R^2_{\text{adjusted}}}\)</span></th>
<th align="center"><span class="math inline">\(\boldsymbol{R^2_{\text{adjusted}}}\)</span> Rank</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">SD <span class="math inline">\(\sim\)</span> Elevation</td>
<td align="center">1</td>
<td align="right">0.8087</td>
<td align="right">0.7996</td>
<td align="center">3</td>
</tr>
<tr class="even">
<td align="left">SD <span class="math inline">\(\sim\)</span> Min.Temp</td>
<td align="center">1</td>
<td align="right">0.6283</td>
<td align="right">0.6106</td>
<td align="center">5</td>
</tr>
<tr class="odd">
<td align="left">SD <span class="math inline">\(\sim\)</span> Max.Temp</td>
<td align="center">1</td>
<td align="right">0.4131</td>
<td align="right">0.3852</td>
<td align="center">7</td>
</tr>
<tr class="even">
<td align="left">SD <span class="math inline">\(\sim\)</span> Elevation + Min.Temp</td>
<td align="center">2</td>
<td align="right">0.8134</td>
<td align="right">0.7948</td>
<td align="center">4</td>
</tr>
<tr class="odd">
<td align="left">SD <span class="math inline">\(\sim\)</span> Elevation + Max.Temp</td>
<td align="center">2</td>
<td align="right">0.8495</td>
<td align="right">0.8344</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="left">SD <span class="math inline">\(\sim\)</span> Min.Temp + Max.Temp</td>
<td align="center">2</td>
<td align="right">0.6308</td>
<td align="right">0.5939</td>
<td align="center">6</td>
</tr>
<tr class="odd">
<td align="left">SD <span class="math inline">\(\sim\)</span> Elevation + Min.Temp + Max.Temp</td>
<td align="center">3</td>
<td align="right">0.8535</td>
<td align="right">0.8304</td>
<td align="center">2</td>
</tr>
</tbody>
</table>
<p>The top model with <em>Elevation</em> and <em>Max.Temp</em> has an <span class="math inline">\(\boldsymbol{R}^2\)</span> of 0.8495, so we can say that the model with <em>Elevation</em> and <em>Maximum Temperature</em> explains 84.95% percent of the variation in <em>Snow Depth</em> and also that this model was selected based on the <span class="math inline">\(\boldsymbol{R}^2_{\text{adjusted}}\)</span>. One of the important features of <span class="math inline">\(\boldsymbol{R}^2_{\text{adjusted}}\)</span> available in this example – adding variables often does not always increase its value even though <span class="math inline">\(\boldsymbol{R}^2\)</span> does increase with <strong>any</strong> addition. In Section <a href="chapter8.html#section8-13">8.13</a> we consider a competitor for this model selection criterion that may “work” a bit better and be extendable into more complicated modeling situations; that measure is called the <strong><em>AIC</em></strong>.</p>
</div>
<div id="section8-5" class="section level2">
<h2><span class="header-section-number">8.5</span> General recommendations for MLR interpretations and VIFs</h2>
<p>There are some important issues to remember<a href="#fn76" class="footnoteRef" id="fnref76"><sup>76</sup></a> when interpreting regression models that can result in common mistakes.</p>
<ul>
<li><p><strong>Don’t claim to “hold everything constant” for a single individual</strong>:</p>
<p>Mathematically this is a correct interpretation of the MLR model but it is rarely the case that we could have this occur in real applications. Is it possible to increase the <em>Elevation</em> while holding the <em>Max.Temp</em> constant? We discussed making term-plots doing exactly this – holding the other variables constant at their means. If we interpret each slope coefficient in an MLR conditionally then we can craft interpretations such as: For locations that have a <em>Max.Temp </em> of, say, <span class="math inline">\(45^\circ F\)</span> and <em>Min.Temp</em> of, say, <span class="math inline">\(30^\circ F\)</span>, a 1 foot increase in <em>Elevation</em> tends to be associated with a 0.0268 inch increase in <em>Snow Depth</em> on average. This does not try to imply that we can actually make that sort of change but that given those other variables, the change for that variable is a certain magnitude.</p></li>
<li><p><strong>Don’t interpret the regression results causally (or casually?)…</strong></p>
<p>Unless you are analyzing the results of a designed experiment (where the levels of the explanatory variable(s) were randomly assigned) you cannot state that a change in that <span class="math inline">\(x\)</span> <strong>causes</strong> a change in <span class="math inline">\(y\)</span>, especially for a given individual. The multicollinearity in predictors makes it especially difficult to put too much emphasis on a single slope coefficient because it may be corrupted/modified by the other variables being in the model. In observational studies, there are also all the potential lurking variables that we did not measure or even confounding variables that we did measure but can’t disentangle from the variable used in a particular model. While we do have a complicated mathematical model relating various <span class="math inline">\(x\text{&#39;s}\)</span> to the response, do not lose that fundamental focus on causal vs non-causal inferences based on the design of the study.</p></li>
<li><p><strong>Be cautious about doing prediction in MLR – you might be doing extrapolation!</strong></p>
<p>It is harder to know if you are doing extrapolation in MLR since you could be in a region of the <span class="math inline">\(x\text{&#39;s}\)</span> that no observations were obtained. Suppose we want to predict the <em>Snow Depth</em> for an <em>Elevation</em> of 6000 and <em>Max.Temp</em> of 30. Is this extrapolation based on Figure <a href="chapter8.html#fig:Figure8-11">8.11</a>? In other words, can you find any observations “nearby” in the plot of the two variables together? What about an <em>Elevation</em> of 6000 and a <em>Max.Temp</em> of 40? The first prediction is in a different proximity to observations than the second one… In situations with more than two explanatory variables it becomes even more challenging to know whether you are doing extrapolation and the problem grows as the number of dimensions to search increases… In fact, in complicated MLR models we typically do not know whether there are observations “nearby” if we are doing predictions for unobserved combinations of our predictors. Note that Figure <a href="chapter8.html#fig:Figure8-11">8.11</a> also reinforces our potential collinearity problem between <em>Elevation</em> and <em>Max.Temp</em> with higher elevations being strongly associated with lower temperatures.</p>

<div class="figure"><span id="fig:Figure8-11"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-11-1.png" alt="Scatterplot of observed Elevations and Maximum Temperatures for SNOTEL data." width="672" />
<p class="caption">
Figure 8.11: Scatterplot of observed Elevations and Maximum Temperatures for SNOTEL data.
</p>
</div></li>
<li><p><strong>Don’t think that the sign of a coefficient is special…</strong></p>
<p>Adding other variables into the MLR models can cause a switch in the coefficients or change their magnitude or make them go from “important” to “unimportant” without changing the slope too much. This is related to the conditionality of the relationships being estimated in MLR and the potential for sharing of information in the predictors when it is present.</p></li>
<li><p><strong>Multicollinearity in MLR models:</strong></p>
<p>When explanatory variables are not independent (related) to one another, then including one variable will have an impact on the other variable. Consider the correlations among the predictors in the SNOTEL data set or visually displayed in Figure <a href="#fig:Figure8-12"><strong>??</strong></a>:</p>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">require</span>(corrplot)
<span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>), <span class="dt">oma=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">0</span>))
<span class="kw">corrplot.mixed</span>(<span class="kw">cor</span>(snotel2[<span class="op">-</span><span class="kw">c</span>(<span class="dv">9</span>,<span class="dv">22</span>),<span class="dv">3</span><span class="op">:</span><span class="dv">6</span>]), <span class="dt">col=</span><span class="kw">c</span>(<span class="st">&quot;black&quot;</span>, <span class="st">&quot;orange&quot;</span>))</code></pre></div>
<p><img src="08-multipleLinearRegression_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">round</span>(<span class="kw">cor</span>(snotel2[<span class="op">-</span><span class="kw">c</span>(<span class="dv">9</span>,<span class="dv">22</span>),<span class="dv">3</span><span class="op">:</span><span class="dv">6</span>]),<span class="dv">2</span>)</code></pre></div>
<pre><code>##            Max.Temp Min.Temp Elevation Snow.Depth
## Max.Temp       1.00     0.77     -0.84      -0.64
## Min.Temp       0.77     1.00     -0.91      -0.79
## Elevation     -0.84    -0.91      1.00       0.90
## Snow.Depth    -0.64    -0.79      0.90       1.00</code></pre>
<p>The predictors all share at least moderately strong linear relationships. For example, the <span class="math inline">\(\boldsymbol{r}=-0.91\)</span> between <em>Min.Temp</em> and <em>Elevation</em> suggests that they contain very similar information and that extends to other pairs of variables as well. When variables share information, their addition to models may not improve the performance of the model and actually can make the estimated coefficients <strong><em>unstable</em></strong>, creating uncertainty in the correct coefficients because of the shared information. It seems that <em>Elevation</em> is related to <em>Snow Depth</em> but maybe it is because it has lower <em>Minimum Temperatures</em>? So you might wonder how we can find the “correct” slopes when they are sharing information in the response variable. The short answer is that we can’t. But we do use <strong><em>Least Squares</em></strong> to find coefficient estimates as we did before – except that we have to remember that these <strong>estimates are conditional on other variables in the model</strong> for our interpretation since they impact one another within the model. It ends up that the uncertainty of pinning those variables down in the presence of shared information leads to larger SEs for all the slopes. And that we can actually measure <strong>how much each of the SEs are inflated</strong> because of multicollinearity with other variables in the model using what are called <strong><em>Variance Inflation Factors</em></strong> (or <strong><em>VIFs</em></strong>).</p></li>
</ul>
<p><strong>VIFs</strong> provide a way to assess the multicollinearity in the MLR model that is caused by including specific variables. The amount of information that is shared between a single explanatory variable and the others can be found by regressing that variable on the others and calculating <span class="math inline">\(\boldsymbol{R}^2\)</span> for that model. The code for this regression is something like: <code>lm(X1~X2+X3+?+XK)</code>, which regresses <em>X1</em>on <em>X2</em> through <em>XK</em>. The <span class="math inline">\(1-\boldsymbol{R}^2\)</span> from this regression is the amount of independent information in <em>X1</em> that is not explained by the other variables in the model. The VIF for each variable is defined using this quantity as <span class="math inline">\(\textbf{VIF}_{\boldsymbol{k}}\boldsymbol{=1/(1-R^2_k)}\)</span> for variable <span class="math inline">\(k\)</span>. If there is no shared information <span class="math inline">\((\boldsymbol{R}^2=0)\)</span>, then the VIF will be 1. But if the information is completely shared with other variables <span class="math inline">\((\boldsymbol{R}^2=1)\)</span>, then the VIF goes to infinity (1/0). Basically, large VIFs are bad, with the rule of thumb that values over 5 or 10 are considered “large” values indicating high multicollinearity in the model for that particular variable. We use this scale to determine if multicollinearity is a problem for a variable of interest. Additionally, the <span class="math inline">\(\boldsymbol{\sqrt{\textbf{VIF}_k}}\)</span> is also very interesting as it is the number of times larger than the SE for the slope for variable <span class="math inline">\(k\)</span> is due to collinearity with other variables in the model. This is the most useful scale to understand VIFs even though the rules of thumb are on the original scale. An example will show how to easily get these results and where the results come from.</p>
<p>In general, the easy way to obtain VIFs is using the <code>vif</code> function from the <code>car</code> package (Fox, 2003). It has the advantage of also providing a reasonable result when we include categorical variables in models (Sections <a href="chapter8.html#section8-9">8.9</a> and <a href="chapter8.html#section8-11">8.11</a>). We apply the <code>vif</code> function directly to a model of interest and it generates values for each explanatory variable.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">require</span>(car)
<span class="kw">vif</span>(m6)</code></pre></div>
<pre><code>## Elevation  Min.Temp  Max.Temp 
##  8.164201  5.995301  3.350914</code></pre>
<p>Not surprisingly, there is an indication of problems with multicollinearity in two of the three variables in the model with the largest issues identified for <em>Elevation</em> and <em>Min.Temp</em>. Both of their VIFs exceed 5 indicating large multicollinearity problems. On the square-root scale, the VIFs show more interpretation utility.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sqrt</span>(<span class="kw">vif</span>(m6))</code></pre></div>
<pre><code>## Elevation  Min.Temp  Max.Temp 
##  2.857307  2.448530  1.830550</code></pre>
<p>The result for <em>Elevation</em> of 2.86 suggests that the SE for <em>Elevation</em> is 2.86 times larger than it should be because of multicollinearity with other variables in the model. Similarly, the <em>Min.Temp</em> SE is 2.45 times larger and the <em>Max.Temp</em> SE is 1.83 times larger. All of this generally suggests issues with multicollinearity in the model and that we need to be cautious in interpreting any slope coefficients from this model.</p>
<p>In order to see how the VIF is calculated for <em>Elevation</em>, we need to regress <em>Elevation</em> on <em>Min.Temp</em> and <em>Max.Temp</em>. Note that this model is only fit to find the percentage of variation in elevation explained by the temperature variables. It ends up being 0.8775 – so a high percentage of <em>Elevation</em> can be explained by the linear model using min and max temperatures.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#VIF calc:</span>
elev1&lt;-<span class="kw">lm</span>(Elevation<span class="op">~</span>Min.Temp<span class="op">+</span>Max.Temp,<span class="dt">data=</span>snotel2[<span class="op">-</span><span class="kw">c</span>(<span class="dv">9</span>,<span class="dv">22</span>),])
<span class="kw">summary</span>(elev1)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Elevation ~ Min.Temp + Max.Temp, data = snotel2[-c(9, 
##     22), ])
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1120.05  -142.99    14.45   186.73   624.61 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) 14593.21     699.77  20.854 4.85e-15
## Min.Temp     -208.82      38.94  -5.363 3.00e-05
## Max.Temp      -56.28      20.90  -2.693    0.014
## 
## Residual standard error: 395.2 on 20 degrees of freedom
## Multiple R-squared:  0.8775, Adjusted R-squared:  0.8653 
## F-statistic: 71.64 on 2 and 20 DF,  p-value: 7.601e-10</code></pre>
<p>Using this result, we can calculate</p>
<p><span class="math display">\[\text{VIF}_{\text{elevation}} = \dfrac{1}{1-R^2_{\text{elevation}}} = \dfrac{1}{1-0.8775} = \dfrac{1}{0.1225} = 8.16\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="fl">0.8775</span></code></pre></div>
<pre><code>## [1] 0.1225</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">1</span><span class="op">/</span><span class="fl">0.1225</span></code></pre></div>
<pre><code>## [1] 8.163265</code></pre>
<p>Note that when we observe small VIFs, that provides us with confidence that multicollinearity is not causing problems under the surface of a particular MLR model. And that we can’t use the VIFs to do anything about multicollinearity in the models – it is just a diagnostic to understand the magnitude of the problem.</p>
</div>
<div id="section8-6" class="section level2">
<h2><span class="header-section-number">8.6</span> MLR Inference: Parameter inferences using the t-distribution</h2>
<p>We have been deliberately vague about what an important variable is up to this point, and chose to focus on some bigger modeling issues. We now turn our attention to one of the most common tasks in any basic statistical model – assessing whether a particular result is more unusual than we would expect by chance. All the previous discussions of estimation in MLR models informs our interpretations of of the tests. The <span class="math inline">\(t\)</span>-tests for slope coefficients are based on our standard recipe – take the estimate, divide it by its standard error and then, assuming the statistic follows a <span class="math inline">\(t\)</span>-distribution under the null hypothesis, find a p-value. This tests whether each true slope coefficent, <span class="math inline">\(\beta_k\)</span>, is 0 or not, in a model that contains all the other variables. Again, sometimes we say “after adjusting for” the other <span class="math inline">\(x\text{&#39;s}\)</span> or “conditional on” the other <span class="math inline">\(x\text{&#39;s}\)</span> in the model or “after allowing for”… as in the slope coefficient interpretations above. The main point is that <strong>you should not interpret anything related to slope coefficients in MLR without referencing the other variables that are in the model!</strong> The tests for the slope coefficients assess <span class="math inline">\(\boldsymbol{H_0:\beta_k=0}\)</span>, which in words is a test that there is no linear relationship between explanatory variable <span class="math inline">\(k\)</span> and the response variable, <span class="math inline">\(y\)</span>, in the population, given the other variables in model. The typical alternative hypothesis is <span class="math inline">\(\boldsymbol{H_0:\beta_k\ne 0}\)</span>. In words, the alternative hypothesis is that there is some linear relationship between explanatory variable <span class="math inline">\(k\)</span> and the response variable, <span class="math inline">\(y\)</span>, in population, given the other variables in the model. It is also possible to test for positive or negative slopes in the alternative, but this is rarely the first concern, especially when MLR slopes can occasionally come out in unexpected directions.</p>
<p>The test statistic forthese hypotheses is <span class="math inline">\(\boldsymbol{t=\dfrac{b_k}{\textbf{SE}_k}}\)</span> and, if our assumptions are met, follows a <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\(n-K-1\)</span> <em>df</em> where <span class="math inline">\(K\)</span> is the number of predictor variables in the model. We perform the test for each slope coefficient, but the test is conditional on all the other variables in the model – the order the variables are fit in does <strong>not</strong> change <span class="math inline">\(t\)</span>-test results. For the <em>Snow Depth</em> example with <strong>Elevation</strong> and <em>Maximum Temperature</em> as predictors, the pertinent output is in the four columns of the <strong><em>Coefficient table</em></strong> that is the first part of the model summary we’ve been working with. You can find the estimated slope (<code>Estimate</code> column), the SE of the slopes (<code>Std. Error</code> column), the <span class="math inline">\(t\)</span>-statistics (<code>t value</code> column), and the p-values (<code>Pr(&gt;|t|)</code> column). The degrees of freedom for the <span class="math inline">\(t\)</span>-distributions show up below the coefficients and the <span class="math inline">\(df=20\)</span> here. This is because <span class="math inline">\(n=23\)</span> and <span class="math inline">\(K=2\)</span>, so <span class="math inline">\(df=23-2-1=20\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m5 &lt;-<span class="st"> </span><span class="kw">lm</span>(Snow.Depth<span class="op">~</span>Elevation<span class="op">+</span>Max.Temp, <span class="dt">data=</span>snotel2[<span class="op">-</span><span class="kw">c</span>(<span class="dv">9</span>,<span class="dv">22</span>),])
<span class="kw">summary</span>(m5)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Snow.Depth ~ Elevation + Max.Temp, data = snotel2[-c(9, 
##     22), ])
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -14.652  -4.645   0.518   3.744  20.550 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) -1.675e+02  3.924e+01  -4.269 0.000375
## Elevation    2.407e-02  3.162e-03   7.613 2.48e-07
## Max.Temp     1.253e+00  5.385e-01   2.327 0.030556
## 
## Residual standard error: 8.726 on 20 degrees of freedom
## Multiple R-squared:  0.8495, Adjusted R-squared:  0.8344 
## F-statistic: 56.43 on 2 and 20 DF,  p-value: 5.979e-09</code></pre>
<p>The hypotheses for the <em>Maximum Temperature</em> term (<em>Max.Temp</em>) are:</p>
<ul>
<li><p><span class="math inline">\(\boldsymbol{H_0: \beta_{\textbf{Max.Temp}}=0}\)</span> <strong>given that</strong> <strong><em>Elevation</em></strong> <strong>is in the model vs</strong></p></li>
<li><p><span class="math inline">\(\boldsymbol{H_A: \beta_{\textbf{Max.Temp}}\ne 0}\)</span> <strong>given that</strong> <strong><em>Elevation</em></strong> <strong>is in the model.</strong></p></li>
</ul>
<p>The test statistic is <span class="math inline">\(t=2.327\)</span> with <span class="math inline">\(df = 20\)</span> (so under the null hypothesis the test statistic follows a <span class="math inline">\(t_{20}\)</span>-distribution).</p>
<p>The output provides a p-value of <span class="math inline">\(0.0306\)</span> for this test. We can also find this using <code>pt</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">2</span><span class="op">*</span><span class="kw">pt</span>(<span class="fl">2.327</span>, <span class="dt">df=</span><span class="dv">20</span>, <span class="dt">lower.tail=</span>F)</code></pre></div>
<pre><code>## [1] 0.03058319</code></pre>
<p>The decision here would probably be to reject <span class="math inline">\(H_0\)</span>. The chance of observing a slope for <em>Max.Temp</em> as extreme or more extreme thanassuming there really is no linear relationship between <em>Max.Temp</em> and <em>Snow Depth</em> (in a model with <em>Elevation</em>), is about 3%.</p>
<p>Conclusion: There is sufficient evidence to suggest that there is a linear relationship between <em>Max.Temp</em> and <em>Snow Depth</em>, once we account for <em>Elevation</em>, in the population of snotel sites in Montana on this day. Because we cannot randomly assign the temperatures to sites, we cannot conclude that temperature causes changes in the snow depth – in fact it might even be possible for a location to have different temperatures because of different snow depths.</p>
<p>Similarly, we can test for <em>Elevation</em> after controlling for the <em>Maximum Temperature</em>: <span class="math inline">\(\boldsymbol{H_0: \beta_{\textbf{Elevation}}=0 \textbf{ vs } H_A: \beta_{\textbf{Elevation}}\ne 0}\)</span>, given that <em>Max.Temp</em> is in the model.</p>
<p><span class="math inline">\(t=7.613\)</span> (<span class="math inline">\(df=20\)</span>) with a p-value of <span class="math inline">\(0.00000025\)</span> or just <span class="math inline">\(&lt;0.00001\)</span>.</p>
<p>Decision: Reject <span class="math inline">\(H_0\)</span> and conclude that there is sufficient evidence to suggest that there is a linear relationship between <em>Elevation</em> and <em>Snow Depth</em>, once we adjust for <em>Max.Temp</em> in the population of SNOTEL sites in Montana on this day.</p>
<p>There is one last test that is of dubious interest in almost every situation – to test that the y-intercept <span class="math inline">\((\boldsymbol{\beta_0})\)</span> in an MLR is 0. This tests if the true mean response is 0 when all the predictor variables are set to 0. I see researchers reporting this p-value frequently and it is possibly the most useless piece of information in the regression model summary. Sometimes less educated statistics users even think this result is proof of something interesting or are disappointed when the p-value is not small. Unless you want to do some prediction and are interested in whether the mean response when all the predictors are set to 0 is different from 0, this test should not be reported or, if reported, is certainly not very interesting<a href="#fn77" class="footnoteRef" id="fnref77"><sup>77</sup></a>. But we should at least go through the motions on this test once so you don’t make the same mistakes.</p>
<p><span class="math inline">\(\boldsymbol{H_0: \beta_0=0 \textbf{ vs } H_A: \beta_0\ne 0}\)</span> in a model with <em>Elevation</em> and <em>Maximum Temperature</em></p>
<p><span class="math inline">\(t=-4.269\)</span>, with an assumption that the test statistic follows a <span class="math inline">\(t_{20}\)</span>-distribution under the null hypothesis, and the p-value <span class="math inline">\(= 0.000375\)</span>.</p>
<p>Decision: Reject <span class="math inline">\(H_0\)</span></p>
<p>Conclusion: There is sufficient evidence to suggest that the true mean <em>Snow Depth</em> is different from 0 when the <em>Maximum Temperature</em> is 0 and the <em>Elevation</em> is 0 in the population of SNOTEL sites. To reinforce the general uselessness of this test, think about the combination of <span class="math inline">\(x\text{&#39;s}\)</span> – is that even physically possible in Montana (or the continental US) in April?</p>
<p>Remember when testing slope coefficients in MLR, that if we fail to reject the null hypothesis, it does not mean that there is no relationship or even no linear relationship between the variables, but that there is no evidence of a linear relationship <strong>once we account for the other variables in the model</strong>. If you do not find a small p-value for a variable, you should either be cautious when interpreting the coefficient, or not interpret it. Some model building strategies would lead to dropping the term from the model but sometimes we will have models to interpret that contain terms with larger p-values. Sometimes they are still of interest but the weight on the interpretation isn’t as heavy as if the term had a small p-value – you should remember that you can’t prove that coefficient is different from 0 in that model. It also may mean that you don’t know too much about its specific value. Confidence intervals will help us pin down where we think the true slope coefficient might be located, given the other variables in the model.</p>
<p>Confidence intervals provide the dual uses of inferences for the location of the true slope and whether the true slope seems to be different from 0. The confidence intervals here have our regular format of estimate <span class="math inline">\(\mp\)</span> margin of error. Like the previous tests, we work with <span class="math inline">\(t\)</span>-distributions with <span class="math inline">\(n-K-1\)</span> degrees of freedom. Specifically the 95% confidence interval for slope coefficient <span class="math inline">\(k\)</span> is</p>
<p><span class="math display">\[\boldsymbol{b_k \mp t^*_{n-K-1}\textbf{SE}_{b_k}}.\]</span></p>
<p>The interpretation is the same as in SLR with the additional tag of “after controlling for the other variables in the model” for all the reasons discussed before. The general slope CI interpretation for predictor <span class="math inline">\(\boldsymbol{x_k}\)</span> in an MLR is:</p>
<ul>
<li>For a 1 <strong>[unit of <span class="math inline">\(\boldsymbol{x_k}\)</span>]</strong> increase in <span class="math inline">\(\boldsymbol{x_k}\)</span>, we are 95% confident that the true mean of <span class="math inline">\(\boldsymbol{y}\)</span> changes by between <strong>LL</strong> and <strong>UL</strong> <strong>[units of <span class="math inline">\(\boldsymbol{Y}\)</span>]</strong> in the population, after adjusting for the other <span class="math inline">\(x\text{&#39;s}\)</span> <strong>[list them!]</strong>.</li>
</ul>
<p>We can either calculate these intervals as we have many times before or we can rely on the <code>confint</code> function to do this:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">confint</span>(m5)</code></pre></div>
<pre><code>##                     2.5 %      97.5 %
## (Intercept) -3.345105e+02 49.70984942
## Elevation    8.679311e-03  0.03413171
## Min.Temp    -2.942363e+00  4.28674848
## Max.Temp    -8.450797e-01  1.86064343</code></pre>
<p>So for a <span class="math inline">\(1^\circ F\)</span> increase in <em>Maximum Temperature</em>, we are 95% confident that the true mean <em>Snow Depth</em> will change by between 0.13 and 2.38 inches in the population, after adjusting for the <em>Elevation</em> of the sites. Similarly, for a 1 foot increase in <em>Elevation</em>, we are 95% confident that the true mean <em>Snow Depth</em> will change by between 0.0175 and 0.0307 inches in the population, after adjusting for the <em>Maximum Temperature</em> of the sites.</p>
</div>
<div id="section8-7" class="section level2">
<h2><span class="header-section-number">8.7</span> Overall F-test in Multiple Linear Regression</h2>
<p>In the MLR summary, reported at the bottom of the output. For the model with <em>Elevation</em> and <em>Maximum Temperature</em>, the last row of the model summary is:</p>
<pre><code>## F-statistic: 56.43 on 2 and 20 DF,  p-value: 5.979e-09</code></pre>
<p>This test is called the <strong><em>overall F-test</em></strong> in MLR and is very similar to the <span class="math inline">\(F\)</span>-test in a reference-coded One-Way ANOVA model. It tests the null hypothesis that involves setting every coefficient except the y-intercept to 0 (so all the slope coefficients equal 0). We saw this reduced model in the One-Way material when we considered setting all the deviations from the baseline group to 0 under the null hypothesis. We can frame this as a comparison between a full and reduced model as follows:</p>
<ul>
<li><p><strong><em>Full Model:</em></strong>   <span class="math inline">\(y_i = \beta_0 + \beta_1x_{1i} + \beta_2x_{2i}+\cdots + \beta_Kx_{Ki}+\varepsilon_i\)</span></p></li>
<li><p><strong><em>Reduced Model:</em></strong>   <span class="math inline">\(y_i = \beta_0 + 0x_{1i} + 0x_{2i}+\cdots + 0x_{Ki}+\varepsilon_i\)</span></p></li>
</ul>
<p>The reduced model estimates the same values for all <span class="math inline">\(y\text{&#39;s}\)</span>, <span class="math inline">\(\hat{y}_i=\bar{y}=b_0\)</span> and corresponds to the null hypothesis of:</p>
<p><span class="math inline">\(\boldsymbol{H_0:}\)</span> <strong>No explanatory variables should be included in the model:</strong> <span class="math inline">\(\beta_1=\beta=2=\cdots=\beta_K=0\)</span>.</p>
<p>The full model corresponds to the alternative:</p>
<p><span class="math inline">\(\boldsymbol{H_A:}\)</span> <strong>At least one explanatory variable should be included in the model: Not all</strong> <span class="math inline">\(\beta_k\text{&#39;s}=0\)</span> for <span class="math inline">\((k=1,\ldots,K)\)</span>.</p>
<p>Note that <span class="math inline">\(\beta_0\)</span> is not set to 0 in the reduced model (under the null hypothesis) – it becomes the true mean of <span class="math inline">\(y\)</span> for all values of the <span class="math inline">\(x\text{&#39;s}\)</span> since all the predictors are multiplied by coefficients of 0.</p>
<p>The test statistic to assess these hypotheses is <span class="math inline">\(F = \text{MS}_{\text{model}}/\text{MS}_E\)</span>, which is assumed to follow an <span class="math inline">\(F\)</span>-distribution with <span class="math inline">\(K\)</span> numerator <em>df</em> and <span class="math inline">\(n-K-1\)</span> denominator <em>df</em> under the null hypothesis. The output provides us with <span class="math inline">\(F(2, 20)=56.43\)</span> and a p-value of <span class="math inline">\(5.979*10^{-9}\)</span> (p-value <span class="math inline">\(&lt;0.00001\)</span>) and enough evidence to reject the null hypothesis. Thus, there is evidence that at least one of the two slope coefficients (<em>Max.Temp</em>’s or <em>Elevation</em>’s) is different from 0 in the population of SNOTEL sites in Montana on this date. While this test is a little bit interesting and a good indicator of something interesting in the model, the moment you see this result, you want to know more about each predictor variable. If neither predictor variable is important, we will discover that in the <span class="math inline">\(t\)</span>-tests for each coefficient and so our general recommendation is to start there.</p>
<p>The overall F-test, then, is really about testing whether there is something good in the model somewhere. And that certainly is important but it is also not too informative. There is one situation where this test is really interesting, when there is only one predictor variable in the model (SLR). In that situation, this test provides exactly the same p-value as the <span class="math inline">\(t\)</span>-test. <span class="math inline">\(F\)</span>-tests will be important when we are mixing categorical and quantitative predictor variables in our MLR models (Section <a href="chapter8.html#section8-12">8.12</a>), but the overall <span class="math inline">\(F\)</span>-test is of very limited utility.</p>
</div>
<div id="section8-8" class="section level2">
<h2><span class="header-section-number">8.8</span> Case Study: First year college GPA and SATs</h2>
<p>Many universities require students to have certain test scores in order to be admitted into their institutions. They obviously must think that those scores are useful predictors of student success to use them in this way. Quality assessments of recruiting classes are also based on their test scores. The Educational Testing Service (the company behind such fun exams as the SAT and GRE) collected a data set to validate their SAT on <span class="math inline">\(n=1000\)</span> students from an unnamed Midwestern university; the data set is available in the <code>openintro</code> package (Diez, Barr, and Cetinkaya-Rundel, 2012) in the <code>satGPA</code> data set. It is unclear from the documentation whether a random sample was collected, in fact it looks like it certainly wasn’t a random sample of all incoming students at a large university (more later). What potential issues would arise if a company was providing a data set to show the performance of their test and it was not based on a random sample?</p>
<p>We will proceed assuming they used good methods in developing their test (there are sophisticated statistical models underlying the development of the SAT and GRE) and in obtaining a data set for testing out the performance of their tests that is at least representative of the students (or some types of students) at this university. They provided information on the <em>Sex</em> (<code>sex</code>) of the students (coded 1 and 2 with possibly 1 for males and 2 for females – but should this even be displayed in a plot with correlations?), <em>SAT Verbal</em> (<code>SATV</code>) and <em>Math</em> (<code>SATM</code>) percentiles (these are not the scores but the ranking percentile that each score translated to in a particular year), <em>High School GPA</em> (<code>HSGPA</code>), and <em>First Year</em> (of college) <em>GPA</em> <code>FYGPA</code> Our interests here are in whether the two SAT percentiles are (together?) related to the first year college GPA, describing the size of their impacts and assessing the predictive potential of SAT-based measures for first year in college GPA. There are certainly other possible research questions that can be addressed with these data but this will keep us focused.</p>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">require</span>(openintro)
<span class="kw">data</span>(satGPA)
<span class="kw">require</span>(psych)
<span class="kw">pairs.panels</span>(satGPA[,<span class="op">-</span><span class="dv">4</span>], <span class="dt">ellipse=</span>F, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lwd=</span><span class="dv">2</span>)</code></pre></div>
<div class="figure"><span id="fig:Figure8-13"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-13-1.png" alt="Scatterplot matrix of SAT and GPA data set." width="672" />
<p class="caption">
Figure 8.12: Scatterplot matrix of SAT and GPA data set.
</p>
</div>
<p>There are positive relationships in Figure <a href="chapter8.html#fig:Figure8-13">8.12</a> among all the pre-college measures and the <em>college GPA</em> but none are above the moderate strength level. The <em>HSGPA</em> has a highest correlation with first year of college results but its correlation is not that strong. Maybe together in a model the SAT percentiles can also be useful… Also note that plot shows an odd <em>HSGPA</em> of 4.5 that probably should be removed<a href="#fn78" class="footnoteRef" id="fnref78"><sup>78</sup></a> if that variable is going to be used (<em>HSGPA</em> was not used in the following models so the observation remains in the data).</p>
<p>In MLR, the modeling process is a bit more complex and often involves more than one model, so we will often avoid the 6+ steps in testing initially and try to generate a model we can use in that more specific process. In this case, the first model of interest using the two SAT percentiles,</p>
<p><span class="math display">\[\text{FYGPA}_i = \beta_0 + \beta_{\text{SATV}}\text{SATV}_i 
+ \beta_{\text{SATM}}\text{SATM}_i +\varepsilon_i,\]</span></p>
<p>looks like it might be worth interrogating further so we can jump straight into considering the 6+ steps involved in hypothesis testing for the two slope coefficients. We will be using a 5% significance level and <span class="math inline">\(t\)</span>-based inferences, assuming that we can trust the assumptions.</p>
<p>Note that this is not a randomized experiment but we can assume that it is representative of the students at that single university. We would not want to extend these inferences to other universities (who might be more or less selective) or to students who did not get into this university and, especially, not to students that failed to complete the first year. The second and third constraints point to a severe limitation in this research – only students who were accepted, went to, and survived one year at this university could be studied. Lower SAT percentile students might not have been allowed in or may not have survived the first year and higher SAT students might have been attracted to other more prestigious institutions. So the scope of inference is just limited to students that were invited and chose to attend this institution and successfully completed one year of courses. It is hard to know if the SAT “works” when the inferences are so restricted in who they might apply to…</p>
<p>The following code fits the model of interest, provides a model summary, and the diagnostic plots, allowing us to consider the tests of interest:</p>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">gpa1 &lt;-<span class="st"> </span><span class="kw">lm</span>(FYGPA<span class="op">~</span>SATV<span class="op">+</span>SATM, <span class="dt">data=</span>satGPA)
<span class="kw">summary</span>(gpa1)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = FYGPA ~ SATV + SATM, data = satGPA)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.19647 -0.44777  0.02895  0.45717  1.60940 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) 0.007372   0.152292   0.048    0.961
## SATV        0.025390   0.002859   8.879  &lt; 2e-16
## SATM        0.022395   0.002786   8.037 2.58e-15
## 
## Residual standard error: 0.6582 on 997 degrees of freedom
## Multiple R-squared:  0.2122, Adjusted R-squared:  0.2106 
## F-statistic: 134.2 on 2 and 997 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>), <span class="dt">oma=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">2</span>,<span class="dv">0</span>))
<span class="kw">plot</span>(gpa1, <span class="dt">sub.caption=</span><span class="st">&quot;Diagnostics for GPA model with SATV and SATM&quot;</span>)</code></pre></div>
<div class="figure"><span id="fig:Figure8-14"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-14-1.png" alt="Diagnostic plots for the \(\text{FYGPA}\sim\text{ SATV }+\text{ SATM}\) model." width="672" />
<p class="caption">
Figure 8.13: Diagnostic plots for the <span class="math inline">\(\text{FYGPA}\sim\text{ SATV }+\text{ SATM}\)</span> model.
</p>
</div>
<ol style="list-style-type: decimal">
<li><p>Hypotheses of interest:</p>
<ul>
<li><p><span class="math inline">\(H_0: \beta_{SATV}=0\)</span> given <em>SATM</em> in the model vs <span class="math inline">\(H_0: \beta_{SATV}\ne 0\)</span> given <em>SATM</em> in the model.</p></li>
<li><p><span class="math inline">\(H_0: \beta_{SATM}=0\)</span> given <em>SATV</em> in the model vs <span class="math inline">\(H_0: \beta_{SATM}\ne 0\)</span> given <em>SATV</em> in the model.</p></li>
</ul></li>
<li><p>Validity conditions:</p>
<ul>
<li><p><strong>Quantitative variables condition:</strong></p>
<ul>
<li>The variables used here are all quantitative. Note that the <em>sex</em> was plotted in the previous scatterplot matrix and is not quantitative – we will explore its use later.</li>
</ul></li>
<li><p><strong>Independence of observations:</strong></p>
<ul>
<li>With a sample from a single university from (we are assuming) a single year of students, there is no particular reason to assume a violation of the independence assumption.</li>
</ul></li>
<li><p><strong>Linearity of relationships:</strong></p>
<ul>
<li><p>The initial scatterplots (Figure <a href="chapter8.html#fig:Figure8-13">8.12</a>) do not show any clear nonlinearities with each predictor used in this model.</p></li>
<li><p>The Residuals vs Fitted and Scale-Location plots (Figure <a href="chapter8.html#fig:Figure8-14">8.13</a> do not show much more than a football shape, which is our desired result.</p>
<ul>
<li>Together, we can feel relatively comfortable with the linearity assumption.</li>
</ul></li>
</ul></li>
<li><p><strong>Multicollinearity checked for:</strong></p>
<ul>
<li><p>The original scatterplots suggest that there is some collinearity between the two SAT percentiles with a correlation of 0.47. That is actually a bit lower than one might expect and suggests that each score must be measuring some independent information about different characteristics of the students.</p></li>
<li><p>VIFs also do not suggest a major issue with multicollinearity in the model with the VIFs for both variables the same at 1.278<a href="#fn79" class="footnoteRef" id="fnref79"><sup>79</sup></a>. This suggests that both SEs are about 13% larger than they otherwise would have been due to shared information between the two predictor variables.</p></li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">vif</span>(gpa1)</code></pre></div>
<pre><code>##     SATV     SATM 
## 1.278278 1.278278</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sqrt</span>(<span class="kw">vif</span>(gpa1))</code></pre></div>
<pre><code>##    SATV    SATM 
## 1.13061 1.13061</code></pre></li>
<li><p><strong>Equal (constant) variance:</strong></p>
<ul>
<li>There is no clear change in variability as a function of fitted values.</li>
</ul></li>
<li><p><strong>Normality of residuals:</strong></p>
<ul>
<li>There is a minor deviation in the upper tail of the residual distribution from normality. It is not pushing towards having larger values than a normal distribution would generate so should not cause us any real problems. Note that this upper limit is likely due to using GPA as a response variable and it has an upper limit. This is an example of a potentially <strong><em>censored</em></strong> variable. For a continuous variable it is possible that the range of a measurement scale doesn’t distinguish among subjects who differ once they pass a certain point. For example, a 4.0 high school student is going to have a high first year college GPA, on average but there is no room for variability in college GPA up, just down. For students more in the middle of the range, they can vary up or down. So in some places you can get symmetric distributions around the mean and in others you cannot. There are specific statistical models for these types of responses that are beyond our scope. In this situation, failing to account for the censoring may push some slopes toward 0 a little because we don’t have responses over 4.0 to work with.</li>
</ul></li>
<li><p><strong>No influential points:</strong></p>
<ul>
<li>There are no influential points. In large data sets, the influence of any point is decreased and even high leverage and outlying points can struggle to have any impacts at all on the results.</li>
</ul></li>
</ul></li>
</ol>
<p>So we are fairly comfortable with all the assumptions being at least not clearly violated and so the inferences from our model should be relatively trustworthy.</p>
<ol start="3" style="list-style-type: decimal">
<li><p>Calculate the test statistics:</p>
<ul>
<li><p>For <em>SATV</em>: <span class="math inline">\(t=\dfrac{0.02539}{0.002859}=8.88\)</span> with <span class="math inline">\(df=997\)</span>.</p></li>
<li><p>For <em>SATM</em>: <span class="math inline">\(t=\dfrac{0.02240}{0.002786}=8.04\)</span> with <span class="math inline">\(df=997\)</span>.</p></li>
</ul></li>
<li><p>Find the p-values:</p>
<ul>
<li><p>For <em>SATV</em>: p-value <span class="math inline">\(&lt;0.0001\)</span></p></li>
<li><p>For <em>SATM</em>: p-value <span class="math inline">\(&lt;0.0001\)</span></p></li>
</ul></li>
<li><p>Decisions:</p>
<ul>
<li><p>For <em>SATV</em>: Reject <span class="math inline">\(H_0\)</span> because there is almost no chance of observing a test statistic as extreme or more extreme than was observed if there really were no linear relationship between <em>FYGPA</em> and <em>SATV</em>, in a model that controls for <em>SATM</em>.</p></li>
<li><p>For <em>SATM</em>: Reject <span class="math inline">\(H_0\)</span> because there is almost no chance of observing a test statistic as extreme or more extreme than was observed if there really were no linear relationship between <em>FYGPA</em> and <em>SATM</em>, in a model that controls for <em>SATV</em>.</p></li>
</ul></li>
<li><p>Conclusions and Scope of Inference:</p>
<ul>
<li><p>For <em>SATV</em>: There is strong evidence to reject the null hypothesis of no linear relationship between <em>SATV</em> and <em>FYGPA</em> and conclude that, in fact, there is a linear relationship between <em>SATV</em> percentile and the first year of college <em>GPA</em>, after controlling for the <em>SATM</em> percentile, in the population of students that completed their first year at this university.</p></li>
<li><p>For <em>SATM</em>: There is strong evidence to reject the null hypothesis of no linear relationship between <em>SATM</em> and <em>FYGPA</em> and conclude that, in fact, there is a linear relationship between <em>SATM</em> percentile and the first year of college <em>GPA</em>, after controlling for the <em>SATV</em> percentile, in the population of students that completed their first year at this university.</p></li>
<li><p>Note that neither inference is causal because there was no random assignment of SAT percentiles to the subjects. The inferences are also limited to students who stayed in school long enough to get a <em>GPA</em> from their first year of college.</p></li>
</ul></li>
</ol>
<p>We could stop there, but just reporting the test results without quantifying the size of the effects is not fully satisfying. The estimated MLR model is</p>
<p><span class="math display">\[\widehat{\text{FYGPA}}_i=0.00737+0.0254\text{SATV}_i
+0.0224\text{SATM}_i.\]</span></p>
<p>So for a 1 percent increase in the <em>SATV</em> percentile, we expect, on average, to get a 0.0254 point change in <em>GPA</em>, after controlling for <em>SATM</em> percentile. Similarly, for a 1 percent increase in the <em>SATM</em> percentile, we expect, on average, to get a 0.0224 pointchange in <em>GPA</em>, after controlling for <em>SATV</em> percentile. While this is a correct interpretation of the slope coefficients, it is often easier to assess “practical” importance of the results by considering how much change this implies over the range of observed predictor values.</p>
<p>The term-plots (Figure <a href="chapter8.html#fig:Figure8-15">8.14</a>) provide a visualization of the “size” of the differences in the response variable explained by each predictor. The <em>SATV</em> term-plot shows that for the range of percentiles from around the 30<sup>th</sup> percentile to the 70<sup>th</sup> percentile, the mean first year <em>GPA</em> is predicted to go from approximately 1.9 to 3.0. That is a pretty wide range of differences in GPAs across the range of observed percentiles. This looks like a pretty interesting and important change in the mean first year GPA across that range of different SAT percentiles. Similarly, the <em>SATM</em> term-plot shows that the <em>SATM</em> percentiles were observed to range between around the 30<sup>th</sup> percentile and 70<sup>th</sup> percentile and predict mean GPAs between 1.95 and 2.8. It seems that the SAT Verbal percentiles produce slightly more impacts in the model, holding the other variable constant, but that both are important variables. The 95% confidence intervals for the means in both plots suggest that the results are fairly precisely estimated – there is little variability around the predicted means in each plot. This is mostly a function of the sample size as opposed to the model itself explain most of the variation in the responses.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">require</span>(effects)
<span class="kw">plot</span>(<span class="kw">allEffects</span>(gpa1))</code></pre></div>

<div class="figure"><span id="fig:Figure8-15"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-15-1.png" alt="Term-plots for the \(\text{FYGPA}\sim\text{SATV} + \text{SATM}\) model." width="672" />
<p class="caption">
Figure 8.14: Term-plots for the <span class="math inline">\(\text{FYGPA}\sim\text{SATV} + \text{SATM}\)</span> model.
</p>
</div>
<p>These plots also inform the types of students attending this university and successfully completing the first year of school. This seems like a good, but maybe not great, institution with few students scoring over the 75<sup>th</sup> percentile on either SAT Verbal or Math (at least that ended up in this data set). This result makes questions about their sampling mechanism re-occur as to who this data set might actually be representative of…</p>
<p>The confidence intervals also help us pin down the uncertainty in each estimated slope coefficient. As always, the “easy” way to get 95% confidence intervals is using the <code>confint</code> function:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">confint</span>(gpa1)</code></pre></div>
<pre><code>##                   2.5 %     97.5 %
## (Intercept) -0.29147825 0.30622148
## SATV         0.01977864 0.03100106
## SATM         0.01692690 0.02786220</code></pre>
<p>So, for a 1 percent increase in the <em>SATV</em> percentile, we are 95% confident that the true mean <em>FYGPA</em> changes between 0.0198 and 0.031 points, in the population of students who completed this year at this institution, after controlling for <em>SATM</em>. The <em>SATM</em> result is similar with an interval from 0.0169 and 0.0279. Both of these intervals might benefit from re-scaling the interpretation to a 10 percentile increase in the predictor variable, with the change in the <em>FYGPA</em> for that level of increase of <em>SATV</em> providing an interval from 0.198 to 0.31 points and for <em>SATM</em> providing an interval from 0.169 to 0.279. So a boost of 10% in either exam percentile likely results in a noticeable but not huge average <em>FYGPA</em> increase.</p>
<p>One final use of these methods is to do prediction and generate prediction intervals, which could be quite informative for a student considering going to this university who has a particular set of SAT scores. For example, suppose that the student is interested in the average <em>FYGPA</em> to expect with <em>SATV</em> at the 30<sup>th</sup> percentile and <em>SATM</em> at the 60<sup>th</sup> percentile. The predicted mean value is</p>
<p><span class="math display">\[\begin{array}{rl}
\hat{\mu}_{\text{GPA}_i} &amp;= 0.00737 + 0.0254\text{ SATV}_i 
+ 0.0224\text{ SATM}_i \\
&amp;= 0.00737 + 0.0254*30 + 0.0224*60 = 2.113
\end{array}\]</span></p>
<p>This result and the 95% confidence interval for the mean student <em>GPA</em> at these scores can be found using the <code>predict</code> function as:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">predict</span>(gpa1,<span class="dt">newdata=</span><span class="kw">data.frame</span>(<span class="dt">SATV=</span><span class="dv">30</span>,<span class="dt">SATM=</span><span class="dv">60</span>))</code></pre></div>
<pre><code>##       1 
## 2.11274</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">predict</span>(gpa1,<span class="dt">newdata=</span><span class="kw">data.frame</span>(<span class="dt">SATV=</span><span class="dv">30</span>,<span class="dt">SATM=</span><span class="dv">60</span>),<span class="dt">interval=</span><span class="st">&quot;confidence&quot;</span>)</code></pre></div>
<pre><code>##       fit      lwr      upr
## 1 2.11274 1.982612 2.242868</code></pre>
<p>For students at the 30<sup>th</sup> percentile of <em>SATV</em> and 60<sup>th</sup> percentile of <em>SATM</em>, we are 95% confident that the true mean first year GPA is between 1.98 and 2.24 points. For an individual student, we would want the 95% prediction interval:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">predict</span>(gpa1,<span class="dt">newdata=</span><span class="kw">data.frame</span>(<span class="dt">SATV=</span><span class="dv">30</span>,<span class="dt">SATM=</span><span class="dv">60</span>),<span class="dt">interval=</span><span class="st">&quot;prediction&quot;</span>)</code></pre></div>
<pre><code>##       fit       lwr      upr
## 1 2.11274 0.8145859 3.410894</code></pre>
<p>For a student with <em>SATV</em>=30 and <em>SATM</em>=60, we are 95% sure that their first year GPA will be between 0.81 and 3.4 points. You can see that while we are very certain about the mean in this situation, there is a lot of uncertainty in the predictions for individual students. The PI is so wide as to almost not be useful.</p>
<p>To support this difficulty in getting a precise prediction for a new student, review the original scatterplots: there is quite a bit of vertical variability in first year <em>GPA</em>s for each level of any of the predictors. The residual SE, <span class="math inline">\(\hat{\sigma}\)</span>, is also informative in this regard – remember that it is the standard deviation of the residuals around the regression line. It is 0.6582, so the SD of new observations around the line is 0.66 GPA points and that is pretty large on a GPA scale if we assume we would see lots of observations within 2 or 3 SDs of the mean. Figure <a href="chapter8.html#fig:Figure8-16">8.15</a> remakes both term-plots, holding the other predictor at its mean, and adds the 95% prediction intervals to show the difference in variability between estimating the mean and pinning down the value of a new observation. The R code is very messy and rarely needed, but hopefully this helps reinforce the differences in these two types of intervals – to make them in MLR, you have to fix all but one of the predictor variables and we usually do that by fixing the other variables at their means.</p>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Remake effects plots with 95% PIs</span>
dv1 &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">SATV=</span><span class="kw">seq</span>(<span class="dt">from=</span><span class="dv">24</span>,<span class="dt">to=</span><span class="dv">76</span>,<span class="dt">length.out=</span><span class="dv">50</span>), <span class="dt">SATM=</span><span class="kw">rep</span>(<span class="fl">54.4</span>,<span class="dv">50</span>))
dm1 &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">SATV=</span><span class="kw">rep</span>(<span class="fl">48.93</span>,<span class="dv">50</span>), <span class="dt">SATM=</span><span class="kw">seq</span>(<span class="dt">from=</span><span class="dv">29</span>,<span class="dt">to=</span><span class="dv">77</span>,<span class="dt">length.out=</span><span class="dv">50</span>))

mv1 &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="kw">predict</span>(gpa1, <span class="dt">newdata=</span>dv1, <span class="dt">interval=</span><span class="st">&quot;confidence&quot;</span>))
pv1 &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="kw">predict</span>(gpa1, <span class="dt">newdata=</span>dv1, <span class="dt">interval=</span><span class="st">&quot;prediction&quot;</span>))

mm1 &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="kw">predict</span>(gpa1, <span class="dt">newdata=</span>dm1, <span class="dt">interval=</span><span class="st">&quot;confidence&quot;</span>))
pm1 &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="kw">predict</span>(gpa1, <span class="dt">newdata=</span>dm1, <span class="dt">interval=</span><span class="st">&quot;prediction&quot;</span>))

<span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))

<span class="kw">plot</span>(dv1<span class="op">$</span>SATV, mv1<span class="op">$</span>fit, <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">ylim=</span><span class="kw">c</span>(pv1<span class="op">$</span>lwr[<span class="dv">1</span>],pv1<span class="op">$</span>upr[<span class="dv">50</span>]), <span class="dt">type=</span><span class="st">&quot;l&quot;</span>,
     <span class="dt">xlab=</span><span class="st">&quot;SATV Percentile&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;GPA&quot;</span>, <span class="dt">main=</span><span class="st">&quot;SATV Effect, CI and PI&quot;</span>)
<span class="kw">lines</span>(dv1<span class="op">$</span>SATV ,mv1<span class="op">$</span>lwr, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">lwd=</span><span class="dv">2</span>)
<span class="kw">lines</span>(dv1<span class="op">$</span>SATV, mv1<span class="op">$</span>upr, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">lwd=</span><span class="dv">2</span>)
<span class="kw">lines</span>(dv1<span class="op">$</span>SATV, pv1<span class="op">$</span>lwr, <span class="dt">col=</span><span class="st">&quot;grey&quot;</span>, <span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">lwd=</span><span class="dv">3</span>)
<span class="kw">lines</span>(dv1<span class="op">$</span>SATV, pv1<span class="op">$</span>upr, <span class="dt">col=</span><span class="st">&quot;grey&quot;</span>, <span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">lwd=</span><span class="dv">3</span>)
<span class="kw">legend</span>(<span class="st">&quot;topleft&quot;</span>, <span class="kw">c</span>(<span class="st">&quot;Estimate&quot;</span>, <span class="st">&quot;CI&quot;</span>,<span class="st">&quot;PI&quot;</span>), <span class="dt">lwd=</span><span class="dv">3</span>, <span class="dt">lty=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>),
       <span class="dt">col =</span> <span class="kw">c</span>(<span class="st">&quot;black&quot;</span>, <span class="st">&quot;red&quot;</span>,<span class="st">&quot;grey&quot;</span>))

<span class="kw">plot</span>(dm1<span class="op">$</span>SATM, mm1<span class="op">$</span>fit, <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">ylim=</span><span class="kw">c</span>(pm1<span class="op">$</span>lwr[<span class="dv">1</span>], pm1<span class="op">$</span>upr[<span class="dv">50</span>]), <span class="dt">type=</span><span class="st">&quot;l&quot;</span>,
     <span class="dt">xlab=</span><span class="st">&quot;SATM Percentile&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;GPA&quot;</span>, <span class="dt">main=</span><span class="st">&quot;SATM Effect, CI and PI&quot;</span>)
<span class="kw">lines</span>(dm1<span class="op">$</span>SATM, mm1<span class="op">$</span>lwr, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">lwd=</span><span class="dv">2</span>)
<span class="kw">lines</span>(dm1<span class="op">$</span>SATM, mm1<span class="op">$</span>upr, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">lwd=</span><span class="dv">2</span>)
<span class="kw">lines</span>(dm1<span class="op">$</span>SATM, pm1<span class="op">$</span>lwr, <span class="dt">col=</span><span class="st">&quot;grey&quot;</span>, <span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">lwd=</span><span class="dv">3</span>)
<span class="kw">lines</span>(dm1<span class="op">$</span>SATM, pm1<span class="op">$</span>upr, <span class="dt">col=</span><span class="st">&quot;grey&quot;</span>, <span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">lwd=</span><span class="dv">3</span>)</code></pre></div>
<div class="figure"><span id="fig:Figure8-16"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-16-1.png" alt="Term-plots for the \(\text{FYGPA}\sim\text{SATV} + \text{SATM}\) model with 95% PIs." width="672" />
<p class="caption">
Figure 8.15: Term-plots for the <span class="math inline">\(\text{FYGPA}\sim\text{SATV} + \text{SATM}\)</span> model with 95% PIs.
</p>
</div>
</div>
<div id="section8-9" class="section level2">
<h2><span class="header-section-number">8.9</span> Different intercepts for different groups: MLR with Indicator variables</h2>
<p>One of the implicit assumptions up to this point was that the models were being applied to a single homogeneous population. In many cases, we take a sample from a population but that group is likely a combination of individuals from different sub-populations. For example, the SAT study was interested in all students at the university but that contains the obvious sub-populations based on the sex of the students. It is dangerous to fit MLR models across subpopulations but we can also use MLR models to address more sophisticated research questions by comparing groups. We will be able to compare the intercepts (mean levels) and the slopes to see if they differ between the groups. For example, does the relationship between the <em>SATV</em> and <em>FYGPA</em> differ for male and female students? We can add the grouping information to the scatterplot of <em>FYGPA</em> vs <em>SATV</em> (Figure <a href="chapter8.html#fig:Figure8-17">8.16</a>) and consider whether there is visual evidence of a difference in the slope and/or intercept between the two groups, with men coded as 1 and women coded as 2<a href="#fn80" class="footnoteRef" id="fnref80"><sup>80</sup></a>.</p>
<p>It appears that the slope for females might be larger (steeper) in this relationship than it is for males. So increases in SAT Verbal percentiles for females might have more of an impact on the average first year GPA. We’ll handle this sort of situation in Section <a href="chapter8.html#section8-11">8.11</a>, where we will formally consider how to change the slopes for different groups. In this section, we develop new methods needed to begin to handle these situations and explore creating models with the same slope coefficient for all groups but different y-intercepts. This material resembles what we did for the Two-Way ANOVA additive model.</p>
<p>These results contrastwith Figure <a href="chapter8.html#fig:Figure8-18">8.17</a> for the relationship between first year college <em>GPA</em> and <em>SATM</em> percentile by sex of the students. The lines for the two groups appear to be mostly parallel and just seem to have different y-intercepts. We can use our MLR techniques to fit a model to the entire data set that allows for different y-intercepts. The real power of this idea is that we can then also test whether the different groups have different y-intercepts – whether the shift between the groups is “real”. In this example, it appears to suggest that females generally have slightly higher GPAs than males, on average, but that an increase in SATM has the same impact for both groups. If this difference in y-intercepts is not “real”, then there appears to be no difference between the sexes in their relationship between SATM and GPA and we can safely continue using a model that does not differentiate the two groups. We could also just subset the data set and do two analyses, but that approach will not allow us to assess whether things are “really” different between the two groups.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">scatterplot</span>(FYGPA<span class="op">~</span>SATV<span class="op">|</span>sex, <span class="dt">lwd=</span><span class="dv">3</span>, <span class="dt">data=</span>satGPA, <span class="dt">spread=</span>F,
            <span class="dt">smooth=</span>F, <span class="dt">main=</span><span class="st">&quot;Scatterplot of GPA vs SATV by Sex&quot;</span>)
<span class="kw">scatterplot</span>(FYGPA<span class="op">~</span>SATM<span class="op">|</span>sex, <span class="dt">lwd=</span><span class="dv">3</span>, <span class="dt">data=</span>satGPA, <span class="dt">spread=</span>F,
            <span class="dt">smooth=</span>F, <span class="dt">main=</span><span class="st">&quot;Scatterplot of GPA vs SATM by Sex&quot;</span>)</code></pre></div>

<div class="figure"><span id="fig:Figure8-17"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-17-1.png" alt="Plot of FYGPA vs SATV by Sex of students." width="672" />
<p class="caption">
Figure 8.16: Plot of FYGPA vs SATV by Sex of students.
</p>
</div>

<div class="figure"><span id="fig:Figure8-18"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-18-1.png" alt="Plot of FYGPA vs SATM by Sex of students." width="672" />
<p class="caption">
Figure 8.17: Plot of FYGPA vs SATM by Sex of students.
</p>
</div>
<p>To fit one model to a data set that contain multiple groups, we need a way of entering categorical variable information in an MLR model. Regression models require quantitative predictor variables for the <span class="math inline">\(x\text{&#39;s}\)</span> so we can’t directly enter the sex of the students into the regression model since it contains categories. To be able to put in “numbers” as predictors, we create what are called <strong><em>indicator variables</em></strong><a href="#fn81" class="footnoteRef" id="fnref81"><sup>81</sup></a> that are made up of 0s and 1s, with the 0 reflecting one category and 1 the other, changing depending on the category of the individual in the data set. The <code>lm</code> function does this for whenever a categorical variable is used as an explanatory variable. It sets up the indicator variables using a baseline category (gets coded as a 0) and the deviation category for the other level of the variable. We can see how this works by exploring what happens when we put <code>SEX</code> into our <code>lm</code><a href="#fn82" class="footnoteRef" id="fnref82"><sup>82</sup></a> with SATM, after first making sure it is categorical using the <code>factor</code> function and making the group <code>levels</code> explicit instead of 1s and 2s.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">satGPA<span class="op">$</span>SEX &lt;-<span class="st"> </span><span class="kw">factor</span>(satGPA<span class="op">$</span>sex)
<span class="kw">levels</span>(satGPA<span class="op">$</span>SEX) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;MALE&quot;</span>, <span class="st">&quot;FEMALE&quot;</span>)
SATSex1 &lt;-<span class="st"> </span><span class="kw">lm</span>(FYGPA<span class="op">~</span>SATM<span class="op">+</span>SEX, <span class="dt">data=</span>satGPA)
<span class="kw">summary</span>(SATSex1)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = FYGPA ~ SATM + SEX, data = satGPA)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.42124 -0.42363  0.01868  0.46540  1.66397 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)  0.21589    0.14858   1.453    0.147
## SATM         0.03861    0.00258  14.969  &lt; 2e-16
## SEXFEMALE    0.31322    0.04360   7.184 1.32e-12
## 
## Residual standard error: 0.6667 on 997 degrees of freedom
## Multiple R-squared:  0.1917, Adjusted R-squared:  0.1901 
## F-statistic: 118.2 on 2 and 997 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>The <code>SEX</code> row contains information that the linear model chose <em>MALE</em> as the baseline category and <em>FEMALE</em> as the deviation category since <em>MALE</em> does not show up in the output. To see what <code>lm</code> is doing for us when we give it a two-level categorical variable, we can create our own “numerical” predictor that is 0 for <em>males</em> and 1 for <em>females</em> that we called <code>SEXINDICATOR</code>, displayed for the first 10 observations:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">satGPA<span class="op">$</span>SEXINDICATOR &lt;-<span class="st"> </span><span class="kw">as.numeric</span>(satGPA<span class="op">$</span>SEX<span class="op">==</span><span class="st">&quot;FEMALE&quot;</span>)
<span class="kw">head</span>(<span class="kw">data.frame</span>(<span class="dt">SEX=</span>satGPA<span class="op">$</span>SEX, <span class="dt">SEXINDICATOR=</span>satGPA<span class="op">$</span>SEXINDICATOR), <span class="dv">10</span>)</code></pre></div>
<pre><code>##       SEX SEXINDICATOR
## 1    MALE            0
## 2  FEMALE            1
## 3  FEMALE            1
## 4    MALE            0
## 5    MALE            0
## 6  FEMALE            1
## 7    MALE            0
## 8    MALE            0
## 9  FEMALE            1
## 10   MALE            0</code></pre>
<p>We can define the indicator variable more generally by calling it <span class="math inline">\(\boldsymbol{I}_{\text{Female},i}\)</span> to denote that it is an indicator (<span class="math inline">\(\boldsymbol{I}\)</span>) that takes on a value of 1 for observations in the category <em>Female</em> and 0 otherwise (<em>Male</em>) – changing based on the observation (<span class="math inline">\(i\)</span>). Indicator variables, once created, are quantitative variables that take on values of 0 or 1 and we can put them directly into linear models with other <span class="math inline">\(x\text{&#39;s}\)</span> (quantitative or categorical). If we replace the categorical <code>SEX</code> variable with our quantitative <code>SEXINDICATOR</code> and re-fit the model, we get:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">SATSex2 &lt;-<span class="st"> </span><span class="kw">lm</span>(FYGPA<span class="op">~</span>SATM<span class="op">+</span>SEXINDICATOR, <span class="dt">data=</span>satGPA)
<span class="kw">summary</span>(SATSex2)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = FYGPA ~ SATM + SEXINDICATOR, data = satGPA)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.42124 -0.42363  0.01868  0.46540  1.66397 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)   0.21589    0.14858   1.453    0.147
## SATM          0.03861    0.00258  14.969  &lt; 2e-16
## SEXINDICATOR  0.31322    0.04360   7.184 1.32e-12
## 
## Residual standard error: 0.6667 on 997 degrees of freedom
## Multiple R-squared:  0.1917, Adjusted R-squared:  0.1901 
## F-statistic: 118.2 on 2 and 997 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>This matches all the previous <code>lm</code> output except that we didn’t get any information on the categories used since <code>lm</code> didn’t know that SEXINDICATOR was anything different from other quantitative predictors.</p>
<p>Now we want to think about what this model means. We can write the estimated model as</p>
<p><span class="math display">\[\widehat{\text{FYGPA}}_i = 0.216 + 0.0386\text{ SATM}_i +
0.313I_{\text{Female},i}.\]</span></p>
<p>When we have a <em>male</em> observation, the indicator takes on a value of 0 so the 0.313 drops out of the model, leaving an SLR just in terms of <em>SATM</em>. For a <em>female</em> student, the indicator is 1 and we add 0.313 to the previous y-intercept. The following works this out step-by-step, simplifying the MLR into two SLRs:</p>
<ul>
<li><p>Simplified model for <em>Males</em> (plug in a 0 for <span class="math inline">\(I_{\text{Female}}\)</span>):</p>
<ul>
<li><span class="math inline">\(\widehat{\text{FYGPA}}_i = 0.216 + 0.0386\text{ SATM}_i + 0.313*0 = 0.216 + 0.0386\text{ SATM}_i\)</span></li>
</ul></li>
<li><p>Simplified model for <em>Females</em> (plug in a 1 for <span class="math inline">\(I_{\text{Female}}\)</span>):</p>
<ul>
<li><p><span class="math inline">\(\widehat{\text{FYGPA}}_i = 0.216 + 0.0386\text{ SATM}_i + 0.313I*1\)</span></p></li>
<li><p><span class="math inline">\(= 0.216 + 0.0386\text{ SATM}_i + 0.313\)</span> (combine “like” terms to simplify the equation)</p></li>
<li><p><span class="math inline">\(= 0.529 + 0.0386\text{ SATM}_i\)</span></p></li>
</ul></li>
</ul>
<p>In this situation, we then end up with two SLR models that relate <em>SATM</em> to <em>GPA</em>, one model for <em>males</em> <span class="math inline">\((\widehat{\text{FYGPA}}_i= 0.216 + 0.0386\text{ SATM}_i)\)</span> and one for <em>females</em> <span class="math inline">\((\widehat{\text{FYGPA}}_i= 0.529 + 0.0386\text{ SATM}_i)\)</span>. The only difference between these two models is in the y-intercept, with the <em>female</em> model’s y-intercept shifted up from the <em>male</em> y-intercept by 0.313. And that is what adding indicator variables into models does in general<a href="#fn83" class="footnoteRef" id="fnref83"><sup>83</sup></a> – it shifts the intercept up or down from the baseline group (here selected as <em>males</em>) to get a new intercept for the deviation group (here <em>females</em>).</p>
<p>To make this visually clearer, Figure <a href="chapter8.html#fig:Figure8-19">8.18</a> contains the regression lines that were estimated for each group. For any <em>SATM</em>, the differencein the groups is the 0.313 coefficient from the <code>SEXFEMALE</code> or <code>SEXINDICATOR</code> row of the model summaries. For example, at <em>SATM</em>=50, the difference in terms of predicted average first year GPAs between males and females is displayed as a difference between 2.15 and 2.46. This model assumes that the slope on <em>SATM</em> is the same for both groups except that they are allowed to have different y-intercepts, which is reasonable here because we saw approximately parallel relationships for the two groups in Figure <a href="chapter8.html#fig:Figure8-18">8.17</a>.</p>

<div class="figure"><span id="fig:Figure8-19"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-19-1.png" alt="Plot of estimated model for FYGPA vs SATM by SEX of students (female line is red, bold)." width="672" />
<p class="caption">
Figure 8.18: Plot of estimated model for <em>FYGPA</em> vs <em>SATM</em> by <em>SEX</em> of students (female line is red, bold).
</p>
</div>
<p>Remember that <code>lm</code> selects baseline categories typically based on the alphabetical order of the levels of the categorical variable. Here, the <code>SEX</code> variable started with a coding of 1 and 2 and retained that order even with the recoding of levels that we created to give it more explicit names. Because we allow <code>lm</code> to create indicator variables for us, the main thing you need to do is explore the model summary and look for the hint at the baseline level that is not displayed after the name of the categorical variable.</p>
<p>We can also work out the impacts of adding an indicator variable to the model in general in the theoretical model with a single quantitative predictor <span class="math inline">\(x_i\)</span> and indicator <span class="math inline">\(I_i\)</span>. The model starts as</p>
<p><span class="math display">\[y_i=\beta_0+\beta_1x_i + \beta_2I_i + \varepsilon_i.\]</span></p>
<p>Again, there are two versions:</p>
<ul>
<li><p>For any observation <span class="math inline">\(i\)</span> in the <strong>baseline</strong> category, <span class="math inline">\(I_i=0\)</span> and the model is <span class="math inline">\(y_i=\beta_0+\beta_1x_i + \varepsilon_i\)</span>.</p></li>
<li><p>For any observation <span class="math inline">\(i\)</span> in the <strong>non-baseline (deviation)</strong> category, <span class="math inline">\(I_i=1\)</span> and the model simplifies to <span class="math inline">\(y_i=(\beta_0+\beta_2)+\beta_1x_i + \varepsilon_i\)</span>.</p>
<ul>
<li>This model has a y-intercept of <span class="math inline">\(\beta_0+\beta_2\)</span>.</li>
</ul></li>
</ul>
<p>The interpretation and inferences for <span class="math inline">\(\beta_1\)</span> resemble the work with any MLR model, noting that these results are “controlled for”, “adjusted for”, or “allowing for differences based on” the categorical variable in the model. The interpretation of <span class="math inline">\(\beta_2\)</span> is as a shift up or down in the y-intercept for the model that includes <span class="math inline">\(x_i\)</span>. When we make term-plot in a model with a quantitative and additive categorical variable, the two reported model components match with the previous discussion – the same estimated term from the quantitative variable for all observations and a shift to reflect the different y-intercepts in the two groups. In Figure <a href="chapter8.html#fig:Figure8-20">8.19</a>, the females are estimated to be that same 0.313 points higher on first year GPA. The males have a mean GPA slightly above 2.3 which is the predicted GPA for the average SATM percentile (remember that we have to hold the other variable at its mean to make each term-plot)<a href="#fn84" class="footnoteRef" id="fnref84"><sup>84</sup></a>.</p>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">require</span>(effects)
<span class="kw">plot</span>(<span class="kw">allEffects</span>(SATSex1))</code></pre></div>
<div class="figure"><span id="fig:Figure8-20"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-20-1.png" alt="Term-plots for the estimated model for \(\text{FYGPA}\sim\text{SATM} + \text{SEX}\)." width="672" />
<p class="caption">
Figure 8.19: Term-plots for the estimated model for <span class="math inline">\(\text{FYGPA}\sim\text{SATM} + \text{SEX}\)</span>.
</p>
</div>
<p>The model summary and confidence intervals provide some potential interesting inferences in these models. Again, these are just applications of MLR methods we have already seen except that the definition of one of the variables is “different” using the indicator coding idea. For the same model, the <code>SEX</code> coefficient can be used to generate inferences for differences in the mean the groups, controlling for their <em>SATM</em> scores.</p>
<pre><code>## SEXFEMALE    0.31322    0.04360   7.184 1.32e-12</code></pre>
<p>Testing the null hypothesis that <span class="math inline">\(H_0: \beta_2=0\)</span> vs <span class="math inline">\(H_A: \beta_2\ne 0\)</span> using our regular <span class="math inline">\(t\)</span>-test provides the opportunity to test for a difference in intercepts between the groups. In this situation, the test statistic is <span class="math inline">\(t=7.184\)</span> and, based on a <span class="math inline">\(t_{997}\)</span>-distribution if the null is true, the p-value is <span class="math inline">\(&lt;0.0001\)</span>. We can reject the null hypothesis because the chances of getting a difference in y-intercepts extreme or more extreme than what was observed is extremely small. Thus, we can conclude that there is evidence that there is a difference in the true y-intercept in a <em>SATM</em> model between <em>males</em> and <em>females</em>. The confidence interval is also informative:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">confint</span>(SATSex1)</code></pre></div>
<pre><code>##                   2.5 %     97.5 %
## (Intercept) -0.07566665 0.50744709
## SATM         0.03355273 0.04367726
## SEXFEMALE    0.22766284 0.39877160</code></pre>
<p>We are 95% confident that the true mean GPA for females is between 0.228 and 0.399 points higher than for males, after adjusting for the <em>SATM</em> in the population of students. If we had subset the data set and fit two SLRs, we could have obtained the same simplified regression models but we never could have performed inferences for the differences between the two groups without putting all the observations together in one model and then assessing those differences with targeted coefficients. We also would not be able to get an estimate of their common slope for <em>SATM</em>, after adjusting for differences in the intercept for each group.</p>
</div>
<div id="section8-10" class="section level2">
<h2><span class="header-section-number">8.10</span> Additive MLR with more than two groups: Headache example</h2>
</div>
<div id="section8-11" class="section level2">
<h2><span class="header-section-number">8.11</span> Different slopes and different intercepts</h2>
</div>
<div id="section8-12" class="section level2">
<h2><span class="header-section-number">8.12</span> F-tests for MLR models with quantitative and categorical variables and interactions</h2>
</div>
<div id="section8-13" class="section level2">
<h2><span class="header-section-number">8.13</span> AICs for model selection</h2>
</div>
<div id="section8-14" class="section level2">
<h2><span class="header-section-number">8.14</span> Forced Expiratory Volume model selection using AICs</h2>
</div>
<div id="section8-15" class="section level2">
<h2><span class="header-section-number">8.15</span> Chapter summary</h2>
</div>
<div id="section8-16" class="section level2">
<h2><span class="header-section-number">8.16</span> Important R code</h2>
</div>
<div id="section8-17" class="section level2">
<h2><span class="header-section-number">8.17</span> Practice problems</h2>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="69">
<li id="fn69"><p>If you take advanced applied mathematics courses, you can learn more about the algorithms being used by <code>lm</code>. Everyone else only cares about the algorithms when they don’t work – which is usually due to the user’s inputs in these models not the algorithm itself.<a href="chapter8.html#fnref69">↩</a></p></li>
<li id="fn70"><p>Sometimes the effects plots ignores the edge explanatory observations with the default display. Always check the original variable summaries when considering the range of observed values. The code modifications used to make these plots are a little annoying and can be avoided if you remember to check the original summary statistics or scatterplots for variable extrema.<a href="chapter8.html#fnref70">↩</a></p></li>
<li id="fn71"><p>We used this same notation in the fitting the additive Two-Way ANOVA and this is also additive in terms of these variables. Interaction models are discussed later in the chapter.<a href="chapter8.html#fnref71">↩</a></p></li>
<li id="fn72"><p>Imagine showing up to a ski area expecting a 40 inch base and there only being 11 inches. I’m sure ski areas are always more accurate than this model in their reporting of amounts of snow on the ground…<a href="chapter8.html#fnref72">↩</a></p></li>
<li id="fn73"><p>The site name is redacted to protect the innocence of the reader. More information on this site, located in Beaverhead County, is available at <a href="http://www.wcc.nrcs.usda.gov/nwcc/site?sitenum=355&amp;state=mt" class="uri">http://www.wcc.nrcs.usda.gov/nwcc/site?sitenum=355&amp;state=mt</a>.<a href="chapter8.html#fnref73">↩</a></p></li>
<li id="fn74"><p>The <code>seq</code> function has syntax of <code>seq(from=startingpoint, to=endingpoint, length.out=#ofvalues_between_start_and_end)</code> and the <code>rep</code> function has syntax of <code>rep(numbertorepeat, #oftimes).</code><a href="chapter8.html#fnref74">↩</a></p></li>
<li id="fn75"><p>Also see Section <a href="chapter8.html#section8-13">8.13</a> for another method of picking among different models.<a href="chapter8.html#fnref75">↩</a></p></li>
<li id="fn76"><p>This section was inspired by a similar section from De Veaux, Velleman, and Bock (2011).<a href="chapter8.html#fnref76">↩</a></p></li>
<li id="fn77"><p>There are some social science models where the model is fit with the mean subtracted from each predictor so all have mean 0 and the precision of the y-intercept is interesting. But even in these models, the test the y-intercept being 0 is rarely of interest.<a href="chapter8.html#fnref77">↩</a></p></li>
<li id="fn78"><p>Either someone had a weighted GPA with bonus points, or more likely here, there was a coding error in the data set since only one observations was over 4.0 in the GPA data. Either way, we could remove it and note that our inferences for HSGPA do not extend above 4.0.<a href="chapter8.html#fnref78">↩</a></p></li>
<li id="fn79"><p>When there are just two predictors, the VIFs have to be the same since the proportion of information shared is the same in both directions. With more than two predictors, each variable can have a different VIF value.<a href="chapter8.html#fnref79">↩</a></p></li>
<li id="fn80"><p>We are actually making an educated guess about what these codes mean. Other similar data sets used 1 for males but the documentation on these data is a bit sparse. We can proceed with a small potential that all conclusions regarding differences in <code>sex</code> are in the wrong direction.<a href="chapter8.html#fnref80">↩</a></p></li>
<li id="fn81"><p>Some people also call them <strong><em>dummy variables</em></strong>.<a href="chapter8.html#fnref81">↩</a></p></li>
<li id="fn82"><p>That may not read how we intended…<a href="chapter8.html#fnref82">↩</a></p></li>
<li id="fn83"><p>This is true for additive uses of indicator variables. In Section <a href="chapter8.html#section8-11">8.11</a>, we consider interactions between quantitative and categorical variables which has the effect of changing slopes and intercepts. The simplification ideas to produce estimated equations for each group are used there but we have to account for changing slopes by group too.<a href="chapter8.html#fnref83">↩</a></p></li>
<li id="fn84"><p>When making the SATM term-plot, the categorical variable is held at the most frequently occurring value in the data set. If you drop <code>ci.style=&quot;lines&quot;</code> from the effect plot options, it is best to copy the figures as Bitmaps or save them as an image or they may (for some reason) lose the shaded bands.<a href="chapter8.html#fnref84">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="chapter7.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="chapter9.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
