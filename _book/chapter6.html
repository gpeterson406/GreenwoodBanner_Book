<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>A Second Semester Statistics Course with R</title>
  <meta name="description" content="A Second Semester Statistics Course with R">
  <meta name="generator" content="bookdown 0.4 and GitBook 2.6.7">

  <meta property="og:title" content="A Second Semester Statistics Course with R" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="gpeterson406/GreenwoodBanner_Book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="A Second Semester Statistics Course with R" />
  
  
  

<meta name="author" content="Mark Greenwood and Katherine Banner">


<meta name="date" content="2017-06-30">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="chapter5.html">
<link rel="next" href="chapter7.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Acknowledgments</a></li>
<li class="chapter" data-level="1" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i><b>1</b> Preface</a><ul>
<li class="chapter" data-level="1.1" data-path="preface.html"><a href="preface.html#overview-of-methods"><i class="fa fa-check"></i><b>1.1</b> Overview of methods</a></a></li>
<li class="chapter" data-level="1.2" data-path="preface.html"><a href="preface.html#getting-started-in-r"><i class="fa fa-check"></i><b>1.2</b> Getting started in R</a></li>
<li class="chapter" data-level="1.3" data-path="preface.html"><a href="preface.html#basic-summary-statistics-histograms-and-boxplots-using-r"><i class="fa fa-check"></i><b>1.3</b> Basic summary statistics, histograms, and boxplots using R</a></li>
<li class="chapter" data-level="1.4" data-path="preface.html"><a href="preface.html#chapter-summary"><i class="fa fa-check"></i><b>1.4</b> Chapter summary</a></li>
<li class="chapter" data-level="1.5" data-path="preface.html"><a href="preface.html#important-r-code"><i class="fa fa-check"></i><b>1.5</b> Important R Code</a></li>
<li class="chapter" data-level="1.6" data-path="preface.html"><a href="preface.html#practice-problems"><i class="fa fa-check"></i><b>1.6</b> Practice problems</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="chapter2.html"><a href="chapter2.html"><i class="fa fa-check"></i><b>2</b> (R)e-Introduction to statistics</a><ul>
<li class="chapter" data-level="2.1" data-path="chapter2.html"><a href="chapter2.html#section2-1"><i class="fa fa-check"></i><b>2.1</b> Histograms, boxplots, and density curves</a></li>
<li class="chapter" data-level="2.2" data-path="chapter2.html"><a href="chapter2.html#section2-2"><i class="fa fa-check"></i><b>2.2</b> Beanplots</a></li>
<li class="chapter" data-level="2.3" data-path="chapter2.html"><a href="chapter2.html#section2-3"><i class="fa fa-check"></i><b>2.3</b> Models, hypotheses, and permutations for the 2 sample mean situation</a></li>
<li class="chapter" data-level="2.4" data-path="chapter2.html"><a href="chapter2.html#section2-4"><i class="fa fa-check"></i><b>2.4</b> Permutation testing for the 2 sample mean situation</a></li>
<li class="chapter" data-level="2.5" data-path="chapter2.html"><a href="chapter2.html#section2-5"><i class="fa fa-check"></i><b>2.5</b> Hypothesis testing (general)</a></li>
<li class="chapter" data-level="2.6" data-path="chapter2.html"><a href="chapter2.html#section2-6"><i class="fa fa-check"></i><b>2.6</b> Connecting randomization (nonparametric) and parametric tests</a></li>
<li class="chapter" data-level="2.7" data-path="chapter2.html"><a href="chapter2.html#section2-7"><i class="fa fa-check"></i><b>2.7</b> Second example of permutation tests</a></li>
<li class="chapter" data-level="2.8" data-path="chapter2.html"><a href="chapter2.html#section2-8"><i class="fa fa-check"></i><b>2.8</b> Confidence intervals and bootstrapping</a></li>
<li class="chapter" data-level="2.9" data-path="chapter2.html"><a href="chapter2.html#section2-9"><i class="fa fa-check"></i><b>2.9</b> Bootstrap confidence intervals for difference in GPAs</a></li>
<li class="chapter" data-level="2.10" data-path="chapter2.html"><a href="chapter2.html#section2-10"><i class="fa fa-check"></i><b>2.10</b> Chapter summary</a></li>
<li class="chapter" data-level="2.11" data-path="chapter2.html"><a href="chapter2.html#section2-11"><i class="fa fa-check"></i><b>2.11</b> Summary of important R code</a></li>
<li class="chapter" data-level="2.12" data-path="chapter2.html"><a href="chapter2.html#section2-12"><i class="fa fa-check"></i><b>2.12</b> Practice problems</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="chapter3.html"><a href="chapter3.html"><i class="fa fa-check"></i><b>3</b> One-Way ANOVA</a><ul>
<li class="chapter" data-level="3.1" data-path="chapter3.html"><a href="chapter3.html#section3-1"><i class="fa fa-check"></i><b>3.1</b> Situation</a></li>
<li class="chapter" data-level="3.2" data-path="chapter3.html"><a href="chapter3.html#section3-2"><i class="fa fa-check"></i><b>3.2</b> Linear model for One-Way ANOVA (cell-means and reference-coding)</a></li>
<li class="chapter" data-level="3.3" data-path="chapter3.html"><a href="chapter3.html#section3-3"><i class="fa fa-check"></i><b>3.3</b> One-Way ANOVA Sums of Squares, Mean Squares, and F-test</a></li>
<li class="chapter" data-level="3.4" data-path="chapter3.html"><a href="chapter3.html#section3-4"><i class="fa fa-check"></i><b>3.4</b> ANOVA model diagnostics including QQ-plots</a></li>
<li class="chapter" data-level="3.5" data-path="chapter3.html"><a href="chapter3.html#section3-5"><i class="fa fa-check"></i><b>3.5</b> Guinea pig tooth growth One-Way ANOVA example</a></li>
<li class="chapter" data-level="3.6" data-path="chapter3.html"><a href="chapter3.html#section3-6"><i class="fa fa-check"></i><b>3.6</b> Multiple (pair-wise) comparisons using Tukey’s HSD and the compact letter display</a></li>
<li class="chapter" data-level="3.7" data-path="chapter3.html"><a href="chapter3.html#section3-7"><i class="fa fa-check"></i><b>3.7</b> Pair-wise comparisons for Prisoner Rating data</a></li>
<li class="chapter" data-level="3.8" data-path="chapter3.html"><a href="chapter3.html#section3-8"><i class="fa fa-check"></i><b>3.8</b> Chapter Summary</a></li>
<li class="chapter" data-level="3.9" data-path="chapter3.html"><a href="chapter3.html#section3-9"><i class="fa fa-check"></i><b>3.9</b> Summary of important R code</a></li>
<li class="chapter" data-level="3.10" data-path="chapter3.html"><a href="chapter3.html#section3-10"><i class="fa fa-check"></i><b>3.10</b> Practice problems</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="chapter4.html"><a href="chapter4.html"><i class="fa fa-check"></i><b>4</b> Two-Way ANOVA</a><ul>
<li class="chapter" data-level="4.1" data-path="chapter4.html"><a href="chapter4.html#section4-1"><i class="fa fa-check"></i><b>4.1</b> Situation</a></li>
<li class="chapter" data-level="4.2" data-path="chapter4.html"><a href="chapter4.html#section4-2"><i class="fa fa-check"></i><b>4.2</b> Designing a two-way experiment and visualizing results</a></li>
<li class="chapter" data-level="4.3" data-path="chapter4.html"><a href="chapter4.html#section4-3"><i class="fa fa-check"></i><b>4.3</b> Two-Way ANOVA models and hypothesis tests</a></li>
<li class="chapter" data-level="4.4" data-path="chapter4.html"><a href="chapter4.html#section4-4"><i class="fa fa-check"></i><b>4.4</b> Guinea pig tooth growth analysis with Two-Way ANOVA</a></li>
<li class="chapter" data-level="4.5" data-path="chapter4.html"><a href="chapter4.html#section4-5"><i class="fa fa-check"></i><b>4.5</b> Observational study example: The Psychology of Debt</a></li>
<li class="chapter" data-level="4.6" data-path="chapter4.html"><a href="chapter4.html#section4-6"><i class="fa fa-check"></i><b>4.6</b> Pushing Two-Way ANOVA to the limit: Un-replicated designs</a></li>
<li class="chapter" data-level="4.7" data-path="chapter4.html"><a href="chapter4.html#section4-7"><i class="fa fa-check"></i><b>4.7</b> Chapter summary</a></li>
<li class="chapter" data-level="4.8" data-path="chapter4.html"><a href="chapter4.html#section4-8"><i class="fa fa-check"></i><b>4.8</b> Important R code</a></li>
<li class="chapter" data-level="4.9" data-path="chapter4.html"><a href="chapter4.html#section4-9"><i class="fa fa-check"></i><b>4.9</b> Practice problems</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="chapter5.html"><a href="chapter5.html"><i class="fa fa-check"></i><b>5</b> Chi-square tests</a><ul>
<li class="chapter" data-level="5.1" data-path="chapter5.html"><a href="chapter5.html#section5-1"><i class="fa fa-check"></i><b>5.1</b> Situation, contingency tables, and plots</a></li>
<li class="chapter" data-level="5.2" data-path="chapter5.html"><a href="chapter5.html#section5-2"><i class="fa fa-check"></i><b>5.2</b> Homogeneity Test Hypotheses</a></li>
<li class="chapter" data-level="5.3" data-path="chapter5.html"><a href="chapter5.html#section5-3"><i class="fa fa-check"></i><b>5.3</b> Independence Test Hypotheses</a></li>
<li class="chapter" data-level="5.4" data-path="chapter5.html"><a href="chapter5.html#section5-4"><i class="fa fa-check"></i><b>5.4</b> Models for R by C tables</a></li>
<li class="chapter" data-level="5.5" data-path="chapter5.html"><a href="chapter5.html#section5-5"><i class="fa fa-check"></i><b>5.5</b> Permutation tests for the <span class="math inline">\(X^2\)</span> statistic</a></li>
<li class="chapter" data-level="5.6" data-path="chapter5.html"><a href="chapter5.html#section5-6"><i class="fa fa-check"></i><b>5.6</b> Chi-square distribution for the <span class="math inline">\(X^2\)</span> statistic</a></li>
<li class="chapter" data-level="5.7" data-path="chapter5.html"><a href="chapter5.html#section5-7"><i class="fa fa-check"></i><b>5.7</b> Examining residuals for the source of differences</a></li>
<li class="chapter" data-level="5.8" data-path="chapter5.html"><a href="chapter5.html#section5-8"><i class="fa fa-check"></i><b>5.8</b> General Protocol for <span class="math inline">\(X^2\)</span> tests</a></li>
<li class="chapter" data-level="5.9" data-path="chapter5.html"><a href="chapter5.html#section5-9"><i class="fa fa-check"></i><b>5.9</b> Political Party and Voting results: Complete Analysis</a></li>
<li class="chapter" data-level="5.10" data-path="chapter5.html"><a href="chapter5.html#section5-10"><i class="fa fa-check"></i><b>5.10</b> Is cheating and lying related in students?</a></li>
<li class="chapter" data-level="5.11" data-path="chapter5.html"><a href="chapter5.html#section5-11"><i class="fa fa-check"></i><b>5.11</b> Analyzing a stratified random sample of California schools</a></li>
<li class="chapter" data-level="5.12" data-path="chapter5.html"><a href="chapter5.html#section5-12"><i class="fa fa-check"></i><b>5.12</b> Chapter summary</a></li>
<li class="chapter" data-level="5.13" data-path="chapter5.html"><a href="chapter5.html#section5-13"><i class="fa fa-check"></i><b>5.13</b> Review of Important R commands</a></li>
<li class="chapter" data-level="5.14" data-path="chapter5.html"><a href="chapter5.html#section5-14"><i class="fa fa-check"></i><b>5.14</b> Practice problems</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="chapter6.html"><a href="chapter6.html"><i class="fa fa-check"></i><b>6</b> Correlation and Simple Linear Regression</a><ul>
<li class="chapter" data-level="6.1" data-path="chapter6.html"><a href="chapter6.html#section6-1"><i class="fa fa-check"></i><b>6.1</b> Relationships between two quantitative variables</a></li>
<li class="chapter" data-level="6.2" data-path="chapter6.html"><a href="chapter6.html#section6-2"><i class="fa fa-check"></i><b>6.2</b> Estimating the correlation coefficient</a></li>
<li class="chapter" data-level="6.3" data-path="chapter6.html"><a href="chapter6.html#section6-3"><i class="fa fa-check"></i><b>6.3</b> Relationships between variables by groups</a></li>
<li class="chapter" data-level="6.4" data-path="chapter6.html"><a href="chapter6.html#section6-4"><i class="fa fa-check"></i><b>6.4</b> Inference for the correlation coefficient (Optional Section)</a></li>
<li class="chapter" data-level="6.5" data-path="chapter6.html"><a href="chapter6.html#section6-5"><i class="fa fa-check"></i><b>6.5</b> Are tree diameters related to tree heights?</a></li>
<li class="chapter" data-level="6.6" data-path="chapter6.html"><a href="chapter6.html#section6-6"><i class="fa fa-check"></i><b>6.6</b> Describing relationships with a regression model</a></li>
<li class="chapter" data-level="6.7" data-path="chapter6.html"><a href="chapter6.html#section6-7"><i class="fa fa-check"></i><b>6.7</b> Least Squares Estimation</a></li>
<li class="chapter" data-level="6.8" data-path="chapter6.html"><a href="chapter6.html#section6-8"><i class="fa fa-check"></i><b>6.8</b> Measuring the strength of regressions: R2</a></li>
<li class="chapter" data-level="6.9" data-path="chapter6.html"><a href="chapter6.html#section6-9"><i class="fa fa-check"></i><b>6.9</b> Outliers: leverage and influence</a></li>
<li class="chapter" data-level="6.10" data-path="chapter6.html"><a href="chapter6.html#section6-10"><i class="fa fa-check"></i><b>6.10</b> Residual diagnostics – setting the stage for inference</a></li>
<li class="chapter" data-level="6.11" data-path="chapter6.html"><a href="chapter6.html#section6-11"><i class="fa fa-check"></i><b>6.11</b> Old Faithful discharge and waiting times</a></li>
<li class="chapter" data-level="6.12" data-path="chapter6.html"><a href="chapter6.html#section6-12"><i class="fa fa-check"></i><b>6.12</b> Chapter summary</a></li>
<li class="chapter" data-level="6.13" data-path="chapter6.html"><a href="chapter6.html#section6-13"><i class="fa fa-check"></i><b>6.13</b> Important R code</a></li>
<li class="chapter" data-level="6.14" data-path="chapter6.html"><a href="chapter6.html#section6-14"><i class="fa fa-check"></i><b>6.14</b> Practice problems</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="chapter7.html"><a href="chapter7.html"><i class="fa fa-check"></i><b>7</b> Simple linear regression inference</a><ul>
<li class="chapter" data-level="7.1" data-path="chapter7.html"><a href="chapter7.html#section7-1"><i class="fa fa-check"></i><b>7.1</b> Model</a></li>
<li class="chapter" data-level="7.2" data-path="chapter7.html"><a href="chapter7.html#section7-2"><i class="fa fa-check"></i><b>7.2</b> Confidence Interval and Hypothesis tests for the slope and intercept</a></li>
<li class="chapter" data-level="7.3" data-path="chapter7.html"><a href="chapter7.html#section7-3"><i class="fa fa-check"></i><b>7.3</b> Bozeman temperature trend</a></li>
<li class="chapter" data-level="7.4" data-path="chapter7.html"><a href="chapter7.html#section7-4"><i class="fa fa-check"></i><b>7.4</b> Randomizing inferences for the slope coefficient</a></li>
<li class="chapter" data-level="7.5" data-path="chapter7.html"><a href="chapter7.html#section7-5"><i class="fa fa-check"></i><b>7.5</b> Transformations part I: Linearizing relationships</a></li>
<li class="chapter" data-level="7.6" data-path="chapter7.html"><a href="chapter7.html#section7-6"><i class="fa fa-check"></i><b>7.6</b> Transformations part II: Impacts on SLR interpretations: log(y), log(x), &amp; both log(y) &amp; log(x)</a></li>
<li class="chapter" data-level="7.7" data-path="chapter7.html"><a href="chapter7.html#confidence-interval-for-the-mean-and-prediction-intervals-for-a-new-observation-270"><i class="fa fa-check"></i><b>7.7</b> Confidence Interval for the mean and prediction Intervals for a new observation 270</a></li>
<li class="chapter" data-level="7.8" data-path="chapter7.html"><a href="chapter7.html#section7-7"><i class="fa fa-check"></i><b>7.8</b> Chapter summary</a></li>
<li class="chapter" data-level="7.9" data-path="chapter7.html"><a href="chapter7.html#section7-8"><i class="fa fa-check"></i><b>7.9</b> Important R code</a></li>
<li class="chapter" data-level="7.10" data-path="chapter7.html"><a href="chapter7.html#section7-9"><i class="fa fa-check"></i><b>7.10</b> Practice problems</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="chapter8.html"><a href="chapter8.html"><i class="fa fa-check"></i><b>8</b> Multiple linear regression</a><ul>
<li class="chapter" data-level="8.1" data-path="chapter8.html"><a href="chapter8.html#section8-1"><i class="fa fa-check"></i><b>8.1</b> Going from SLR to MLR</a></li>
<li class="chapter" data-level="8.2" data-path="chapter8.html"><a href="chapter8.html#section8-2"><i class="fa fa-check"></i><b>8.2</b> Validity conditions in MLR</a></li>
<li class="chapter" data-level="8.3" data-path="chapter8.html"><a href="chapter8.html#section8-3"><i class="fa fa-check"></i><b>8.3</b> Interpretation of MLR terms</a></li>
<li class="chapter" data-level="8.4" data-path="chapter8.html"><a href="chapter8.html#section8-4"><i class="fa fa-check"></i><b>8.4</b> Comparing multiple regression models</a></li>
<li class="chapter" data-level="8.5" data-path="chapter8.html"><a href="chapter8.html#section8-5"><i class="fa fa-check"></i><b>8.5</b> General recommendations for MLR interpretations and VIFs</a></li>
<li class="chapter" data-level="8.6" data-path="chapter8.html"><a href="chapter8.html#section8-6"><i class="fa fa-check"></i><b>8.6</b> MLR Inference: Parameter inferences using the t-distribution</a></li>
<li class="chapter" data-level="8.7" data-path="chapter8.html"><a href="chapter8.html#section8-7"><i class="fa fa-check"></i><b>8.7</b> Overall F-test in Multiple Linear Regression</a></li>
<li class="chapter" data-level="8.8" data-path="chapter8.html"><a href="chapter8.html#section8-8"><i class="fa fa-check"></i><b>8.8</b> Case Study: First year college GPA and SATs</a></li>
<li class="chapter" data-level="8.9" data-path="chapter8.html"><a href="chapter8.html#section8-9"><i class="fa fa-check"></i><b>8.9</b> Different intercepts for different groups: MLR with Indicator variables</a></li>
<li class="chapter" data-level="8.10" data-path="chapter8.html"><a href="chapter8.html#section8-10"><i class="fa fa-check"></i><b>8.10</b> Additive MLR with more than two groups: Headache example</a></li>
<li class="chapter" data-level="8.11" data-path="chapter8.html"><a href="chapter8.html#section8-11"><i class="fa fa-check"></i><b>8.11</b> Different slopes and different intercepts</a></li>
<li class="chapter" data-level="8.12" data-path="chapter8.html"><a href="chapter8.html#section8-12"><i class="fa fa-check"></i><b>8.12</b> F-tests for MLR models with quantitative and categorical variables and interactions</a></li>
<li class="chapter" data-level="8.13" data-path="chapter8.html"><a href="chapter8.html#section8-13"><i class="fa fa-check"></i><b>8.13</b> AICs for model selection</a></li>
<li class="chapter" data-level="8.14" data-path="chapter8.html"><a href="chapter8.html#section8-14"><i class="fa fa-check"></i><b>8.14</b> Forced Expiratory Volume model selection using AICs</a></li>
<li class="chapter" data-level="8.15" data-path="chapter8.html"><a href="chapter8.html#section8-15"><i class="fa fa-check"></i><b>8.15</b> Chapter summary</a></li>
<li class="chapter" data-level="8.16" data-path="chapter8.html"><a href="chapter8.html#section8-16"><i class="fa fa-check"></i><b>8.16</b> Important R code</a></li>
<li class="chapter" data-level="8.17" data-path="chapter8.html"><a href="chapter8.html#section8-17"><i class="fa fa-check"></i><b>8.17</b> Practice problems</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="chapter9.html"><a href="chapter9.html"><i class="fa fa-check"></i><b>9</b> Case studies</a><ul>
<li class="chapter" data-level="9.1" data-path="chapter9.html"><a href="chapter9.html#section9-1"><i class="fa fa-check"></i><b>9.1</b> Overview of material covered</a></li>
<li class="chapter" data-level="9.2" data-path="chapter9.html"><a href="chapter9.html#section9-2"><i class="fa fa-check"></i><b>9.2</b> The impact of simulated chronic nitrogen deposition on the biomass and N2-fixation activity of two boreal feather moss–cyanobacteria associations</a></li>
<li class="chapter" data-level="9.3" data-path="chapter9.html"><a href="chapter9.html#section9-3"><i class="fa fa-check"></i><b>9.3</b> Ants learn to rely on more informative attributes during decision-making</a></li>
<li class="chapter" data-level="9.4" data-path="chapter9.html"><a href="chapter9.html#section9-4"><i class="fa fa-check"></i><b>9.4</b> Multi-variate models are essential for understanding vertebrate diversification in deep time</a></li>
<li class="chapter" data-level="9.5" data-path="chapter9.html"><a href="chapter9.html#section9-5"><i class="fa fa-check"></i><b>9.5</b> General summary</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">A Second Semester Statistics Course with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="chapter6" class="section level1">
<h1><span class="header-section-number">Chapter 6</span> Correlation and Simple Linear Regression</h1>
<div id="section6-1" class="section level2">
<h2><span class="header-section-number">6.1</span> Relationships between two quantitative variables</h2>
<p>The independence test in Chapter <a href="chapter5.html#chapter5">5</a> provided a technique for assessing evidence of a relationship between two categorical variables. The terms <strong><em>relationship</em></strong> and <strong><em>association</em></strong> are synonyms that, in statistics, imply that values on one variable tend to occur more often with some other values of the other variable or that knowing something about the level of one variable provides information about the patterns of values on the other variable. These terms are not specific to the “form” of the relationship – any pattern (strong or weak, negative or positive, easily explained or complicated) satisfy the definition. There are two other aspects to using these terms in a statistical context. First, they are not directional – an association between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> is the same as saying there is an association between <span class="math inline">\(y\)</span> and <span class="math inline">\(x\)</span>. Second, they are not causal unless the levels of the one of the variables are randomly assigned in an experimental context. We add to this terminology the idea of correlation between variables <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>. <strong><em>Correlation</em></strong>, in most statistical contexts, is a measure of the specific type of relationship between the variables: the <strong>linear relationship between two quantitative variables</strong><a href="#fn54" class="footnoteRef" id="fnref54"><sup>54</sup></a>. So as we start to review these ideas from your previous statistics course, remember that associations and relationships are more general than correlations and it is possible to have no correlation where there is a strong relationship between variables. “Correlation” is used colloquially as a synonym for relationship but we will work to reserve it for its more specialized usage here to refer to the linear relationship.</p>
<p>Assessing and then modeling relationships between quantitative variables drives the rest of the chapters, so we should get started with some motivating examples to start to think about what relationships between quantitative variables “look like”… To motivate these methods, we will start with a study of the effects of beer consumption on blood alcohol levels (<em>BAC</em>, in grams of alcohol per deciliter of blood). A group of <span class="math inline">\(n=16\)</span> student volunteers at The Ohio State University drank a randomly assigned number of beers<a href="#fn55" class="footnoteRef" id="fnref55"><sup>55</sup></a>. Thirty minutes later, a police officer measured their <em>BAC</em>. Your instincts, especially as well-educated college students with some chemistry knowledge, should inform you about the direction of this relationship – that there is a <strong><em>positive relationship</em></strong> between <code>Beers</code> and <code>BAC</code>. In other words, <strong>higher values of one variable are associated with higher values of the other</strong>. Similarly, lower values of one are associated with lower values of the other. In fact there are online calculators that tell you how much your <em>BAC</em> increases for each extra beer consumed (for example: <a href="http://www.craftbeer.com/beer-studies/blood-alcohol-content-calculator" class="uri">http://www.craftbeer.com/beer-studies/blood-alcohol-content-calculator</a> if you plug in 1 beer). The increase in <span class="math inline">\(y\)</span> (<code>BAC</code>) for a 1 unit increase in <span class="math inline">\(x\)</span> (here, 1 more beer) is an example of <strong><em>slope coefficient</em></strong> that is applicable if the relationship between the variables is linear and something that will be fundamental in what we will call <strong><em>simple linear regression model</em></strong>. In a simple linear regression model (simple means that there is only one explanatory variable) the slope is the expected change in the mean response for a one unit increase in the explanatory variable. You could also use the <em>BAC</em> calculator and the models that we are going to develop to pick a total number of beers you will consume and get a predicted <em>BAC</em>.</p>
<p>Before we get to the specifics of this model and how we measure correlation, we should explore the relationship between <code>Beers</code> and <code>BAC</code> in a scatterplot. Figure <a href="chapter6.html#fig:Figure6-1">6.1</a> shows a <strong><em>scatterplot</em></strong> of the results that display the expected positive relationship. Scatterplots display the response pairs for the two quantitative variables with the explanatory variable on the x-axis and the response variable on the y-axis. The relationship between <code>Beers</code> and <code>BAC</code> appears to be relatively linear but there is possibly more variability than one might expect. For example, for students consuming 5 beers, their <em>BAC</em>s range from 0.05 to 0.10. If you look at the online <em>BAC</em> calculators, you will see that other factors such as weight, sex, and beer percent alcohol can impact the results. We might also be interested in previous alcohol consumption. In Chapter <a href="chapter8.html#chapter8">8</a>, we will learn how to estimate the relationship between <code>Beers</code> and <code>BAC</code> after correcting for those “other variables” using <strong><em>multiple linear regression</em></strong>, where we incorporate more than one quantitative explanatory variable into the linear model (somewhat like in the 2-Way ANOVA). Some of this variability might be hard or impossible to explain regardless of the other variables available and is considered unexplained variation and goes into the residual errors in our models, just like in the ANOVA models. To make scatterplots as in Figure <a href="chapter6.html#fig:Figure6-1">6.1</a>, we simply use <code>plot(y~x, data=...)</code>.</p>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">BB &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;http://www.math.montana.edu/courses/s217/documents/beersbac.csv&quot;</span>)
<span class="kw">plot</span>(BAC<span class="op">~</span>Beers, <span class="dt">data=</span>BB)</code></pre></div>
<div class="figure"><span id="fig:Figure6-1"></span>
<img src="06-correlationAndSimpleLinearRegression_files/figure-html/Figure6-1-1.png" alt="Scatterplot of beers consumed versus BAC." width="672" />
<p class="caption">
Figure 6.1: Scatterplot of beers consumed versus BAC.
</p>
</div>
<p>There are a few general things to look for in scatterplots:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Assess the</strong> <span class="math inline">\(\underline{\textbf{direction of the relationship}}\)</span> – is it positive or negative?</p></li>
<li><p><strong>Consider the</strong> <span class="math inline">\(\underline{\textbf{strength of the relationship}}\)</span>. The general idea of assessing strength visually is about how hard or easy it is to see the pattern. If it is hard to see a pattern, then it is weak. If it is easy to see, then it is strong.</p></li>
<li><p><strong>Consider the</strong> <span class="math inline">\(\underline{\textbf{linearity of the relationship}}\)</span>. Does it appear to curve or does it follow a relatively straight line? Curving relationships are called <strong><em>curvilinear</em></strong> or <strong><em>nonlinear</em></strong> and can be strong or weak just like linear relationships – it is all about how tightly the points follow the pattern you identify.</p></li>
<li><p><strong>Check for</strong> <span class="math inline">\(\underline{\textbf{unusual observations -- outliers}}\)</span> – by looking for points that don’t follow the overall pattern. Being large in <span class="math inline">\(x\)</span> or <span class="math inline">\(y\)</span> doesn’t mean that the point is an outlier. Being unusual relative to the overall pattern makes a point an outlier in this setting.</p></li>
<li><p><strong>Check for</strong> <span class="math inline">\(\underline{\textbf{changing variability}}\)</span> in one variable based on values of the other variable. This will tie into a constant variance assumption later in the regression models.</p></li>
<li><p><strong>Finally, look for</strong> <span class="math inline">\(\underline{\textbf{distinct groups}}\)</span> in the scatterplot. This might suggest that observations from two populations, say males and females, were combined but the relationship between the two quantitative variables might be different for the two groups.</p></li>
</ol>
<p>Going back to Figure <a href="chapter6.html#fig:Figure6-1">6.1</a> it appears that there is a moderately strong linear relationship between <code>Beers</code> and <code>BAC</code> – not weak but with some variability around what appears to be a straight-line relationship. There might even be a hint of a nonlinear relationship in the higher beer values. There are no clear outliers because the observation at 9 beers seems to be following the overall pattern fairly closely. There is little evidence of non-constant variance mainly because of the limited size of the data set – we’ll check this with better plots later. And there are no clearly distinct groups in this plot, mainly because the # of beers was randomly assigned. These data have one more interesting feature to be noted – that subjects managed to consume 8 or 9 beers. This seems to be a large number. I have never been able to trace this data set to the original study so it is hard to know if (1) they had this study approved by a human subjects research review board to make sure it was “safe”, (2) every subject in the study was able to consume their randomly assigned amount, and (3) whether subjects were asked to show up to the study with <em>BAC</em>s of 0. We also don’t know the alcohol concentration of the beer consumed or volume. But it is still a fun example to start these methods with…</p>
<p>In making scatterplots, there is always a choice of a variable for the x-axis and the y-axis. It is our convention to put explanatory or independent variables (the ones used to explain or predict the responses) on the x-axis. In studies where the subjects are randomly assigned to levels of a variable, this is very clearly an explanatory variable, and we can go as far as making causal inferences with it. In observational studies, it can be less clear which variable explains which. In these cases, make the most reasonable choice based on the observed variables but remember that, when the direction of relationship is unclear, you could have switched which axes and implication of which variable explains which.</p>
</div>
<div id="section6-2" class="section level2">
<h2><span class="header-section-number">6.2</span> Estimating the correlation coefficient</h2>
<p>In terms of quantifying relationships between variables, we start with the correlation coefficient, a measure that is the same regardless of your choice of which variable is considered explanatory or response. We measure the strength and direction of linear relationships between two quantitative variables using <strong><em>Pearson’?’s r</em></strong> or <strong><em>Pearson’?’s Product Moment Correlation Coefficient</em></strong>. For those who really like acronyms, Wikipedia even suggests calling it the PPMCC. However, its use is so ubiquitous that the lower case <strong><em>r</em></strong> or just “correlation coefficient” are often sufficient to identify that you have used the PPMCC. Some of the extra distinctions arise because there are other ways of measuring correlations in other situations (for example between two categorical variables), but we will not consider them here.</p>
<p>The correlation coefficient, <strong><em>r</em></strong>, is calculated as</p>
<p><span class="math display">\[r=\frac{1}{n-1}\Sigma^n_{i=1}\left(\frac{x_i-\bar{x}}{s_x}\right)
\left(\frac{y_i-\bar{y}}{s_y}\right),\]</span></p>
<p>where <span class="math inline">\(s_x\)</span> and <span class="math inline">\(s_y\)</span> are the standard deviations of <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>. This formula can also be written as</p>
<p><span class="math display">\[r=\frac{1}{n-1}\sum^n_{i=1}z_{x_i}z_{y_i}\]</span></p>
<p>where <span class="math inline">\(z_{x_i}\)</span> is the z-score (observation minus mean divided by standard deviation) for the <span class="math inline">\(i^{th}\)</span> observation on <span class="math inline">\(x\)</span> and <span class="math inline">\(z_{y_i}\)</span> is the z-score for the <span class="math inline">\(i^{th}\)</span> observation on <span class="math inline">\(y\)</span>. We won’t directly use this formula, but its contents inform the behavior of <strong><em>r</em></strong>. First, because it is a sum divided by (<span class="math inline">\(n-1\)</span>) it is a bit like an average – it combines information across all observations and, like the mean, is sensitive to outliers. Second, it is a dimension-less measure, meaning that it has no units attached to it. It is based on z-scores which have units of standard deviations of <span class="math inline">\(x\)</span> or <span class="math inline">\(y\)</span> so the original units of measurement are cancelled out going into this calculation. This also means that changing the original units of measurement, say from Fahrenheit to Celsius or from miles to km for one or the other variable will have no impact on the correlation. Less obviously, the formula guarantees that <strong><em>r</em></strong> is between -1 and 1. It will attain -1 for a perfect negative linear relationship, 1 for a perfect positive linear relationship, and 0 for no linear relationship. We are being careful here to say <strong><em>linear relationship</em></strong> because you can have a strong nonlinear relationship with a correlation of 0. For example, consider Figure <a href="chapter6.html#fig:Figure6-2">6.2</a>.</p>

<div class="figure"><span id="fig:Figure6-2"></span>
<img src="06-correlationAndSimpleLinearRegression_files/figure-html/Figure6-2-1.png" alt="Scatterplot of an amusing relationship that has \(r=0\)." width="672" />
<p class="caption">
Figure 6.2: Scatterplot of an amusing relationship that has <span class="math inline">\(r=0\)</span>.
</p>
</div>
<p>There are some conditions for trusting the results that the correlation coefficient provides:</p>
<ol style="list-style-type: decimal">
<li><p>Two quantitative variables measured.</p>
<ul>
<li>This might seem silly, but categorical variables can be coded numerically and a meaningless correlation can be estimated if you are not careful what you correlate.</li>
</ul></li>
<li><p>The relationship between the variables is relatively linear.</p>
<ul>
<li>If the relationship is nonlinear, the correlation is meaningless and can be misleading.</li>
</ul></li>
<li><p>There should be no outliers.</p>
<ul>
<li><p>The correlation is very sensitive (technically <strong><em>not resistant</em></strong>) to the impacts of certain types of outliers and you should generally avoid reporting the correlation when they are present.</p></li>
<li><p>One option in the presence of outliers is to report the correlation with and without outliers to see how they influence the estimated correlation.</p></li>
</ul></li>
</ol>
<p>The correlation coefficient is dimensionless but larger magnitude values (closer to -1 OR 1) mean stronger linear relationships. A rough interpretation scale based on experiences working with correlations follows, but this varies between fields and types of research and variables measured. It depends on the levels of correlation researchers become used to obtaining, so can even vary within fields. Use this scale until you develop your own experience:</p>
<ul>
<li><p><span class="math inline">\(\left|\mathbf{r}\right|&lt;0.3\)</span>: weak linear relationship,</p></li>
<li><p><span class="math inline">\(0.3 &lt; \left|\mathbf{r}\right|&lt;0.7\)</span>: moderate linear relationship,</p></li>
<li><p><span class="math inline">\(0.7 &lt; \left|\mathbf{r}\right|&lt;0.7\)</span>: strong linear relationship, and</p></li>
<li><p><span class="math inline">\(0.9 &lt; \left|\mathbf{r}\right|&lt;1.0\)</span>: very strong linear relationship.</p></li>
</ul>
<p>And again note that this scale only relates to the <strong>linear</strong> aspect of the relationship between the variables.</p>
<p>When we have linear relationships between two quantitative variables, <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>, we can obtain estimated correlations from the <code>cor</code> function either using <code>y~x</code> or by running the <code>cor</code> function<a href="#fn56" class="footnoteRef" id="fnref56"><sup>56</sup></a> on the entire data set. When you run the <code>cor</code> function on a data set it produces a <strong><em>correlation matrix</em></strong> which contains a matrix of correlations where you can triangulate the variables being correlated by the row and column names, noting that the correlation between a variable and itself is 1. A matrix of correlations is useful for comparing more than two variables, discussed below.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">require</span>(mosaic)
<span class="kw">cor</span>(BAC<span class="op">~</span>Beers, <span class="dt">data=</span>BB)</code></pre></div>
<pre><code>## [1] 0.8943381</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cor</span>(BB)</code></pre></div>
<pre><code>##           Beers       BAC
## Beers 1.0000000 0.8943381
## BAC   0.8943381 1.0000000</code></pre>
<p>Based on either version of using the function, we find that the correlation between <code>Beers</code> and <code>BAC</code> is estimated to be 0.89. This suggests a strong linear relationship between the two variables. Examples are about the only way to build up enough experience to become skillful in using the correlation coefficient. Some additional complications arise in more complicated studies as the next example demonstrates.</p>
<p>Gude, Cookson, Greenwood, and Haggerty (2009) explored the relationship between average summer temperature (degrees F) and area burned (natural log of hectares<a href="#fn57" class="footnoteRef" id="fnref57"><sup>57</sup></a> = log(hectares)) by wildfires in Montana from 1985 to 2007. The <strong><em>log-transformation</em></strong> is often used to reduce the impacts of really large observations on non-negative (strictly greater than 0) responses with really large observations (more on <strong><em>transformations</em></strong> and their impacts on regression models in Chapter <a href="chapter7.html#chapter7">7</a>). Based on your experiences and before analyzing the data, I’m sure you would assume that summer temperature explains the area burned by wildfires. But could it be that more fires are related to having warmer summers? That second direction is unlikely on a state-wide scale but could apply at a particular weather station that is near a fire. There is another option – some other variable is affecting both variables. For example, drier summers might be the real explanatory variable that is related to having both warm summers and lots of fires. These variables are also being measured over time making them examples of <strong><em>time series</em></strong>. In statistics, time series data is generally reserved for evenly spaced measurements over time, like monthly or yearly measurements. In this situation, if there are changes over time, they might be attributed to climate change. So there are really three relationships to explore with the variables measured here (remembering that the full story might require measuring even more!): log-area burned versus temperature, temperature versus year, and log-area burned versus year.</p>
<p>With more than two variables, we can use the <code>cor</code> function on all the variables and end up getting a matrix of correlations or, simply, the <strong><em>correlation matrix</em></strong>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mtfires &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;http://www.math.montana.edu/courses/s217/documents/climateR2.csv&quot;</span>)
<span class="co"># natural log transformation of area burned</span>
mtfires<span class="op">$</span>loghectacres &lt;-<span class="st"> </span><span class="kw">log</span>(mtfires<span class="op">$</span>hectacres) 

<span class="co">#Cuts the original hectacres data so only log-scale version in data.frame</span>
mtfiresR &lt;-<span class="st"> </span>mtfires[,<span class="op">-</span><span class="dv">3</span>] 
<span class="kw">cor</span>(mtfiresR)</code></pre></div>
<pre><code>##                    Year Temperature loghectacres
## Year          1.0000000  -0.0037991    0.3617789
## Temperature  -0.0037991   1.0000000    0.8135947
## loghectacres  0.3617789   0.8135947    1.0000000</code></pre>
<p>If you triangulate the row and column labels, that cell provides the correlation between that pair of variables. For example, in the first row (<code>Year</code>) and the last column (<code>loghectacres</code>), you can find that the correlation coefficient is <strong><em>r</em></strong>=0.362. Note the symmetry in the matrix around the diagonal of 1’?’s – this further illustrates that correlation between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> does not depend on which variable is viewed as the “response”. The estimated correlation between <code>Temperature</code> and <code>Year</code> is -0.004 and the correlation between <code>loghectacres</code> (<em>log-hectares burned</em>) and <code>Temperature</code> is 0.81. So <code>Temperature</code> has almost no linear change over time. And there is a strong linear relationship between <code>loghectacres</code> and <code>Temperature</code>. So it appears that temperatures may be related to log-area burned but that the trend over time in both is less clear (at least the linear trends).</p>
<p>The correlation matrix alone is misleading – we need to explore scatterplots to check for nonlinear relationships, outliers, and clustering of observations that may be distorting the numerical measure of the linear relationship. The <code>pairs.panels</code> function from the <code>psych</code> package (Revelle, 2016) combines the numerical correlation information and scatterplots in one display. There are some options to turn off for the moment but it is an easy function to use to get lots of information in one place. As in the correlation matrix, you triangulate the variables for the pairwise relationship. The upper right diagonal of Figure <a href="chapter6.html#fig:Figure6-3">6.3</a> displays a correlation of 0.36 for <code>Year</code> and <code>loghectares</code> and the lower left panel contains the scatterplot with <code>Year</code> on the x-axis and <code>loghectares</code> on the y-axis. The correlation between <code>Year</code> and <code>Temperature</code> is really small, both in magnitude and in display, but appears to be nonlinear (it goes down between 1985 and 1995 and then goes back up), so the correlation coefficient doesn’t mean much here since it just measures the overall linear relationship. We might say that this is a moderate strength (moderately “clear”) curvilinear relationship. In terms of the underlying climate process, it suggests a decrease in summer temperatures between 1985 and 1995 and then an increase in the second half of the data set.</p>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">require</span>(psych) 
<span class="kw">pairs.panels</span>(mtfiresR, <span class="dt">ellipses=</span>F, <span class="dt">scale=</span>T, <span class="dt">smooth=</span>F, <span class="dt">col=</span><span class="dv">0</span>)</code></pre></div>
<div class="figure"><span id="fig:Figure6-3"></span>
<img src="06-correlationAndSimpleLinearRegression_files/figure-html/Figure6-3-1.png" alt="Scatterplot matrix of Montana fires data." width="672" />
<p class="caption">
Figure 6.3: Scatterplot matrix of Montana fires data.
</p>
</div>
<p>As one more example, the Australian Institute of Sport collected data on 102 male and 100 female athletes that are available in the <code>ais</code> data set from the <code>alr3</code> package (Weisberg, 2005). They measured a variety of variables including the athlete’?’s Hematocrit (<code>Hc</code>, units of percentage of red blood cells in the blood), Body Fat Percentage (<code>Bfat</code>, units of percentage of total bodyweight), and height (<code>Ht</code>, units of cm). Eventually we might be interested in predicting <code>Hc</code> based on the other variables, but for now the associations are of interest.</p>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">require</span>(alr3)
<span class="kw">data</span>(ais)
aisR &lt;-<span class="st"> </span>ais[,<span class="kw">c</span>(<span class="st">&quot;Ht&quot;</span>,<span class="st">&quot;Hc&quot;</span>,<span class="st">&quot;Bfat&quot;</span>)]
<span class="kw">summary</span>(aisR)</code></pre></div>
<pre><code>##        Ht              Hc             Bfat       
##  Min.   :148.9   Min.   :35.90   Min.   : 5.630  
##  1st Qu.:174.0   1st Qu.:40.60   1st Qu.: 8.545  
##  Median :179.7   Median :43.50   Median :11.650  
##  Mean   :180.1   Mean   :43.09   Mean   :13.507  
##  3rd Qu.:186.2   3rd Qu.:45.58   3rd Qu.:18.080  
##  Max.   :209.4   Max.   :59.70   Max.   :35.520</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cor</span>(aisR)</code></pre></div>
<pre><code>##              Ht         Hc       Bfat
## Ht    1.0000000  0.3711915 -0.1880217
## Hc    0.3711915  1.0000000 -0.5324491
## Bfat -0.1880217 -0.5324491  1.0000000</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pairs.panels</span>(aisR,<span class="dt">scale=</span>T,<span class="dt">ellipse=</span>F,<span class="dt">smooth=</span>F,<span class="dt">col=</span><span class="dv">0</span>)</code></pre></div>
<div class="figure"><span id="fig:Figure6-4"></span>
<img src="06-correlationAndSimpleLinearRegression_files/figure-html/Figure6-4-1.png" alt="Scatterplot matrix of athlete data." width="672" />
<p class="caption">
Figure 6.4: Scatterplot matrix of athlete data.
</p>
</div>
<p><code>Ht</code> (<em>Height</em>) and <code>Hc</code> (<em>Hematocrit</em>) have a moderate positive relationship that may contain a slightly nonlinearity. It also contains one clear outlier for a middle height athlete (around 175 cm) with an <code>Hc</code> of close to 60% (a result that is extremely high). One might wonder about whether this athlete has been doping or if that measurement involved a recording error. We should consider removing that observation to see how our results might change without it impacting the results. For the relationship between <code>Bfat</code> (<em>bodyfat</em>) and <code>Hc</code> (<em>hematocrit</em>), that same high <code>Hc</code> value is a clear outlier. There is also a high <code>Bfat</code> (<em>body fat</em>) athlete (35%) with a somewhat low <code>Hc</code> value. This also might be influencing our impressions so we will remove both “unusual” values and remake the plot. The two offending observations were found for individuals numbered 56 and 166 in the data set:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">aisR[<span class="kw">c</span>(<span class="dv">56</span>,<span class="dv">166</span>),]</code></pre></div>
<pre><code>##        Ht   Hc  Bfat
## 56  179.8 37.6 35.52
## 166 174.9 59.7  9.56</code></pre>
<p>We can create a reduced version of the data (<code>aisR2</code>) by removing those two rows using <code>[-c(56, 166),]</code> and then remake the plot:</p>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">aisR2 &lt;-<span class="st"> </span>aisR[<span class="op">-</span><span class="kw">c</span>(<span class="dv">56</span>,<span class="dv">166</span>),] <span class="co">#Removes observations in rows 56 and 166</span>
<span class="kw">pairs.panels</span>(aisR2, <span class="dt">scale=</span>T, <span class="dt">ellipse=</span>F, <span class="dt">smooth=</span>F, <span class="dt">col=</span><span class="dv">0</span>)</code></pre></div>
<div class="figure"><span id="fig:Figure6-5"></span>
<img src="06-correlationAndSimpleLinearRegression_files/figure-html/Figure6-5-1.png" alt="Scatterplot matrix of athlete data with two potential outliers removed." width="672" />
<p class="caption">
Figure 6.5: Scatterplot matrix of athlete data with two potential outliers removed.
</p>
</div>
<p>After removing these two unusual observations, the relationships between the variables are more obvious (Figure <a href="chapter6.html#fig:Figure6-5">6.5</a>). There is a moderate strength, relatively linear relationship between <em>Height</em> and <em>Hematocrit</em>. There is almost no relationship between <em>Height</em> and <em>Body Fat %</em> (<strong><em>r</em></strong>=-0.20). There is a negative, moderate strength, somewhat curvilinear relationship between <em>Hematocrit</em> and <em>Body Fat %</em> (<strong><em>r</em></strong>=-0.54). As hematocrit increases initially, the body fat percentage decreases but at a certain level (around 45% for <code>Hc</code>), the body fat percentage seems to level off. Interestingly, it ended up that removing those two outliers had only minor impacts on the estimated correlations – this will not always be the case.</p>
<p>Sometimes we want to just be able to focus on the correlations, assuming we trust that the correlation is a reasonable description of the results between the variables. To make it easier to see patterns of positive and negative correlations, we can employ a different version of the same display from the <code>corrplot</code> package (Wei and Simko, 2016). In this case (Figure <a href="chapter6.html#fig:Figure6-6">6.6</a>), it tells much the same story but also allows the viewer to easily distinguish both size and direction and read off the numerical correlations if desired.</p>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">require</span>(corrplot)</code></pre></div>
<pre><code>## Loading required package: corrplot</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">corrplot.mixed</span>(<span class="kw">cor</span>(aisR2), <span class="dt">col=</span><span class="kw">c</span>(<span class="st">&quot;black&quot;</span>, <span class="st">&quot;orange&quot;</span>))</code></pre></div>
<div class="figure"><span id="fig:Figure6-6"></span>
<img src="06-correlationAndSimpleLinearRegression_files/figure-html/Figure6-6-1.png" alt="Correlation plot of the athlete data with two potential outliers removed. Lighter (orange) circle for positive correlations and black for negative correlations." width="576" />
<p class="caption">
Figure 6.6: Correlation plot of the athlete data with two potential outliers removed. Lighter (orange) circle for positive correlations and black for negative correlations.
</p>
</div>
</div>
<div id="section6-3" class="section level2">
<h2><span class="header-section-number">6.3</span> Relationships between variables by groups</h2>
</div>
<div id="section6-4" class="section level2">
<h2><span class="header-section-number">6.4</span> Inference for the correlation coefficient (Optional Section)</h2>
</div>
<div id="section6-5" class="section level2">
<h2><span class="header-section-number">6.5</span> Are tree diameters related to tree heights?</h2>
</div>
<div id="section6-6" class="section level2">
<h2><span class="header-section-number">6.6</span> Describing relationships with a regression model</h2>
</div>
<div id="section6-7" class="section level2">
<h2><span class="header-section-number">6.7</span> Least Squares Estimation</h2>
</div>
<div id="section6-8" class="section level2">
<h2><span class="header-section-number">6.8</span> Measuring the strength of regressions: R2</h2>
</div>
<div id="section6-9" class="section level2">
<h2><span class="header-section-number">6.9</span> Outliers: leverage and influence</h2>
</div>
<div id="section6-10" class="section level2">
<h2><span class="header-section-number">6.10</span> Residual diagnostics – setting the stage for inference</h2>
</div>
<div id="section6-11" class="section level2">
<h2><span class="header-section-number">6.11</span> Old Faithful discharge and waiting times</h2>
</div>
<div id="section6-12" class="section level2">
<h2><span class="header-section-number">6.12</span> Chapter summary</h2>
</div>
<div id="section6-13" class="section level2">
<h2><span class="header-section-number">6.13</span> Important R code</h2>
</div>
<div id="section6-14" class="section level2">
<h2><span class="header-section-number">6.14</span> Practice problems</h2>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="54">
<li id="fn54"><p>There are measures of correlation between categorical variables but when statisticians say correlation they mean correlation of quantitative variables. If they are discussing correlations of other types, they will make that clear.<a href="chapter6.html#fnref54">↩</a></p></li>
<li id="fn55"><p>Some of the details of this study have been lost, so we will assume that the subjects were randomly assigned and that a beer means a can of beer and that the beer was of regular strength. We don’t know if any of that is actually true. I have been asking the Dean of Students to repeat this study as an educational activity at MSU with no success yet.<a href="chapter6.html#fnref55">↩</a></p></li>
<li id="fn56"><p>This interface with the <code>cor</code> function only works after you load the <code>mosaic</code> package.<a href="chapter6.html#fnref56">↩</a></p></li>
<li id="fn57"><p>The natural log (<span class="math inline">\(\log_e\)</span> or <span class="math inline">\(\ln\)</span>) is used in statistics so much that the function in R <code>log</code> actually takes the natural log and if you want a <span class="math inline">\(\log_{10}\)</span> you have to use the function <code>log10</code>. When statisticians say log we mean natural log.<a href="chapter6.html#fnref57">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="chapter5.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="chapter7.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
